title,company,location,job description
b'Data Scientist',b'National University',"b'San Diego, CA, US'","b'Position Summary\n\nUnder the direction of the VP, Chief Data Officer, the Data Scientist provides analytical leadership to support the data and analytical needs of the entire University. This position is responsible for developing and maintaining National University\xe2\x80\x99s analytical infrastructure to provide timely and reliable data for informed decision-making. In addition, the incumbent will apply advanced statistical, data mining, machine learning and various predictive modeling techniques to provide information, knowledge, coordination, and tools that support the growth and continued success of National University. The VP, Chief Data Officer provides general oversight concerning objectives and projects for this position and completes an annual evaluation of position.\n\nEssential Functions\nResponsible for the development, maintenance and advancement of National University\xe2\x80\x99s analytical\ninfrastructure.\nDevelop and maintain data extraction, transfer and loading from various sources.\nImplement appropriate security measures throughout the data pipeline.\nResponsible for maintaining metadata management and data quality activities so that data are accurate, reliable and documented.\nApply advanced predictive modeling, data mining, machine learning and statistical techniques to enable\ninformed decision-making, student support, and strategic initiatives.\nProvide analytical guidance to the entire University.\nFacilitate the transmission and understanding of data to enable fact-based decisions to various stakeholders, such as leadership, faculty and staff.\nProvide reliable and timely data that supports strategic planning, student success initiates, and educational and operational effectiveness.\nUtilize various software tools and reporting services to deliver actionable data to end-users in a digestible form\n\nSupervisory Responsibilities: NA\n\nRequirements\n\nEducation & Experience\nBachelor\xe2\x80\x99s degree in a related discipline (Statistics, Mathematics, Data Science, Social Sciences).\nAdvanced degree in a related field or evidence of pursuit of advanced studies or degree strongly preferred.\nOne to three (1-3) years of recent professional experience in data analysis and/or data engineering.\nTechnical / Functional Skills\nProficient in the following software applications: Microsoft Office Applications; Microsoft SQL Server; Microsoft\nAzure; Redmine; Peoplesoft/SOAR; Relational Database Management; Tableau/Power BI; and Statistical\nanalysis software (R, Python, or the equivalent) required.\nExperience and thorough knowledge in data collection and analysis techniques.\nCompetencies\nRequires analytic ability and frequent independent judgment based on knowledge of University policy and precedent.\nFluency in information technologies, including high level of proficiency and understanding with data mapping, data mining, machine learning, statistics, cloud computing and analytical programming languages such as SQL, R and/or Python.\nProven ability to independently synthesize, implement, analyze and report findings of research studies.\nExceptional interpersonal, organizational, and problem-solving skills as well as effective written and verbal communications.\nProven ability to troubleshoot problems and overcome obstacles with creative solutions.\nCapable of performing in a professional and friendly manner despite conditions of deadlines and pressure.\nKeen ability to transform vague requirements into clear, objective, and actionable tasks.\nFully accustomed to working on multiple projects, both independently and as a team member.\nSelf-starter with a positive attitude, intellectual curiosity and a passion for analytics\n\nPhysical Demands / Environment\n\nTravel: none required'"
b'Data Specialist',b'Veyo',b'Greater San Diego Area',"b'Veyo is using its platform and app-based transportation services to reinvent the medical logistics world. Our company is using technology to pioneer new operational models to help make transportation more powerful and more reliable for the healthcare industry.\n\nWhen you work at Veyo, you\xe2\x80\x99re helping to solve one of the nation\xe2\x80\x99s growing healthcare challenges -- ensuring patients get to and from their medical appointments, safely and on-time. We are using smart design and innovative technology to make patient transportation safer and more connected. In the process, we\xe2\x80\x99re transforming the entire industry.\n\nWhat you can expect:\nUse technology to help people lead healthier lives\nWork with an incredibly talented, intelligent team\nAbility to try out new technologies to gauge fit for business needs\nEncouragement to grow professionally and personally \xe2\x80\x93 attend conferences, give knowledge sharing presentations, pick your career path\n\nWhat we\xe2\x80\x99ll expect from you:\nBe committed to the health and safety of our passengers\nHelp shape the strategy and direction of the company and an industry\nSolve algorithmic problems in the logistics, healthcare and operations space through research, experiments and development and support deployment of these solutions into a real world environment\nEntrepreneurial. Everywhere you go, you can\xe2\x80\x99t help but mobilize people, build things, solve problems, roll up your sleeves, go above and beyond, raise the bar. You are an insatiable doer and driver\nAbility to effectively collaborate with and communicate complex concepts to both technical and non-technical audiences at all levels, from C-Level to individual contributors.\nUnderstand the latest industrial and academic developments in AI/ML, and apply it to create prototypes for demonstration\nWork with development teams to mature these algorithms into production quality programs\nDo applied research on a wide array of Operations research and machine learning projects.\n\nRequired Skills:\nAdvanced degree in Statistics, Applied Mathematics, Operations Research, Computer Science, or a related quantitative field.\n5+ years of experience crafting advanced models and familiar with statistical methods applied to large data sets\nProven experience with optimization libraries, scripting languages (Python, R, etc.), SQL and statistical tools, major object-oriented programming languages, and simulation software\nFamiliar with the Microsoft stack C#, .Net 4.5 is a plus\nFamiliarity with GoLang is a plus\n\n\nWe like the following personality traits: Friendly, social, outgoing, positive, passionate, cool under pressure, detail-oriented, deadline oriented, quick learner, multi-tasker, great sense of humor.\n\nWe\xe2\x80\x99re looking for people that love the opportunity to be involved in strategy and management at the top level, but also aren\xe2\x80\x99t scared to get their hands dirty and do what needs to be done to make things happen! We move quickly, and our team doesn\xe2\x80\x99t know the meaning of \xe2\x80\x9cnot my job.\xe2\x80\x9d We want people that want to get things done and can check their ego at the door.\n\nWe thank all applicants for their interest and effort in applying for this position. This position is only for candidates legally allowed to work in the US. EOE.\n\nVeyo is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.'"
b'Senior Software Engineer',b'The Recruiting Spa',b'Greater San Diego Area',"b""Join this 100 person company doing cutting edge work in Search and voice search platforms using Machine Learning.  \n\nMultiple openings for talented backend Java Engineers and Full Stack engineers (frontend focused) to deliver world-class search engine technologies. \n  Duties and Responsibilities:\nJava Role - Building the backend engine that runs the product. This includes extending our existing Machine Learning and Big Data pipelines and building entirely new capabilities, including: Big Data cluster, workflows and applications: data pipelines at scale, and real-time processing Machine learning and Data Scientist support: used in linguistics, ranking, classification, and other artificial intelligence applicationsIngestion Pipeline: process data that comes from our web crawler which discovers and fetches content from the web and other sources\nFrontend/Fullstack Role - Building the frontend of the product (we have our own custom framework), AND building frontend internal tools for our Machine Learning team\n\nSkills and Qualifications (Java):\nBS or MS degree in Computer Science\nSolid experience with Java programming (we also use Spring, Spring Webflux, Reactor, Netty)\nMulti-threading experience is a must\nExperience in scalable architectures and high-throughput application design\nComfortable in Linux and Windows environments.\nPrefer some experience with Big Data Technologies (at least one of the following):\nHadoop ecosystem (HDFS, Hadoop, Hive)\nSpark\nSamza\nKafka\nCassandra\nLucene NLP (Solr or ElasticSearch)\n\nSkills and Qualifications (Frontend):\n\nStrong Javascript\nSPA's\nReact/Redux (Minikube is a plus)\nFull-stack knowledge \n  The ideal candidates will be local to SoCal (We are located in North Coastal San DIego),  be self-motivated, possess excellent communication skills (both oral and written) and be able to work independently.\n   \n """
"b'AWS DevOps, DataOps, and Cloud Engineering Consultant'",b'Hitachi Vantara',"b'San Diego, CA, US'","b'The Company\n\nHitachi Vantara, a wholly owned subsidiary of Hitachi, Ltd., helps data-driven leaders use the value in their data to innovate intelligently and reach outcomes that matter for business and society \xe2\x80\x93 what we call a double bottom line. Only Hitachi Vantara combines 100+ years of experience in operational technology (OT) and 60+ years in IT to unlock the power of data from your business, your people and your machines. We help enterprises store, enrich, activate and monetize data for better customer experiences, new revenue streams and lower business costs.\n\n47Lining, a part of Hitachi Vantara is an AWS Premier Consulting Partner with Big Data and Machine Learning Competency designations. We develop big data solutions and deliver big data managed services built from underlying AWS building blocks like Amazon Redshift, Kinesis, S3, DynamoDB, Machine Learning and Elastic MapReduce. We help customers build, operate and manage breathtaking \xe2\x80\x9cData Machines\xe2\x80\x9d for their data-driven businesses. We architect solutions that address traditional data warehousing, Internet-of-Things analytics back-ends, predictive analytics and machine learning to open up new business opportunities. Our experience spans use cases in multiple industries including industrial, manufacturing, oil & gas, energy, life sciences, gaming, retail analytics, financial services and media & entertainment.\n\nThe Role\n\nWe are seeking experienced and versatile AWS Software Engineering Consultants to develop data and analytics services and solutions in AWS. The ideal contributor will work with a skilled team to develop, deploy, and operate enterprise-grade data platform services and infrastructure on the AWS platform, spanning ingest of IoT and other enterprise data sources, Big Data, machine learning and predictive analytics.\n\n47Lining is growing at an exponential rate and can only grow as quickly as we are able to find the right talent.\xe2\x80\x82We pay extremely competitive salaries, bonuses, free training and conference attending budget, flexible hours and we have a genuinely extremely talented team.\n\nResponsibilities\nHands-on experience developing advanced analytics in SQL, R, Spark or similar tools\nWork with AWS architectures, development, and deployment\nBuild with enterprise-scale data warehouse technologies (Teradata, Oracle, SQL Data Warehouse, Vertica, Redshift)\nExperience managing applications in AWS and familiarity with core services including EC2, S3, RDS, etc.\nExposure to networking & load balancing solutions\nREST API design and development\nWork across all layers of an application, from back-end databases through UI\nCollaborate with development teams to deliver high-quality results\nUse Agile / Scrum development methodology\nSystem decomposition, architecture, design, and specification\n\n\nQualifications\nExperience with deployment automation tools like Puppet, Chef, and Ansible\nGood working knowledge of Big Data technologies such as Hadoop, Hive, Spark\nProficient with SQL databases and knowledge of standard methodologies\nStrong experience with middle-tier web services development (REST APIs)\nStrong background in commercial-grade software development with Java, Python, SQL\nFront End Application Development (Application Views & Controller)\nDomain Entity and Behavior Modeling, Design, and Implementation\n3rd-party application, service and data integration\nData Management, Mapping, Translation & Persistence\nLarge-scale Data Management & Workflow\nAnalytic development and automation\nExcellent documentation habits\n\nWe are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.'"
b'Machine Learning Engineer II',b'Zovio',"b'San Diego, CA, US'","b'Responsibilities\nParticipate in entire lifecycle for Business Intelligence Solution Delivery\nDesign, build, document and manage machine learning solutions and data warehouse objects\nDesign and develop ETL processes using SQL Server Integration Services\nDevelop predictive data models using R or other statistical language following the Machine Learning lifecycle\nResearch and improve features and machine learning models for production pipeline\nOperationalize the Machine Learning model in adherence with Data Warehouse principles integrating easily with Microsoft SQL Stack.\n\nRequirements\nMaster\xe2\x80\x99s Degree in Information Systems, Statistics or Computer Science\n1 year of experience in job offered or as Business Intelligence Engineer I or Business Intelligence Engineer II (or any combination thereof . Must have 1 year of experience (can be gained concurrently with the above experience) in the following: (1) developing machine learning solutions; (2) developing solutions using the MS SQL Server BI Stack; (3) using statistical computer languages include R and Python to manipulate data and draw insights from large data sets.\nMust have working knowledge of:\nSSIS and T-SQL\nAdvanced statistical methods (including regression, classification, and clustering) using machine learning algorithms (including decision tree learning, artificial neural networks, GLM and Random Forest).\nWork from home (home office required).\nBackground check required. Employer will accept any suitable combination of education, training or experience.\nEmployer: Zovio Inc. Job location: San Diego, CA. Qualified applicants should email resume to human.resources@zovio.com'"
b'Machine Learning Engineer',b'Big Cloud',b'Greater San Diego Area',"b""Work with industry experts in combining the best of deep learning and semiconductor design, to bring on-edge machine learning to listening devices.\n\nThis will improve efficiency and improving privacy, whilst lowering latency and saving bandwidth. Moving away from inference and training that is dependent on cloud or legacy data-centers, this company uses unique technology to accelerate toward processing on device.\n\nAs the first, implementation is on devices with listening capabilities, the company is looking for a strong engineer with the ability to implement speech and audio algorithms in high quality, seamless code.\n\nIf you\xe2\x80\x99re a passionate innovative engineer, excited about the future of deep learning then this is for you.\n\nThe company is well-funded, about to complete their series A, and are confident they have a homerun venture, exemplified by the interest by major technology companies who see the value of implementation into their hardware devices.\n\nResponsibilities:\nDesign and implement signal processing algorithms on devices that adopt microphone array to achieve the state-of-art speech recognition performance \n Design and implement robust acoustic modeling algorithms for adverse acoustic conditions, such as far-field, reverberant, and noisy environments\n\nQualifications:\nPh.D. or Master's degree in Computer Science, Electrical Engineering, Signal processing\nExperience with acoustic signal processing algorithms \nExperience with common signal processing and speech recognition toolkits \nExperience with deep learning frameworks\nExperience with building embedded systems is a plus \nPublication record in top speech conferences/journals is a plus\n\nKeywords: speech recognition, speech processing, audio signaling, acoustic signal processing, speaker verification, speech signal processing, long short term memory, lstm, ICASSP, Interspeech, language translation, noise suppression, multi-channel signal processing, acoustic echo cancellation, speech coding, audio coding, TTS, text-to-speech\n \n  Big Cloud is acting as a vendor to this position which is a direct hire."""
b'Machine Learning Performance Engineers',b'Qualcomm',"b'San Diego, CA, US'","b""Job Id\n\nJob Title\n\nMachine Learning Performance Engineers\n\nCompany\n\n\nDivision\n\nQualcomm Technologies, Inc.\n\n\nCorporate Research & Development\n\nJob Area\n\nEngineering - Systems\n\nLocation\n\nCalifornia - San Diego\n\nNorth Carolina - Raleigh\n\nOverview\n\nQualcomm is a company of inventors that unlocked 5G - ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5G\xe2\x80\x99s potential into world-changing technologies and products. This is the Invention Age - and this is where you come in. Qualcomm is utilizing its traditional strengths in digital wireless technologies to play a central role in the evolution of automotive infotainment and autonomous driving. We are investing in several supporting technologies including 4G, 5G, ADAS, and Deep Learning.\n\nThe Qualcomm CR&D team is developing hardware and software solutions for the Qualcomm ADAS system. We are seeking ambitious, bright and innovative engineers with experience in software system design, autonomy, device functional safety concepts and implementations.\n\nJob activities span the whole product life cycle from early R&D to commercial deployment. The environment is fast-paced and requires cross-functional interaction on a daily basis so good communication, planning and execution skills are a must.\n\nWe are looking to staff engineers at multiple levels in systems & software, integration and test. Details of one of the roles we are looking to staff are listed below.\n\nDesired Skills And Aptitudes\nExperience executing, analyzing, and optimizing neural networks in TensorFlow, Caffe2, PyTorch or similar frameworks\nBackground and understanding of neural network operators and mathematical operations: linear algebra, math libraries, desirable\nExperience with industry standard and emerging ML benchmark suites such as MLPerf desirable\nExperience / understanding of machine learning execution engines such as Glow, ONNX Runtime, or similar a plus\nExperience with machine learning accelerators and related software a plus\nStrong skills in analyzing performance of software/hardware solutions on multi-core architectures; understanding of multi-core architecture fundamentals (core, cache, memory, bus, PCIe, etc\xe2\x80\xa6)\nTarget specific code generation and optimization using LLVM or GCC compiler\nPerformance analysis, tuning, and debug using Linux-based profiling tools: perf events, hot-spots, call stacks, Ftrace\nUse of simulators, emulators, JTAG and serial debuggers, a plus\nStrong development skills in C++ and Python\nExcellent communication skills (written and verbal) and team player\n\nEducation Requirements\n\nRequired: Bachelor's, Computer Engineering and/or Electrical Engineering\nPreferred: Master's, Computer Engineering and/or Electrical Engineering\n\nKeywords"""
"b'Scientist, Data Science'",b'Johnson & Johnson',"b'San Diego, CA, US'","b'Janssen Research & Development LLC, a Johnson & Johnson company, is recruiting for a Scientist, Data Science located in La Jolla, CA or Spring House, PA with up to 15% domestic travel.\n\nThe R&D Data Science team within Janssen is looking for an outstanding scientist who is interested in designing, developing, and fielding impactful data science solutions. Our team supports projects from discovery through late development. The scientist will help identify viable data science opportunities and then conceive, develop and implement end to end data analytical solutions. The scientist will be someone who stays on the cutting edge of the data science field in order to implement novel algorithms that influence decisions at various levels in the organization. The role requires both a broad knowledge of existing machine learning algorithms and creativity to invent and customize when necessary. The scientist will be part of a multifaceted, accomplished team that supports multiple R&D therapeutic areas in the discovery and development of innovative medicines.\n\nKey Responsibilities\nWork with colleagues in research and development to design, build and deploy state-of-the art scientific algorithms to support Janssen R&D initiatives.\nAssemble large, complex data sets that meet functional / non-functional business requirements.\nDevelop and apply creative solutions that go beyond current tools to deliver data-driven insights to high-priority scientific problems.\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery.\nAdvocate transparency & action through data storytelling! Establish and execute strategies to increase usage and adoption of Data Science from project conceptualization to completion.\n\nQualifications\nPh.D degree (OR Master\xe2\x80\x99s degree with a minimum of 3 years of relevant experience) in Computer Science, Statistics, Machine Learning & Artificial Intelligence, Physics, Mathematics, Computational Chemistry, Bioinformatics, Computational Biology or a related discipline is required.\n\nRequired\n\nExperience and Skills:\nFamiliarity with large datasets, understanding of data analysis workflows, and/or knowledge of querying languages such as SQL is required.\nProficient with common data science toolkits, such as R, Pandas, TensorFlow, NumPy.\nStrong working knowledge of statistics, machine learning algorithms such as Random Forest, SVM, neural networks, etc. and/or Natural Language Processing techniques is required.\nExperience with visualization software/tools such as Python, R, D3.js, Spotfire, Tableau, etc.\nExperience with big data tools: Spark, Hadoop, Redshift, EMR.\nAbility to effectively communicate technical work to a wide audience.\n\nPrefered\nHandling of healthcare relevant datasets, such as EHR, genomics, clinical trials, insurance claims or registry data.\nExperience designing, developing and deployed web applications, microservices.\nFamiliarity with drug discovery and clinical development processes.\nExperience building processes supporting data transformation, data structures, metadata.\nWe will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\n\nJohnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.\n\nPrimary Location\nUnited States-California-San Diego-\nOther Locations\nNorth America-United States-Pennsylvania-Spring House\nOrganization\nJanssen Research & Development, LLC (6084)\nJob Function\nR&D\nRequisition ID\n2534200402'"
b'Staff Deep Learning/AI Engineer',b'Illumina',"b'San Diego, CA, US'","b'Position Summary\n\nThe Staff Deep Learning/AI Engineer in Illumina\xe2\x80\x99s Finance Performance Management group will focus on applying machine learning/deep learning techniques to finance and business applications. They will be part of analytics team developing machine learning/deep learning methods applied to financial and commercial datasets, with the goal of improving finance and accounting processes.\n\nResponsibilities\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of finance and accounting processes\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDeliver solutions leveraging latest machine learning (ML) techniques, including exploratory data analysis, feature engineering, model selection, model evaluation and cross-validation, and deployment and productionalization at all scales.\nUse predictive modeling to increase and optimize forecasting, revenue generation, and other business outcomes.\nDevelop company A/B testing framework and test model quality.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nMentor and scientifically lead junior members of the team\nBuild strong collaborative relationships with diverse groups within and outside of Illumina\nListed responsibilities are an essential, but not exhaustive list, of the usual duties associated with the position. Changes to individual responsibilities may occur due to business needs.\n\nRequirements\nExperience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\n5-7 years of experience manipulating data sets and building statistical models\nMaster\xe2\x80\x99s or PhD in Statistics, Mathematics, Computer Science or another quantitative field\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nExcellent written and verbal communication skills for coordinating across teams\nAll listed requirements are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional task and responsibilities.\nIllumina believes that everyone has the ability to make an impact, and we are proud to be an equal opportunity employer committed to providing employment opportunity regardless of sex, race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship status, and genetic information. If you require accommodation to complete the application or interview process, please contact accommodations@illumina.com. To learn more, visit: https://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf'"
b'SSD Machine Learning Engineer I (Temporary)',b'Kaiser Permanente',"b'San Diego, CA, US'","b""Description\n\nMachine Learning Engineer will provide technical direction, execution and support of machine learning strategies for the SCPMG Medical informatics group. The position entails designing and implementing data pipelining, integration, and optimization of machine learning models to address healthcare's triple aim: to improve the health of populations, to lower the cost of care, and to enhance the care experience.\n\nEssential Responsibilities\nUse statistical and machine learning techniques to develop and improve clinical decision support tools\nDesign and develop data pipelines for machine learning applications\nOptimize machine learning models to scale in real-time streaming applications\nIntegrate and deploy machine learning components in a production environment\nWork closely with machine learning scientists, physicians, and other stakeholders\nDeploy developed products to project environments.\nReview and provide practical feedback on group products and procedures.\nProvide technical feedback on team members' work.\nSeek out open-source software packages or existing software code that can be reused or applied to assigned tasks.\nProduce/archive process related artifacts such as design documents, test plans, wikis, and code review forms.\nExperience\n\nBasic Qualifications:\nMinimum two (2) years of programming or technical related experience.\nEducation\nB.S. in Computer Science, Informatics, Physics, Mathematics, Engineering or related fields.\nLicense, Certification, Registration\nN/A\nAdditional Requirements\nFamiliarity in the following languages, expert in at least one: Python, Java, SQL\nExperience with pipelining, workflow, and orchestration tools such as Apache Airflow, MLFlow, Kubeflow, Kubernates\nExperience with deep learning frameworks (e.g. Tensorflow)\nFamiliarity with classification and regression algorithms\nPreferred Qualifications\nDemonstrated experience in Natural Language Processing\nDemonstrated experience with machine learning integration and deployment in production environments\nDemonstrated experience with Tensorflow Serving or TensorRT\nFamiliarity with C++\nFamiliarity with writing custom CUDA\nExperience with source control tools for code and models/data\nFamiliarity with healthcare terminology\nM.S. in Computer Science, Informatics, Physics, Mathematics, Engineering or related fields.\nThis is a temporary position"""
b'Summer 2020 Machine Learning/HPC Co-Op/Intern - (78821)',b'AMD',"b'San Diego, CA, US'","b'What You Do At AMD Changes Everything\n\nAt AMD, we push the boundaries of what is possible. We believe in changing the world for the better by driving innovation in high-performance computing, graphics, and visualization technologies \xe2\x80\x93 building blocks for gaming, immersive platforms, and the data center.\n\nDeveloping great technology takes more than talent: it takes amazing people who understand collaboration, respect, and who will go the \xe2\x80\x9cextra mile\xe2\x80\x9d to achieve unthinkable results. It takes people who have the passion and desire to disrupt the status quo, push boundaries, deliver innovation, and change the world. If you have this type of passion, we invite you to take a look at the opportunities available to come join our team.\n\nMachine Learning/HPC Internship\n\nThe Role\n\nRTG (Radeon Technologies Group) Architecture team in San Diego is passionate about developing next-generation GPU solutions. As a Machine Learning/HPC architect, you will collaborate with a strong architecture and design team on developing next generation products for data centers and super-computers. You will engage in architecture exploration, modeling and analysis of ML/HPC workloads. Through your experiments and analysis, you will provide valuable insight into new and emerging hardware and software technologies.\n\nThe Person\n\nYou have excellent analytical and problem-solving skills, along with attention to detail. You are an effective team player who focuses on collaboration, team building, mentoring, and furthering team success. You have strong communication, time management, and presentation skills\n\nKey Responsibilities\nWork with architects to propose innovative solutions that can be implemented in SW/HW, validated by developing various models/simulators\nAnalyze HPC/ML workloads, identify performance bottlenecks and propose solutions\nCollect/summarize data or simulation results for consumption by architects and design teams\n\n\nPreferred Experience\nKnowledge of CPU architectures, basic knowledge of GPGPU architectures\nExcellent C/C++/Scripting (Python, etc.) skills\nKnowledge of Graphics/Compute APIs (CUDA/OpenCL/Vulkan etc.) is preferred\nHW/RTL/SystemC experience is a plus\nKnowledge of ML networks, Tensorflow/Pytorch is desirable\n\n\nAcademic Credentials\nBachelor of Science degree with emphasis in Electrical Engineering, Computer architecture, or Computer Science with relevant experience preferred, or\nMaster or PhD degree with emphasis in Electrical Engineering, Computer architecture, or Computer Science\n\n\nLOCATION:\n\nSan Diego, CA\n\nAMD does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services. AMD and its subsidiaries are equal opportunity employers and will consider all applicants without regard to race, marital status, sex, age, color, religion, national origin, veteran status, disability or any other characteristic protected by law. EOE/MFDV\n\nRequisition Number: 78821\nCountry: United States State: California City: San Diego\nJob Function: Student/ Intern/ Temp\n\nAMD does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services. AMD and its subsidiaries are equal opportunity employers. We consider candidates regardless of age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status. Please click here for more information.'"
b'Deep Learning Research Engineer',b'TuSimple',"b'San Diego, CA, US'","b'TuSimple was founded in 2015 with the goal of bringing the top minds in the world together to achieve the dream of a driverless truck solution. With a foundation in computer vision, algorithms, mapping, and AI, TuSimple is working to create the first commercially viable autonomous truck driving platform with L4 (SAE) levels of safety.\n\nJob Description\n\nOur deep learning team helps autonomous trucks sense and perceive the world. You will play an important role in creating novel algorithms for advanced perception and applying your algorithm on terabytes of data. You will also work closely with other talents in this field in building the next-generation of autonomous sensing algorithms.\n\nResponsibilities\nResearch and prototype developing using deep learning with a special focus on the perception problems of autonomous driving\n\n\nQualifications\nMS/PhD in Computer Science/Electrical Engineering\n3+ years of research or practical experience in applying deep learning on large scale and real world data\nKnowledge in deep learning topics including but not limited to detection, segmentation, 3D perception, and spatial-temporal analysis\nStrong coding skills in Python or C/C++\nFamiliar with at least one of the following deep learning frameworks: MXNET (preferred), TensorFlow, Pytorch, Caffe.\n\n\nPreferred\nTrack record of publishing in top-tier computer vision or machine learning conferences or/and journals.\nPrior academic or industrial experience in autonomous driving.\n\n\nPerks\nCompetitive salary and benefits\nWork with world class AI Engineers\nShape the landscape of autonomous driving\nDaily breakfast, lunch, and dinner\nFull kitchen with unlimited snacks and fruits\nMedical, Vision, and Dental insurance plan\nCompany 401(K) program\nCompany paid life insurance\n\nTuSimple is an Equal Opportunity Employer. This company does not discriminate in employment and personnel practices on the basis of race, sex, age, handicap, religion, national origin or any other basis prohibited by applicable law. Hiring, transferring and promotion practices are performed without regard to the above listed items.'"
b'Sr. Machine Learning Engineer',b'ServiceNow',"b'San Diego, CA, US'","b'Job Title: Senior Machine Learning Engineer\n\nCompany\n\nWork matters. It\xe2\x80\x99s where we spend a third of our lives. And the workplace of the future is going to be a great place. We\xe2\x80\x99re dedicated to bringing that to life for people everywhere. That\xe2\x80\x99s why we put people at the heart of everything we do.\n\nPeople matter. Our people have a passion for learning, building, and innovating. Whether you\xe2\x80\x99re an engineer, a sales professional, a finance professional, or anything in-between, our roles aim to provide each person with meaningful impact and plenty of space to grow.\n\nTeam\n\nCome join the Vulnerability Response Product Engineering team and work with a talented group of developers building best in class automated security orchestration in ServiceNow cloud platform. This team is responsible for the innovation, features, and architecture of products used by many Fortune 500 companies.\n\nRole\n\nAlmost 48% of organizations report that they have had a data breach in the past two years. As the severity and volume of attacks increase, the race to outpace attackers continues. Cybersecurity teams are not equipped enough to keep up and need to leverage the right tools to detect and patch in a timely manner.\n\n60% of breach victims said they were breached due to an unpatched known vulnerability where the patch was not applied\n62% were unaware that their organizations were vulnerable prior to the data breach\n52% of respondents say their organizations are at a disadvantage in responding to vulnerabilities because they use manual processes\n\nWith ServicerNow Vulnerability Response product, we replace manual tasks with automated security orchestration. By unifying the data and processes across IT and security teams, we enable them to prioritize and remediate vulnerabilities and security incidents faster. Using ServiceNow Vulnerability Response, vulnerabilities are patched 60% faster, triage time shrinks by 50% and the existing security and IT staff can handle 50% more workload.\n\nAs a Senior Machine Learning Engineer, you will play a major part in defining the strategy to use massive amounts of data, to prioritize, remediate and predict the vulnerabilities within an Enterprise to reduce and manage exposure to cyber security risk within an organization.\n\nWhat You Get To Do In This Role\nYou will build models against machine learning algorithms and collaborate with industry leading machine learning technologists to address new problem spaces within the ServiceNow ecosystem.\nYou will join a team that takes pride in building extensible and resilient engineering solutions.\nYou will work closely with Product Managers and customers to understand detailed requirements.\nYou will own your solution from design, implementation, automation, delivery and validation with our users.\nYou will define machine learning application strategies and architecture to support these strategies.\nYou will collaborate with an energetic team of like-minded developers, product managers and quality engineers using agile software development methodology.\nYou will work closely with the ServiceNow SaaS platform team on understanding the platform capabilities and extending those capabilities to meet the unique challenges and needs of Vulnerability Response product.\nYou will troubleshoot problems encountered by customers and provide resolutions.\n\nIn order to be successful in this role, we need someone who has:\n6+ years of experience in architecture, design and development of enterprise-grade applications in a high transaction environment.\n2+ years and/or machine learning experience\nKnowledge of Machine Learning algorithms\nStrong understanding of Object-Oriented Analysis, Design Patterns, Data Structures, and time and space-efficient and high performing algorithms\nPassion for software development and problem solving\nHigh energy, self-starter with aptitude for learning new technologies\nKnowledge of Java & JavaScript technologies, with excellent understanding of JavaScript frameworks as Angular, React, Node.js.\nExpert in building RESTful services, and data exchange formats as XML and JSON.\nSolid experience with open source technologies Linux, Apache, Selenium.\nIn-depth knowledge of relational databases (e.g. PostgreSQL, MySQL) and NoSQL databases (e.g. MongoDB)\nExceptional debugging including browser-based debugging, testing, and problem-solving skills.\nExceptional written and verbal communication skills with proven ability to effectively communicate complex technical issues to both technical and non-technical teams.\nPassion for software development, problem-solving, and learning new technologies.\nStrong educational background in Computer Science, Machine Learning, or Mathematics fields, prefer MS/PhD\n\nNote that an exact match on skills is less critical than strong design instincts, high quality coding discipline and enthusiasm for taking on an ambitious project that will reshape the way people interact with enterprise software.\n\nEEOE Statement Section\n\nServiceNow\xe2\x80\x99s EEOE statement is automatically added to each U.S. based job description.'"
b'Deep Learning Research Scientist / Engineer (Deep Learning & Algorithms)',b'Samsung Electronics America',"b'San Diego, CA, US'","b""Description\n\nPosition at Samsung Semiconductor, Inc.\n\nJOB TITLE\n\nResearch Engineer-Deep Learning Theory and Algorithms\n\nRequisition ID\n\nDSA31988\n\nOverview\n\nSamsung Semiconductor, Inc. in San Diego is searching for research engineers at all levels. Candidate will work as part of a team on research and development of algorithms and theory of machine learning. Candidate will research fundamental theoretical aspects of deep learning as well as develop novel techniques to advance the theory and practice of deep learning. Candidate can also apply the developed theory and algorithms to advance the performance of multimedia applications, such as computer vision, augmented reality, natural language processing, or speech processing.\n\nJob Responsibilities\nUnderstand state of the art machine/deep learning concepts, theory, and applications.\nResearch algorithms and theory of learning.\nDevelop machine/deep learning algorithms for mobile processors.\nDevelop simulators and analyze the performance.\nProduce key intellectual property for machine/deep learning.\n\nRequired Skills\nStrong analytical and problem-solving skills\nExpertise in machine/deep learning, optimization, probability theory, statistical inference, information theory, signal processing, and/or image processing\nExcellent communication and teamwork skills\nC/C++, Python, and/or MATLAB coding skills\nPublications in highly ranked journals and conferences\nPhD is required\n\nPreferred Skills\nExperience on popular deep learning frameworks\n*********************************************************************************************************************** Samsung Semiconductor Inc (SSI), an equal opportunity employer, is a world leader in Memory, System LSI, and LCD technologies. Headquartered in San Jose, California, SSI is a wholly-owned U.S. subsidiary of Samsung Electronics Co., Ltd.- the second largest semiconductor manufacturer in the world and the industry's volume and technology leader in DRAM, NAND Flash, SSDs, mobile DRAM and graphics memory. It is one of the largest providers of system logic, imaging and LED lighting solutions, as well as providing advanced process design and manufacturing for fabless companies. Samsung Semiconductor, Inc. also has a research and innovation center with numerous labs providing product design and research in: logic, memory, image sensors, displays and mobile technologies. In addition, the company supports Samsung Display Company, the largest producer of LCD and OLED displays. ***********************************************************************************************************************\n\nLearn more about Samsung Semiconductor here.\n\nA day in the life Samsung Video\n\nSamsung Semiconductor Career Page"""
b'Machine Learning Scientist',b'Amazon',"b'San Diego, CA, US'","b'Description\n\nHave you ever wanted to work on machine learning challenges that will make a lasting impact on society? How about solving key problems that impact the experience of millions of Amazon customers?\n\nAmazon is looking for brilliant Machine Learning Scientists who have the passion to tackle tough problems and help shape a new product from the very early stages in the online grocery shopping space. Together, with a multi-disciplinary team of scientists, engineers, economists, product managers, and subject domain experts, you will help define our customer experience with machine learning at its core. You will define the research and experiment strategy with an iterative approach to create machine learning models and progressively improve the results over time. We are looking for candidates who thrive in fast paced environments and want to invent the future.\n\n\nBasic Qualifications\nPhD or Masters degree in Applied Math, Data Science, Computer Science, Engineering, Machine Learning (or in a highly related field)\n5+ years of hands-on industry experience in predictive modeling, algorithm development, and big data analytics\n5+ year of experience in building machine learning models deployed to production environments\nExperience in applying fundamental machine learning algorithms to solve complex problems\nExperience with modifying standard algorithms (e.g. changing objectives, working-out the math, implementing and scaling)\n7+ years in one or more major programming languages (Python, Java, C++, C, Perl/Ruby, etc.)\nPreferred Qualifications\nPhD in Computer Science, Applied Math, Data Science, Engineering, Machine Learning (or in a highly related field)\n7+ years of hands-on industry experience in predictive modeling, algorithm development and big data analytics\nExtensive experience applying theoretical models in an applied environment\nMastery in fundamentals of problem solving, algorithm design and complexity analysis\nStrong interpersonal and communication skills -- the ability to explain technical concepts and analysis implications clearly to a wide audience, including senior executives, and translate business objectives into action\nAmazon.com is an Equal Opportunity-Affirmative Action Employer \xe2\x80\x93 Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation\n\n\nCompany - Amazon.com Services LLC\nJob ID: A1037013'"
b'Deep Machine Learning Engineer',b'CyberCoders Middleware Test Compay',"b'San Diego, CA, US'","b""Happy New Year!\nBased in the San Diego, CA area, we are one of the most innovative Image solutions companies in the World. We are well-funded with premiere clients who are utilizing us to solve the most challenging image issues we currently face. Our team is composed of experts in the world of machine learning and image processing with a leadership team that brings experiences from leading global scientific technology firms and pride themselves in their hands-on, mentor level management style. If you are a strong Deep Learning / Machine Learning Scientist with experience in Python OR Java OR C and, obviously, Machine Learning expertise, we would welcome the opportunity to discuss the details.....What You Need for this PositionRequirements:\n- 3+ years of Deep / Machine Learning experience\n- Master's Degree or PhD HIGHLY preferred. Points if you have published papers on the same topics.\n- Supervised and Unsupervised machine learning a must\n- Timeseries and/or Deep Learning a big plus\n- Algorithm development experience\n- Communicates very well\n- Research type\n- Excellent communication and written skills\n\nNice to have skills:\n- Strong interest in creating solutions to problems\n- Experience in and interest in learning new technologies\n- Experience managing multiple projects and working independentlyTop Reasons to Work with UsFast growing.\nWell-funded.\nStart-up equity.What's In It for YouWe are willing to offer excellent compensation packages including annualized pay potential of $110k to around $135k, plus EQUITY, and excellent benefits. We are located in a centrally located area with access to 2 major freeways, and plenty of parking.So, if you are a recent PHD grad, or PHD grad with experience in Machine Learning, please apply today!\n\n*** You can also email me directly at eric.shaner@cybercoders.com\n*** Find/connect with me on LinkedIn - www.linkedin.com/in/analytics\nDesired Skills and Experience\nLinear, Non-linear, Deep Learning, Supervised Techniques, Timeseries Analysis, UnSupervised Techniques"""
b'Data Scientist - Statistics and Machine Learning',b'Q-Centrix',"b'San Diego, CA, US'","b'Who are we? Q-Centrix is a leading healthcare information solutions provider with offices in Portsmouth, NH, Chicago, and San Diego, plus more than 900 clinical experts working remotely in 49 states. Our team of smart, ambitious, and fun-loving healthcare professionals are 100% focused on improving the quality of patient care at hospitals throughout the country.\n\nAbout the Job Q-Centrix is looking for a Junior Data Scientist to join us at our San Diego office. We are a data driven and automation focused organization that loves to gain new insights from the massive amount of structured and unstructured data that is collected on a daily basis.\n\nAs a Data Scientist, You Will\nWork on various projects ranging from statistical analysis, data pipelines, machine learning, and advanced signal processing to software engineering\nWrite complete softwares to implement domain agnostic generalized mathematical models that could be deployed on any data\nWork closely with leaders across the organization to look for workflow automation opportunities and execute them\nBuild advanced software solutions that will help prepare the data for analytics projects\nLeverage your experience working with supervised machine learning methods such as ensemble tree classifiers, support vector machines, neural networks, and Bayesian methods to create state-of-the-art predictive models\nCommunicate your successful efforts through documentation and white papers\nKnowledge, Skills, Abilities And Qualification Requirements\nM.S. in Applied Mathematics, Computer Science, or Electrical Engineering and 3+ years of prior experience working as a Data Scientist, machine learning engineer, or data engineer is required\n3+ year of hands-on experience in software engineering, deep learning, and signal processing is highly desired\nQuality Requirements\nPositively contribute to our work environment values of professionalism, mutual respect, teamwork, and collaboration.\nKey Competencies\nProfessionalism and customer service orientation\nAbility to manage multiple projects\nPlanning, organization and excellent time management\nAttention to detail and unrelenting passion for delivery\nFlexibility, adaptability, and teamwork\nYou\xe2\x80\x99re Our Dream Candidate If You\nLove solving business problems with mathematics and programming\nHave a proven track record for writing world class software solutions with Python, Ruby, Java, or Go\nAre passionate about automation and consider yourself an advanced python software developer\nBuilt and operationalized signal processing solutions\nAre intimately familiar with the latest techniques in predictive data modeling including deep learning\nLove data science competitions and are an active participant in kaggle competitions\nLove writing detailed documentation of your completed research, and lastly,\nYou love dogs and cats!\nWho are we?\n\nAt Q-Centrix, we hire people who love learning, value innovation and believe in our mission and values to improve outcomes in healthcare. We applaud qualified applicants who are accountable and committed to producing quality work. As an Equal Opportunity Employer, we support and value diversity, dignity and respect in our work environment, and are committed to creating an inclusive environment in which everyone can thrive.\n\nWe employ people based on the needs of the business and the job, and their individual professional qualifications. Here\xe2\x80\x99s what does not impact our employment decisions: race, religious creed, religion, color, sex, sexual orientation, pregnancy, parental status, genetic information, gender, gender identity, gender expression, age, national origin, ancestry, citizenship, protected veteran or disability status, health, marital, civil union or domestic partnership status, or any status or characteristic protected by the laws or regulations in locations where we operate. If you are an individual with a qualified disability and you need an accommodation during the interview process, please reach out to your recruiter.\n\nWe celebrate and embrace these differences, and take pride in our commitment to being an equal opportunity team.'"
b'Software Engineer',b'PointPredictive Inc.',"b'San Diego, California'","b'We are looking for a junior to mid-level software engineer, whose core skills being Python and experience with Amazon Web Services in Our San Diego Offices.\n\nThis person will act as a generalist supporting senior staff, and will contribute in the following areas:\n\nHelp optimize Python analytics applications and AWS infrastructure for performance.\nBuild-out a robust software testing and release pipeline.\nDevelop automated code tests.\nResearch and develop production monitoring tools.\nContribute partially in a DevOps role.\nDevelop production-level data pipelines for company-critical data science and machine learning solutions\nDevelop tooling, optimization, and testing around core data science work\nBuild and maintain production-level python libraries for the data science team\nLeverage open-source tools and cloud computing technologies comfortably\nExecute best practices in version control and continuous integration/delivery\nOwn and drive projects from conception to completion \n\nIdeally, prior experience includes:\n\n1-5 years as software engineer, with Python as a primary language. Familiar with the Pandas library would be helpful.\nSome experience working in an analytics or data science environment, or exposure to machine-learning.\n1-5 years experience with several AWS services, preferably some of Lambda, EC2, S3, Cloudwatch, API Gateway, and S3.\n1-2 years experience with relational (MySQL, PostgresQL) and NoSql databases (AWS Dynamo DB, MongoDB).\nFamiliarity with version control principles, ideally git.\n\nBonus Points for:\n\nKnowledge of AWS Networking: Virtual Private Cloud (VPC), Subnets, Network Address Translation (NAT) services.\nWindows developer or system administrator skills (Windows Server 2012 or greater, ideally Windows Server 2016)\nExperience with Node.js and Nginx.\nAbility to administer an SFTP server, add users, create keys/credentials'"
b'Data Engineer',b'Accenture',"b'San Diego, CA, US'","b""This role is located in either Sacramento or Los Angeles, CA, and relocation would be required if hired.\n\nWe are:\n\nApplied Intelligence, the people who love using data to tell a story. We\xe2\x80\x99re also the world\xe2\x80\x99s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything\xe2\x80\x94spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds?\nVisit us here to find out more about Applied Intelligence.\n\nYou Are:\n\nA Spark Big Data engineering pro\xe2\x80\x94someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. You\xe2\x80\x99re passionate about digital technology, and you take pride in making a tangible difference. You have communication and people skills in spades, along with strong leadership chops. Complex issues don\xe2\x80\x99t faze you thanks to your razor-sharp critical thinking skills. Working in an information systems environment makes you more than happy.\n\nThe Work:\n\nConsult as part of a team that is in charge of building end-to-end digital transformation capabilities and lead fast moving development teams using Agile methodologies.\nDesign and build Big Data and real-time analytics solutions using industry standard technologies and work with data architects to make sure Big Data solutions align with technology direction.\nLead by example, role-modeling best practices for unit testing, CI/CD, performance testing, capacity planning, documentation, monitoring, alerting and incident response.\nKeep everyone from individual contributors to top executives in the loop about progress, communicating across organizations and levels. If critical issues block progress, refer them up the chain of command to be resolved in a timely manner.\nOptimize NLU model by implementing NLP systems, performing intent classification and entity extraction and user testing.\nDevelop and maintain digital conversational flows, dialog research, Architect, Prototype and Test Dialogue Management system and Natural Language Generator Connect to data source (e.g. multiple xml documents) and query database.\nPinpoint and clarify key issues that need action, lead the response and articulate results clearly in actionable form.\nShow a strong aptitude for carrying out solutions and translating objectives into a scalable solution that meets end customers\xe2\x80\x99 needs within deadlines.\nCollaborate with research teams working on a variety of deep learning and NLP problems.\n\nHere's what you need:\n\nBachelor's degree in Computer Science, Engineering, Technical Science or 12 years of experience in programming and building large scale data/analytics solutions operating in production environments.\nMinimum 2+ years of expertise in designing, implementing large scale data pipelines for data curation, feature engineering and machine learning, using Spark in combination with pySpark, Java, Scala or Python; either on premise or on Cloud (AWS, Google or Azure).\nMinimum 1 year of designing and building performant data tiers (or refactoring existing ones), that supports scaled AI and Analytics, using different Cloud native data stores on AWS, Azure and Google (Redshift, S3, Big Query, SQLDW etc.) as well as using NoSQL and Graph Stores.\nMinimum 1 year of designing and building streaming data ingestion, analysis and processing pipelines using Kafka, Kafka Streams, Spark Streaming and similar cloud native technologies.\nBonus points if:\n\nMinimum 1 year of designing and building secured and governed Big Data ETL pipelines, using Talend or Informatica technologies; for data curation and analysis of large le production deployed solutions.\nExperience implementing smart data preparation tools such as Palate, Trifacta, Tamr for enhancing analytics solutions.\nMinimum 1 year of building Business Data Catalogs or Data Marketplaces for powering business analytics using technologies such as Alation, Collibra, Informatica or custom solutions.\n\nImportant Information:\n\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration. Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\n\nEqual Employment Opportunity:\n\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law. Job Candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\n\nAccenture is committed to providing veteran employment opportunities to our service men and women."""
b'Data Scientist',b'Realty Income Corporation',"b'San Diego, CA, US'","b""Description\n\nRealty Income, The Monthly Dividend Company\xc2\xae, one of four San Diego based S&P 500 companies dedicated to providing shareholders with dependable monthly income. Our company is structured as a REIT, and its monthly dividends are supported by the cash flow, over 6,000 real estate properties owned under long-term lease agreements with regional and national commercial tenants. To date, our company has declared over 600 consecutive common stock monthly dividends throughout its 50-year operating history and has continually increased the dividend since Realty Income's public listing in 1994 (NYSE: O). Our company attracts individuals who value integrity, perseverance, and teamwork. If you appreciate working on a truly collaborative team in a professional environment in a company that encourages a work-life balance, make sure to apply today!\n\nAs Realty Income\xe2\x80\x99s Data Scientist, you will be a ground-breaking leader who works as part of a team that builds and owns analytics-based assets, bringing the value of real estate predictive analytics to our business leaders. You will shape the future of a data-savvy organization, in part by driving processes for data extraction and analysis, and by creating new lines of thinking within our core real estate and investing business. In this role, you will design, develop and execute predictive analytics work streams that serve as the catalyst to increase ROI for the business.\n\nYour Contribution to the Team Includes\n\nPredictive Analytics\nBuild predictive analytics for use cases such as: Portfolio Management; Development; Acquisitions\nWork with business teams to identify, develop and deliver new use cases over time\nPrioritize predictive analytics initiatives based on multiple factors, e.g., ROI/productivity, business continuity, ease of delivery\nDeliver insights with user friendly end-products such as web-based tools, reports (e.g., Power BI) or visualizations that are accessible and understandable for business users\nEnsure we remain state of the art by keeping up on the latest technologies and approaches, attending conferences or other events as needed\nInfrastructure for Predictive Analytics\nCreate the vision for static and dynamic data architecture for predictive analytics encompassing internal data in our ERP system or other data sources as well as externally sourced data (e.g., census information news feeds)\nOversee the process for data management leveraging IT and business teams using clearly articulated responsibility matrices and timelines, including meeting internal audit requirements for data/process integrity\nCoordinate with the IT team to buy or license required tools, data and feeds\nWork with the IT team as they set up the necessary infrastructure and processes to support predictive analytics, e.g., ETL from the ERP system to data warehouse/lake\nDetermine how and when to take and store \xe2\x80\x9csnapshots\xe2\x80\x9d of data so that we can go back in time to test new models and approaches\nOrganizational Relationships\nWork closely with business teams, IT, internal audit and enterprise risk to define end products and processes\nCreate cross-functional working groups or teams as needed to initiate, approve or complete work\nUpdate the Investment Committee monthly or quarterly on key matters such as portfolio risk\nSupport business teams in the achievement of their objectives using predictive analytics tools\nPerforms other duties as assigned.\n\nRequirements\n\nWhat You\xe2\x80\x99ll Need to be Successful\nPHD Preferred in a relevant discipline, e.g., machine learning, statistics, applied mathematics, econometrics, or operations research\n3-5+ years of experience providing advanced analytics within a business setting\nPrior work experience within real estate or financial services is preferred, but not required\nProgramming experience in Python, Spark and SQL. Java/Scala is a plus\nExperience with RDBMS systems like PostgreSQL and NoSQL systems like MongoDB\nHands-on experience in Microsoft Azure and Amazon EC2 cloud platform\nDemonstrated ability to design and implement ETL workflows across both Windows and Linux environments\nAbility to clearly communicate ideas, orally or via written communications\nTo all recruitment agencies: Realty Income does not accept unsolicited agency resumes. Please do not forward resumes to our job\xe2\x80\x99s alias, Realty Income employees, or any company location. Realty Income is not responsible for any fees related to unsolicited resumes."""
b'Business Intelligence Analyst - Customer Experience and Analytics',b'BD',"b'San Diego, CA, US'","b'Job Description Summary\n\nBD\xe2\x80\x99s Global Customer Services (GCS) organization is transforming the customer experience on our journey to advance the world of health. The mission of the Customer Experience & Analytics team is to partner with GCS businesses to deliver actionable insights, resulting from analysis of Voice of the Customer (VOC) data and operational data, that drive meaningful improvement in customer and associate experience.\n\nWe are seeking a Business Intelligence Analyst, Customer Experience Analytics that will develop actionable research hypotheses, prepare and analyze datasets, develop predictive models, and present key findings to stakeholders in a clear way. This individual should be highly analytical and capable of truly understanding data to identify new opportunities and actionable insights that drive BD\xe2\x80\x99s customer experience. In addition to technical capabilities, this individual will be extremely collaborative and continuously seeking new opportunities in a consultative manner.\n\nJob Description\n\nJob Summary\n\nBD\xe2\x80\x99s Global Customer Services (GCS) organization is transforming the customer experience on our journey to advance the world of health. The mission of the Customer Experience & Analytics team is to partner with GCS businesses to deliver actionable insights, resulting from analysis of Voice of the Customer (VOC) data and operational data, that drive meaningful improvement in customer and associate experience.\n\nWe are seeking a Business Intelligence Analyst, Customer Experience Analytics that will develop actionable research hypotheses, prepare and analyze datasets, develop predictive models, and present key findings to stakeholders in a clear way. This individual should be highly analytical and capable of truly understanding data to identify new opportunities and actionable insights that drive BD\xe2\x80\x99s customer experience. In addition to technical capabilities, this individual will be extremely collaborative and continuously seeking new opportunities in a consultative manner.\n\nThe Core Responsibilities Include\nPartner with internal customers to understand stakeholder needs; translate business needs into analytical requirements that can be answered with available data using statistical and machine learning methods\nExtract and prepare data sets from various sources including Hadoop, SQL Server, flat files, etc\nDevelop visualizations to help explain patterns and trends in large data sets\nCommunicate analyses and results to executive leadership backed by data and coupled with actionable insights to drive business decisions\nRecognize and adopt industry best practices in reporting and analysis\nSupport the survey methodology of the NPS program, supported by Qualtrics, and capture insights\nDraw conclusions and prioritize actions/recommendations with limited data\n\nQualifications\nBachelor\xe2\x80\x99s or Master\xe2\x80\x99s degree in a quantitative field such as Data Science, Analytics, Computer Science Engineering, Systems Engineering, or Statistics\n3+ years of experience in a role requiring application of analytic skills to integrate data into operational/business planning\nStrong experience with BI tools (e.g., Power BI, Tableau), data extraction, data manipulation, and analysis; demonstrated strength using SQL queries in a business environment\nStrong quantitative and qualitative analytical skills with ability to distill large data sets into meaningful insights and takeaways\nStrong PowerPoint skills and ability to translate data insights into impactful presentations\nSuperior verbal and written communication skills with the ability to effectively advocate technical solutions to non-technical audiences\nAbility to cultivate and maintain productive working relationships with internal business partners and work successfully in a highly cross-functional matrix organization\nExtreme curiosity to understand business operations and data with a desire to work across groups to do so\nQualtrics and Salesforce experience a plus but not required\n\nPrimary Work Location\nUSA CA - San Diego Bldg A&B\n\nAdditional Locations\n\nWork Shift\n\nJob Category: Professional Services'"
b'Data Scientist',b'Broadcom Inc.',"b'San Diego, CA, US'","b'Job Description\n\nDo you enjoy analyzing data? Creating products that solve real-world problems and taking them into production? Working with colleagues to find novel ways to approach difficult problems in fintech?\n\nWe are looking for people with graduate degrees (MS or PhD) in an analytical field, e.g., Physics, Statistics, Electrical Engineering, Computer Science, Oceanography, Applied Mathematics, Data Science. You should understand how to apply mathematics to real-world problems, including linear algebra, vector calculus, etc.\n\nWe Are Looking For People Who\nHave strong scientific coding aptitude \xe2\x80\x93 efficient code that is numerically stable and of production quality.\nAre strong analytical thinkers, including reasoning through probabilities and statistics, as well as delving into detailed deterministic thinking and using individual examples\nCan learn new business domains, understanding the context for the data science\nCan learn and apply machine learning and AI techniques to new domains, with a focus on client needs\nHave interest in working from start to finish: gather data, clean and prepare, model, code, package, guide into production, and help clients use the results.\nEnjoy working with data.\nCan communicate complex and sophisticated ideas to people without scientific backgrounds\nEnjoy working in a team environment\n\nYou Will Be Responsible For\nWorking on problems in the fintech area, including online payments, banking, and other areas\nWorking on a team under the leadership of other Data Scientists\nCommunicating with clients, internal and external, to understand the business problems that we can solve using machine learning and AI\nAnalyzing and understanding data from different domains, including data cleansing and detailed analysis of relationships between fields\nDeveloping supervised, unsupervised, and reinforcement models in the laboratory\nCoding models for production, with particular attention to efficient use of computational resources and robustness of the code\nWorking with Software Engineers and SaaS Operations to package and deploy the models\nMonitoring the models to ensure that they are working properly, and generalizing to new data\nWorking with clients to ensure that they are using the results of the models effectively.\nSkills needed include: excellent written and verbal communications, and presentation skills.\n\nLanguages needed include a subset of: Python, C++, Unix scripting, SAS, PySpark, Scala, Perl, C\n\nStrong command of Unix is preferred.\n\nExperience (Data Scientist): Fresh Graduate degree holders are welcome to apply. Industry experience greatly appreciated.\n\nIf you are located outside USA, please be sure to fill out a home address as this will be used for future correspondence.'"
b'Data Scientist',b'HP',"b'San Diego, CA, US'","b""Data Scientist\n\nAs Data Scientist at HP Inc. in San Diego, you will join an industry-leading organization and work on developing frameworks for systematic data science modeling to identify optimal marketing, pricing and sales decisions for our Printing & PC business. Working within a dynamic, highly skilled and diverse Pricing Strategy and Analytics team (economists, engineers, scientists or even musicians ? majority of them with a PhD) you will build models and develop tools and analytical processes to develop pricing and marketing strategies for HP printers, cartridges and PCs around the world.\n\nResponsibilities\nDevelop and apply statistical methods to analyze the effect of pricing and sales decisions on business performance\nDevelop and implement frameworks and processes for systematic and automated data analysis\nDevelop tools to ingest, merge, and clean data sets\nImmerse yourself in very large data sets and complex problems\nVisualize and interpret the results of analyses, and create strategy recommendations\nPresent the results and the corresponding recommendations to the relevant stakeholders, including senior leadership\n\nQualifications\nInterest in data science, pricing, economics, and/or consumer behavior\nScientific thinking and ability to design and critically analyze quantitative research\nAbility to think creatively about research problems and invent original solutions to modeling challenges\nAbility to build and interpret complex linear regression models, with machine learning experience a plus\nKnowledge of and experience in deploying numerical optimization routines\nProficiency with Python and R is required\nStrong analytical skills, with a high level of attention to detail\nProficiency in Microsoft Excel and Microsoft PowerPoint\nExcellent written and verbal communication skills\n\nNice-To-Haves\nKnowledge of price optimization approaches, price discrimination models and a general knowledge of main concepts from the industrial organization literature\nExperience working with large data sets\nExperience in data engineering\nExposure to digital marketing\nExperience working in or collaborating with industry\nExperience creating data visualizations\nAbility to build dashboards and other tools using front-end development skills\nExperience in software development\n\nEducation & Experience\nBachelor?s, Master's or PhD degree in Engineering, Computer Science, Economics, Quantitative Marketing, Mathematics, Physics or equivalent\n1-3 years? experience including graduate or postgraduate research"""
b'Analytics Engineer',b'ICF',"b'San Diego, CA, US'","b'ICF is a premier provider of Full-spectrum cyberspace operations and analysis services to the Federal government. Our experts use analytics, machine learning and automation to identify and respond to network anolmalies, ensuring resiliency and mission assurance for our clients. We develop the next generation of Cyber Security for our clients, providing monitoring and active network defense of their networks.\n\nWe are seeking an Analytics Engineer to join our team supporting the Navy in San Diego\n\nExperience And Qualification Required\nCybersecurity Workforce (CSWF) IAT Level II\nStrong knowledge of scripting, programming or application programming interface\nSkills to develop extensibility to support diverse analytics for multiple use cases\nKnowledge of military and commercial data transports\nExperience in designing solution sets that operate in a low computational provide and in isolated environments\nExperience developing capabilities that quickly process and provide to end user critical data requests\nExperience in designing, developing, testing, implementing and maintaining large-scale data analytics techniques and technologies to include indexing techniques,information retrieval, data frameworks, machine learning, predictive analytics, data mining and statistical analysis\nExperience in developing analytics supporting cyber security use cases that supports decision aids at the strategic, operational and tactical levels of maritime warfare\nMinimum security clearance of TOP SECRET; ability to\nobtain TS/SCI clearance\n\nAnd Either\nMinimum of BS degree in related field and at least five (5) years of experience in skills identified above\nOR- Formal degree requirement may be evaluated and waived if applicant provides at least seven (7) years of experience in skills identified above\n\nWorking at ICF\n\nWorking at ICF means applying a passion for meaningful work with intellectual rigor to help solve the leading issues of our day. Smart, compassionate, innovative, committed, ICF employees tackle unprecedented challenges to benefit people, businesses, and governments around the globe. We believe in collaboration, mutual respect, open communication, and opportunity for growth. If you\xe2\x80\x99re seeking to make a difference in the world, visit www.icf.com/careers to find your next career. ICF\xe2\x80\x94together for tomorrow.\n\nICF is an equal opportunity employer that values diversity at all levels. (EOE \xe2\x80\x93 Minorities/Females/ Protected Veterans Status/Disability Status/Sexual Orientation/Gender Identity)\n\nReasonable Accommodations are available for disabled veterans and applicants with disabilities in all phases of the application and employment process. To request an accommodation please email and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: and .\n\nSan Diego, CA (CA74)'"
b'Data Scientist',b'National University',"b'San Diego, CA, US'","b'Position Summary\n\nUnder the direction of the VP, Chief Data Officer, the Data Scientist provides analytical leadership to support the data and analytical needs of the entire University. This position is responsible for developing and maintaining National University\xe2\x80\x99s analytical infrastructure to provide timely and reliable data for informed decision-making. In addition, the incumbent will apply advanced statistical, data mining, machine learning and various predictive modeling techniques to provide information, knowledge, coordination, and tools that support the growth and continued success of National University. The VP, Chief Data Officer provides general oversight concerning objectives and projects for this position and completes an annual evaluation of position.\n\nEssential Functions\nResponsible for the development, maintenance and advancement of National University\xe2\x80\x99s analytical\ninfrastructure.\nDevelop and maintain data extraction, transfer and loading from various sources.\nImplement appropriate security measures throughout the data pipeline.\nResponsible for maintaining metadata management and data quality activities so that data are accurate, reliable and documented.\nApply advanced predictive modeling, data mining, machine learning and statistical techniques to enable\ninformed decision-making, student support, and strategic initiatives.\nProvide analytical guidance to the entire University.\nFacilitate the transmission and understanding of data to enable fact-based decisions to various stakeholders, such as leadership, faculty and staff.\nProvide reliable and timely data that supports strategic planning, student success initiates, and educational and operational effectiveness.\nUtilize various software tools and reporting services to deliver actionable data to end-users in a digestible form\n\nSupervisory Responsibilities: NA\n\nRequirements\n\nEducation & Experience\nBachelor\xe2\x80\x99s degree in a related discipline (Statistics, Mathematics, Data Science, Social Sciences).\nAdvanced degree in a related field or evidence of pursuit of advanced studies or degree strongly preferred.\nOne to three (1-3) years of recent professional experience in data analysis and/or data engineering.\nTechnical / Functional Skills\nProficient in the following software applications: Microsoft Office Applications; Microsoft SQL Server; Microsoft\nAzure; Redmine; Peoplesoft/SOAR; Relational Database Management; Tableau/Power BI; and Statistical\nanalysis software (R, Python, or the equivalent) required.\nExperience and thorough knowledge in data collection and analysis techniques.\nCompetencies\nRequires analytic ability and frequent independent judgment based on knowledge of University policy and precedent.\nFluency in information technologies, including high level of proficiency and understanding with data mapping, data mining, machine learning, statistics, cloud computing and analytical programming languages such as SQL, R and/or Python.\nProven ability to independently synthesize, implement, analyze and report findings of research studies.\nExceptional interpersonal, organizational, and problem-solving skills as well as effective written and verbal communications.\nProven ability to troubleshoot problems and overcome obstacles with creative solutions.\nCapable of performing in a professional and friendly manner despite conditions of deadlines and pressure.\nKeen ability to transform vague requirements into clear, objective, and actionable tasks.\nFully accustomed to working on multiple projects, both independently and as a team member.\nSelf-starter with a positive attitude, intellectual curiosity and a passion for analytics\n\nPhysical Demands / Environment\n\nTravel: none required'"
b'Data Specialist',b'Veyo',b'Greater San Diego Area',"b'Veyo is using its platform and app-based transportation services to reinvent the medical logistics world. Our company is using technology to pioneer new operational models to help make transportation more powerful and more reliable for the healthcare industry.\n\nWhen you work at Veyo, you\xe2\x80\x99re helping to solve one of the nation\xe2\x80\x99s growing healthcare challenges -- ensuring patients get to and from their medical appointments, safely and on-time. We are using smart design and innovative technology to make patient transportation safer and more connected. In the process, we\xe2\x80\x99re transforming the entire industry.\n\nWhat you can expect:\nUse technology to help people lead healthier lives\nWork with an incredibly talented, intelligent team\nAbility to try out new technologies to gauge fit for business needs\nEncouragement to grow professionally and personally \xe2\x80\x93 attend conferences, give knowledge sharing presentations, pick your career path\n\nWhat we\xe2\x80\x99ll expect from you:\nBe committed to the health and safety of our passengers\nHelp shape the strategy and direction of the company and an industry\nSolve algorithmic problems in the logistics, healthcare and operations space through research, experiments and development and support deployment of these solutions into a real world environment\nEntrepreneurial. Everywhere you go, you can\xe2\x80\x99t help but mobilize people, build things, solve problems, roll up your sleeves, go above and beyond, raise the bar. You are an insatiable doer and driver\nAbility to effectively collaborate with and communicate complex concepts to both technical and non-technical audiences at all levels, from C-Level to individual contributors.\nUnderstand the latest industrial and academic developments in AI/ML, and apply it to create prototypes for demonstration\nWork with development teams to mature these algorithms into production quality programs\nDo applied research on a wide array of Operations research and machine learning projects.\n\nRequired Skills:\nAdvanced degree in Statistics, Applied Mathematics, Operations Research, Computer Science, or a related quantitative field.\n5+ years of experience crafting advanced models and familiar with statistical methods applied to large data sets\nProven experience with optimization libraries, scripting languages (Python, R, etc.), SQL and statistical tools, major object-oriented programming languages, and simulation software\nFamiliar with the Microsoft stack C#, .Net 4.5 is a plus\nFamiliarity with GoLang is a plus\n\n\nWe like the following personality traits: Friendly, social, outgoing, positive, passionate, cool under pressure, detail-oriented, deadline oriented, quick learner, multi-tasker, great sense of humor.\n\nWe\xe2\x80\x99re looking for people that love the opportunity to be involved in strategy and management at the top level, but also aren\xe2\x80\x99t scared to get their hands dirty and do what needs to be done to make things happen! We move quickly, and our team doesn\xe2\x80\x99t know the meaning of \xe2\x80\x9cnot my job.\xe2\x80\x9d We want people that want to get things done and can check their ego at the door.\n\nWe thank all applicants for their interest and effort in applying for this position. This position is only for candidates legally allowed to work in the US. EOE.\n\nVeyo is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.'"
b'Senior Software Engineer',b'The Recruiting Spa',b'Greater San Diego Area',"b""Join this 100 person company doing cutting edge work in Search and voice search platforms using Machine Learning.  \n\nMultiple openings for talented backend Java Engineers and Full Stack engineers (frontend focused) to deliver world-class search engine technologies. \n  Duties and Responsibilities:\nJava Role - Building the backend engine that runs the product. This includes extending our existing Machine Learning and Big Data pipelines and building entirely new capabilities, including: Big Data cluster, workflows and applications: data pipelines at scale, and real-time processing Machine learning and Data Scientist support: used in linguistics, ranking, classification, and other artificial intelligence applicationsIngestion Pipeline: process data that comes from our web crawler which discovers and fetches content from the web and other sources\nFrontend/Fullstack Role - Building the frontend of the product (we have our own custom framework), AND building frontend internal tools for our Machine Learning team\n\nSkills and Qualifications (Java):\nBS or MS degree in Computer Science\nSolid experience with Java programming (we also use Spring, Spring Webflux, Reactor, Netty)\nMulti-threading experience is a must\nExperience in scalable architectures and high-throughput application design\nComfortable in Linux and Windows environments.\nPrefer some experience with Big Data Technologies (at least one of the following):\nHadoop ecosystem (HDFS, Hadoop, Hive)\nSpark\nSamza\nKafka\nCassandra\nLucene NLP (Solr or ElasticSearch)\n\nSkills and Qualifications (Frontend):\n\nStrong Javascript\nSPA's\nReact/Redux (Minikube is a plus)\nFull-stack knowledge \n  The ideal candidates will be local to SoCal (We are located in North Coastal San DIego),  be self-motivated, possess excellent communication skills (both oral and written) and be able to work independently.\n   \n """
b'Machine Learning Engineering Manager',b'Mitchell International',"b'San Diego, California'","b'We are looking for a Machine Learning Engineering Manager having insatiable intellectual curiosity and passion about developing intelligent products and applying Computer Vision; Artificial Intelligence (Deep learning) and Machine learning techniques to solve real business problems in the P&C sector.\n As a ML Engineering Manager, Your primary focus will be to apply your experience in managing teams and Machine Learning knowledge in developing algorithmic solutions that combine techniques like clustering, Image based pattern mining, predictive modeling, deep learning, statistical Analysis, information retrieval, computer vision and natural language processing and apply them to vast amounts of data. You will help us analyze and discover information hidden in the vast amounts of data (Textual as well as Image), and help us make smarter decisions and deliver AI enabled products to our customers. \n You will be responsible to solve many challenging problems, including\nLeading engineering projects and a team of data scientists from inception to shipped software.\nBuilding models at scale using vast amounts of structured and unstructured heterogeneous types of data.\nEnsuring high accuracy based on industry\xe2\x80\x99s stringent requirements around precision or recall and with minimum Type I and Type II errors.\nGenerating predictions for millions of rows of data with high response time.\nDealing with high data diversity (vast amounts of data will need to be classified and will have multi labelled outcomes).\nDealing with very high dimensionality (expect to work on large matrix computations, variable transformation & feature engineering and selection using PCA and other novel ML techniques).\nDealing with noisy data (build models robust enough for unclassified and/or mislabeled data).\nYou will primarily work on,\nWorking collaboratively in coming up with strategy around labelling vast amounts of images as well as textual data.\nApplying ML techniques like collaborative filtering, bootstrap aggregation (bagging), Random Forest and Ensemble algorithms and generate statistically significant models.\nSelecting features, building and optimizing classifiers using machine learning techniques.\nData mining using state-of-the-art methods.\nExtending company\xe2\x80\x99s data with third party sources of information when needed.\nEnhancing data collection procedures to include information that is relevant for building analytic systems.\nProcessing, cleansing, and verifying the integrity of data used for analysis.\nDoing ad-hoc analysis and presenting results in a clear manner.\nCreating automated anomaly detection systems and constant tracking of its performance.\nBeing creative and going far beyond theoretical solutions to deal with challenges outlined.\nMeeting business requirements with domain knowledge into complex data analytical workflows and efficiently utilize expertise when needed to mitigate risk.\n\nQualifications\nYou must have\nConsistent track record of hiring, managing, and developing great Data Scientists and Engineers.\nDeep & broad understanding of machine learning theory, practice, and tools.\nPassionate problem solver, building the best solutions for the most important problems.\nAbility to communicate thoughtfully, leveraging problem-solving skills and a learning mindset to build long-term relationships.\nAt least 5+ years hands-on software development experience and applied machine learning experience.\nAt least 3+ years of engineering management experience.\nAt a Minimum - Master\xe2\x80\x99s Degree in Computer Science, Data Science, Mathematics or related field \nSound coding knowledge of scientific, distributed programming and scripting languages like Python, PyTorch, PySpark and/or Java.\nSolid foundation in statistics, machine learning, data structures, algorithms, and software design.\nExcellent understanding of machine learning, AI techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, Ensembles, Decisions Trees, and CNNs.\nExperience with common data science toolkits, such as Scikit-learn, MLLib, Google Inception, Google TensorFlow, Weka, NumPy, SciPy, MatLab, Excellence in at least three of these is highly desirable.\nProficiency in using query languages such as SQL, PL/SQL.\nExperience Big Data framework like Hadoop.\nGood applied statistics skills, such as distributions, statistical analysis and testing (T Test), and regression techniques.\nGreat communication skills and Data-oriented personality.\n\nPreferred Qualifications\nExperience with cloud framework like AWS SageMaker, GCP MLE as well as data visualization tools, such as D3.js, Tableau, Kibana, GGplot is a plus.\nFamiliarity of modern statistical learning methods & machine learning Frameworks like H2O, Spark, and PyTorch\nExperience working with cloud infrastructure like AWS, Azure and/or GCP.\nExperience with NoSQL databases, such as MongoDB, HBase is a plus\n  Mitchell International, an equal opportunity employer, values the diversity of our workforce and the knowledge of our people. Mitchell will not discriminate against an applicant or employee on the basis of race, color, religion, national origin, ancestry, sex/gender, age, physical or mental disability, military or veteran status, genetic information, sexual orientation, gender identity, gender expression, marital status, or any other characteristic protected by applicable federal, state or local law.'"
b'Machine Learning Engineer II',b'Zovio',"b'San Diego, CA, US'","b'Responsibilities\nParticipate in entire lifecycle for Business Intelligence Solution Delivery\nDesign, build, document and manage machine learning solutions and data warehouse objects\nDesign and develop ETL processes using SQL Server Integration Services\nDevelop predictive data models using R or other statistical language following the Machine Learning lifecycle\nResearch and improve features and machine learning models for production pipeline\nOperationalize the Machine Learning model in adherence with Data Warehouse principles integrating easily with Microsoft SQL Stack.\n\nRequirements\nMaster\xe2\x80\x99s Degree in Information Systems, Statistics or Computer Science\n1 year of experience in job offered or as Business Intelligence Engineer I or Business Intelligence Engineer II (or any combination thereof . Must have 1 year of experience (can be gained concurrently with the above experience) in the following: (1) developing machine learning solutions; (2) developing solutions using the MS SQL Server BI Stack; (3) using statistical computer languages include R and Python to manipulate data and draw insights from large data sets.\nMust have working knowledge of:\nSSIS and T-SQL\nAdvanced statistical methods (including regression, classification, and clustering) using machine learning algorithms (including decision tree learning, artificial neural networks, GLM and Random Forest).\nWork from home (home office required).\nBackground check required. Employer will accept any suitable combination of education, training or experience.\nEmployer: Zovio Inc. Job location: San Diego, CA. Qualified applicants should email resume to human.resources@zovio.com'"
b'Machine Learning Engineer',b'Big Cloud',b'Greater San Diego Area',"b""Work with industry experts in combining the best of deep learning and semiconductor design, to bring on-edge machine learning to listening devices.\n\nThis will improve efficiency and improving privacy, whilst lowering latency and saving bandwidth. Moving away from inference and training that is dependent on cloud or legacy data-centers, this company uses unique technology to accelerate toward processing on device.\n\nAs the first, implementation is on devices with listening capabilities, the company is looking for a strong engineer with the ability to implement speech and audio algorithms in high quality, seamless code.\n\nIf you\xe2\x80\x99re a passionate innovative engineer, excited about the future of deep learning then this is for you.\n\nThe company is well-funded, about to complete their series A, and are confident they have a homerun venture, exemplified by the interest by major technology companies who see the value of implementation into their hardware devices.\n\nResponsibilities:\nDesign and implement signal processing algorithms on devices that adopt microphone array to achieve the state-of-art speech recognition performance \n Design and implement robust acoustic modeling algorithms for adverse acoustic conditions, such as far-field, reverberant, and noisy environments\n\nQualifications:\nPh.D. or Master's degree in Computer Science, Electrical Engineering, Signal processing\nExperience with acoustic signal processing algorithms \nExperience with common signal processing and speech recognition toolkits \nExperience with deep learning frameworks\nExperience with building embedded systems is a plus \nPublication record in top speech conferences/journals is a plus\n\nKeywords: speech recognition, speech processing, audio signaling, acoustic signal processing, speaker verification, speech signal processing, long short term memory, lstm, ICASSP, Interspeech, language translation, noise suppression, multi-channel signal processing, acoustic echo cancellation, speech coding, audio coding, TTS, text-to-speech\n \n  Big Cloud is acting as a vendor to this position which is a direct hire."""
b'Machine Learning Performance Engineers',b'Qualcomm',"b'San Diego, CA, US'","b""Job Id\n\nJob Title\n\nMachine Learning Performance Engineers\n\nCompany\n\n\nDivision\n\nQualcomm Technologies, Inc.\n\n\nCorporate Research & Development\n\nJob Area\n\nEngineering - Systems\n\nLocation\n\nCalifornia - San Diego\n\nNorth Carolina - Raleigh\n\nOverview\n\nQualcomm is a company of inventors that unlocked 5G - ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5G\xe2\x80\x99s potential into world-changing technologies and products. This is the Invention Age - and this is where you come in. Qualcomm is utilizing its traditional strengths in digital wireless technologies to play a central role in the evolution of automotive infotainment and autonomous driving. We are investing in several supporting technologies including 4G, 5G, ADAS, and Deep Learning.\n\nThe Qualcomm CR&D team is developing hardware and software solutions for the Qualcomm ADAS system. We are seeking ambitious, bright and innovative engineers with experience in software system design, autonomy, device functional safety concepts and implementations.\n\nJob activities span the whole product life cycle from early R&D to commercial deployment. The environment is fast-paced and requires cross-functional interaction on a daily basis so good communication, planning and execution skills are a must.\n\nWe are looking to staff engineers at multiple levels in systems & software, integration and test. Details of one of the roles we are looking to staff are listed below.\n\nDesired Skills And Aptitudes\nExperience executing, analyzing, and optimizing neural networks in TensorFlow, Caffe2, PyTorch or similar frameworks\nBackground and understanding of neural network operators and mathematical operations: linear algebra, math libraries, desirable\nExperience with industry standard and emerging ML benchmark suites such as MLPerf desirable\nExperience / understanding of machine learning execution engines such as Glow, ONNX Runtime, or similar a plus\nExperience with machine learning accelerators and related software a plus\nStrong skills in analyzing performance of software/hardware solutions on multi-core architectures; understanding of multi-core architecture fundamentals (core, cache, memory, bus, PCIe, etc\xe2\x80\xa6)\nTarget specific code generation and optimization using LLVM or GCC compiler\nPerformance analysis, tuning, and debug using Linux-based profiling tools: perf events, hot-spots, call stacks, Ftrace\nUse of simulators, emulators, JTAG and serial debuggers, a plus\nStrong development skills in C++ and Python\nExcellent communication skills (written and verbal) and team player\n\nEducation Requirements\n\nRequired: Bachelor's, Computer Engineering and/or Electrical Engineering\nPreferred: Master's, Computer Engineering and/or Electrical Engineering\n\nKeywords"""
"b'Scientist, Data Science'",b'Johnson & Johnson',"b'San Diego, CA, US'","b'Janssen Research & Development LLC, a Johnson & Johnson company, is recruiting for a Scientist, Data Science located in La Jolla, CA or Spring House, PA with up to 15% domestic travel.\n\nThe R&D Data Science team within Janssen is looking for an outstanding scientist who is interested in designing, developing, and fielding impactful data science solutions. Our team supports projects from discovery through late development. The scientist will help identify viable data science opportunities and then conceive, develop and implement end to end data analytical solutions. The scientist will be someone who stays on the cutting edge of the data science field in order to implement novel algorithms that influence decisions at various levels in the organization. The role requires both a broad knowledge of existing machine learning algorithms and creativity to invent and customize when necessary. The scientist will be part of a multifaceted, accomplished team that supports multiple R&D therapeutic areas in the discovery and development of innovative medicines.\n\nKey Responsibilities\nWork with colleagues in research and development to design, build and deploy state-of-the art scientific algorithms to support Janssen R&D initiatives.\nAssemble large, complex data sets that meet functional / non-functional business requirements.\nDevelop and apply creative solutions that go beyond current tools to deliver data-driven insights to high-priority scientific problems.\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery.\nAdvocate transparency & action through data storytelling! Establish and execute strategies to increase usage and adoption of Data Science from project conceptualization to completion.\n\nQualifications\nPh.D degree (OR Master\xe2\x80\x99s degree with a minimum of 3 years of relevant experience) in Computer Science, Statistics, Machine Learning & Artificial Intelligence, Physics, Mathematics, Computational Chemistry, Bioinformatics, Computational Biology or a related discipline is required.\n\nRequired\n\nExperience and Skills:\nFamiliarity with large datasets, understanding of data analysis workflows, and/or knowledge of querying languages such as SQL is required.\nProficient with common data science toolkits, such as R, Pandas, TensorFlow, NumPy.\nStrong working knowledge of statistics, machine learning algorithms such as Random Forest, SVM, neural networks, etc. and/or Natural Language Processing techniques is required.\nExperience with visualization software/tools such as Python, R, D3.js, Spotfire, Tableau, etc.\nExperience with big data tools: Spark, Hadoop, Redshift, EMR.\nAbility to effectively communicate technical work to a wide audience.\n\nPrefered\nHandling of healthcare relevant datasets, such as EHR, genomics, clinical trials, insurance claims or registry data.\nExperience designing, developing and deployed web applications, microservices.\nFamiliarity with drug discovery and clinical development processes.\nExperience building processes supporting data transformation, data structures, metadata.\nWe will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\n\nJohnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.\n\nPrimary Location\nUnited States-California-San Diego-\nOther Locations\nNorth America-United States-Pennsylvania-Spring House\nOrganization\nJanssen Research & Development, LLC (6084)\nJob Function\nR&D\nRequisition ID\n2534200402'"
b'Staff Deep Learning/AI Engineer',b'Illumina',"b'San Diego, CA, US'","b'Position Summary\n\nThe Staff Deep Learning/AI Engineer in Illumina\xe2\x80\x99s Finance Performance Management group will focus on applying machine learning/deep learning techniques to finance and business applications. They will be part of analytics team developing machine learning/deep learning methods applied to financial and commercial datasets, with the goal of improving finance and accounting processes.\n\nResponsibilities\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of finance and accounting processes\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDeliver solutions leveraging latest machine learning (ML) techniques, including exploratory data analysis, feature engineering, model selection, model evaluation and cross-validation, and deployment and productionalization at all scales.\nUse predictive modeling to increase and optimize forecasting, revenue generation, and other business outcomes.\nDevelop company A/B testing framework and test model quality.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nMentor and scientifically lead junior members of the team\nBuild strong collaborative relationships with diverse groups within and outside of Illumina\nListed responsibilities are an essential, but not exhaustive list, of the usual duties associated with the position. Changes to individual responsibilities may occur due to business needs.\n\nRequirements\nExperience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\n5-7 years of experience manipulating data sets and building statistical models\nMaster\xe2\x80\x99s or PhD in Statistics, Mathematics, Computer Science or another quantitative field\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nExcellent written and verbal communication skills for coordinating across teams\nAll listed requirements are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional task and responsibilities.\nIllumina believes that everyone has the ability to make an impact, and we are proud to be an equal opportunity employer committed to providing employment opportunity regardless of sex, race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship status, and genetic information. If you require accommodation to complete the application or interview process, please contact accommodations@illumina.com. To learn more, visit: https://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf'"
b'SSD Machine Learning Engineer I (Temporary)',b'Kaiser Permanente',"b'San Diego, CA, US'","b""Description\n\nMachine Learning Engineer will provide technical direction, execution and support of machine learning strategies for the SCPMG Medical informatics group. The position entails designing and implementing data pipelining, integration, and optimization of machine learning models to address healthcare's triple aim: to improve the health of populations, to lower the cost of care, and to enhance the care experience.\n\nEssential Responsibilities\nUse statistical and machine learning techniques to develop and improve clinical decision support tools\nDesign and develop data pipelines for machine learning applications\nOptimize machine learning models to scale in real-time streaming applications\nIntegrate and deploy machine learning components in a production environment\nWork closely with machine learning scientists, physicians, and other stakeholders\nDeploy developed products to project environments.\nReview and provide practical feedback on group products and procedures.\nProvide technical feedback on team members' work.\nSeek out open-source software packages or existing software code that can be reused or applied to assigned tasks.\nProduce/archive process related artifacts such as design documents, test plans, wikis, and code review forms.\nExperience\n\nBasic Qualifications:\nMinimum two (2) years of programming or technical related experience.\nEducation\nB.S. in Computer Science, Informatics, Physics, Mathematics, Engineering or related fields.\nLicense, Certification, Registration\nN/A\nAdditional Requirements\nFamiliarity in the following languages, expert in at least one: Python, Java, SQL\nExperience with pipelining, workflow, and orchestration tools such as Apache Airflow, MLFlow, Kubeflow, Kubernates\nExperience with deep learning frameworks (e.g. Tensorflow)\nFamiliarity with classification and regression algorithms\nPreferred Qualifications\nDemonstrated experience in Natural Language Processing\nDemonstrated experience with machine learning integration and deployment in production environments\nDemonstrated experience with Tensorflow Serving or TensorRT\nFamiliarity with C++\nFamiliarity with writing custom CUDA\nExperience with source control tools for code and models/data\nFamiliarity with healthcare terminology\nM.S. in Computer Science, Informatics, Physics, Mathematics, Engineering or related fields.\nThis is a temporary position"""
b'Summer 2020 Machine Learning/HPC Co-Op/Intern - (78821)',b'AMD',"b'San Diego, CA, US'","b'What You Do At AMD Changes Everything\n\nAt AMD, we push the boundaries of what is possible. We believe in changing the world for the better by driving innovation in high-performance computing, graphics, and visualization technologies \xe2\x80\x93 building blocks for gaming, immersive platforms, and the data center.\n\nDeveloping great technology takes more than talent: it takes amazing people who understand collaboration, respect, and who will go the \xe2\x80\x9cextra mile\xe2\x80\x9d to achieve unthinkable results. It takes people who have the passion and desire to disrupt the status quo, push boundaries, deliver innovation, and change the world. If you have this type of passion, we invite you to take a look at the opportunities available to come join our team.\n\nMachine Learning/HPC Internship\n\nThe Role\n\nRTG (Radeon Technologies Group) Architecture team in San Diego is passionate about developing next-generation GPU solutions. As a Machine Learning/HPC architect, you will collaborate with a strong architecture and design team on developing next generation products for data centers and super-computers. You will engage in architecture exploration, modeling and analysis of ML/HPC workloads. Through your experiments and analysis, you will provide valuable insight into new and emerging hardware and software technologies.\n\nThe Person\n\nYou have excellent analytical and problem-solving skills, along with attention to detail. You are an effective team player who focuses on collaboration, team building, mentoring, and furthering team success. You have strong communication, time management, and presentation skills\n\nKey Responsibilities\nWork with architects to propose innovative solutions that can be implemented in SW/HW, validated by developing various models/simulators\nAnalyze HPC/ML workloads, identify performance bottlenecks and propose solutions\nCollect/summarize data or simulation results for consumption by architects and design teams\n\n\nPreferred Experience\nKnowledge of CPU architectures, basic knowledge of GPGPU architectures\nExcellent C/C++/Scripting (Python, etc.) skills\nKnowledge of Graphics/Compute APIs (CUDA/OpenCL/Vulkan etc.) is preferred\nHW/RTL/SystemC experience is a plus\nKnowledge of ML networks, Tensorflow/Pytorch is desirable\n\n\nAcademic Credentials\nBachelor of Science degree with emphasis in Electrical Engineering, Computer architecture, or Computer Science with relevant experience preferred, or\nMaster or PhD degree with emphasis in Electrical Engineering, Computer architecture, or Computer Science\n\n\nLOCATION:\n\nSan Diego, CA\n\nAMD does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services. AMD and its subsidiaries are equal opportunity employers and will consider all applicants without regard to race, marital status, sex, age, color, religion, national origin, veteran status, disability or any other characteristic protected by law. EOE/MFDV\n\nRequisition Number: 78821\nCountry: United States State: California City: San Diego\nJob Function: Student/ Intern/ Temp\n\nAMD does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services. AMD and its subsidiaries are equal opportunity employers. We consider candidates regardless of age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status. Please click here for more information.'"
b'Deep Learning Research Engineer',b'TuSimple',"b'San Diego, CA, US'","b'TuSimple was founded in 2015 with the goal of bringing the top minds in the world together to achieve the dream of a driverless truck solution. With a foundation in computer vision, algorithms, mapping, and AI, TuSimple is working to create the first commercially viable autonomous truck driving platform with L4 (SAE) levels of safety.\n\nJob Description\n\nOur deep learning team helps autonomous trucks sense and perceive the world. You will play an important role in creating novel algorithms for advanced perception and applying your algorithm on terabytes of data. You will also work closely with other talents in this field in building the next-generation of autonomous sensing algorithms.\n\nResponsibilities\nResearch and prototype developing using deep learning with a special focus on the perception problems of autonomous driving\n\n\nQualifications\nMS/PhD in Computer Science/Electrical Engineering\n3+ years of research or practical experience in applying deep learning on large scale and real world data\nKnowledge in deep learning topics including but not limited to detection, segmentation, 3D perception, and spatial-temporal analysis\nStrong coding skills in Python or C/C++\nFamiliar with at least one of the following deep learning frameworks: MXNET (preferred), TensorFlow, Pytorch, Caffe.\n\n\nPreferred\nTrack record of publishing in top-tier computer vision or machine learning conferences or/and journals.\nPrior academic or industrial experience in autonomous driving.\n\n\nPerks\nCompetitive salary and benefits\nWork with world class AI Engineers\nShape the landscape of autonomous driving\nDaily breakfast, lunch, and dinner\nFull kitchen with unlimited snacks and fruits\nMedical, Vision, and Dental insurance plan\nCompany 401(K) program\nCompany paid life insurance\n\nTuSimple is an Equal Opportunity Employer. This company does not discriminate in employment and personnel practices on the basis of race, sex, age, handicap, religion, national origin or any other basis prohibited by applicable law. Hiring, transferring and promotion practices are performed without regard to the above listed items.'"
b'Sr. Machine Learning Engineer',b'ServiceNow',"b'San Diego, CA, US'","b'Job Title: Senior Machine Learning Engineer\n\nCompany\n\nWork matters. It\xe2\x80\x99s where we spend a third of our lives. And the workplace of the future is going to be a great place. We\xe2\x80\x99re dedicated to bringing that to life for people everywhere. That\xe2\x80\x99s why we put people at the heart of everything we do.\n\nPeople matter. Our people have a passion for learning, building, and innovating. Whether you\xe2\x80\x99re an engineer, a sales professional, a finance professional, or anything in-between, our roles aim to provide each person with meaningful impact and plenty of space to grow.\n\nTeam\n\nCome join the Vulnerability Response Product Engineering team and work with a talented group of developers building best in class automated security orchestration in ServiceNow cloud platform. This team is responsible for the innovation, features, and architecture of products used by many Fortune 500 companies.\n\nRole\n\nAlmost 48% of organizations report that they have had a data breach in the past two years. As the severity and volume of attacks increase, the race to outpace attackers continues. Cybersecurity teams are not equipped enough to keep up and need to leverage the right tools to detect and patch in a timely manner.\n\n60% of breach victims said they were breached due to an unpatched known vulnerability where the patch was not applied\n62% were unaware that their organizations were vulnerable prior to the data breach\n52% of respondents say their organizations are at a disadvantage in responding to vulnerabilities because they use manual processes\n\nWith ServicerNow Vulnerability Response product, we replace manual tasks with automated security orchestration. By unifying the data and processes across IT and security teams, we enable them to prioritize and remediate vulnerabilities and security incidents faster. Using ServiceNow Vulnerability Response, vulnerabilities are patched 60% faster, triage time shrinks by 50% and the existing security and IT staff can handle 50% more workload.\n\nAs a Senior Machine Learning Engineer, you will play a major part in defining the strategy to use massive amounts of data, to prioritize, remediate and predict the vulnerabilities within an Enterprise to reduce and manage exposure to cyber security risk within an organization.\n\nWhat You Get To Do In This Role\nYou will build models against machine learning algorithms and collaborate with industry leading machine learning technologists to address new problem spaces within the ServiceNow ecosystem.\nYou will join a team that takes pride in building extensible and resilient engineering solutions.\nYou will work closely with Product Managers and customers to understand detailed requirements.\nYou will own your solution from design, implementation, automation, delivery and validation with our users.\nYou will define machine learning application strategies and architecture to support these strategies.\nYou will collaborate with an energetic team of like-minded developers, product managers and quality engineers using agile software development methodology.\nYou will work closely with the ServiceNow SaaS platform team on understanding the platform capabilities and extending those capabilities to meet the unique challenges and needs of Vulnerability Response product.\nYou will troubleshoot problems encountered by customers and provide resolutions.\n\nIn order to be successful in this role, we need someone who has:\n6+ years of experience in architecture, design and development of enterprise-grade applications in a high transaction environment.\n2+ years and/or machine learning experience\nKnowledge of Machine Learning algorithms\nStrong understanding of Object-Oriented Analysis, Design Patterns, Data Structures, and time and space-efficient and high performing algorithms\nPassion for software development and problem solving\nHigh energy, self-starter with aptitude for learning new technologies\nKnowledge of Java & JavaScript technologies, with excellent understanding of JavaScript frameworks as Angular, React, Node.js.\nExpert in building RESTful services, and data exchange formats as XML and JSON.\nSolid experience with open source technologies Linux, Apache, Selenium.\nIn-depth knowledge of relational databases (e.g. PostgreSQL, MySQL) and NoSQL databases (e.g. MongoDB)\nExceptional debugging including browser-based debugging, testing, and problem-solving skills.\nExceptional written and verbal communication skills with proven ability to effectively communicate complex technical issues to both technical and non-technical teams.\nPassion for software development, problem-solving, and learning new technologies.\nStrong educational background in Computer Science, Machine Learning, or Mathematics fields, prefer MS/PhD\n\nNote that an exact match on skills is less critical than strong design instincts, high quality coding discipline and enthusiasm for taking on an ambitious project that will reshape the way people interact with enterprise software.\n\nEEOE Statement Section\n\nServiceNow\xe2\x80\x99s EEOE statement is automatically added to each U.S. based job description.'"
b'Deep Learning Research Scientist / Engineer (Deep Learning & Algorithms)',b'Samsung Electronics America',"b'San Diego, CA, US'","b""Description\n\nPosition at Samsung Semiconductor, Inc.\n\nJOB TITLE\n\nResearch Engineer-Deep Learning Theory and Algorithms\n\nRequisition ID\n\nDSA31988\n\nOverview\n\nSamsung Semiconductor, Inc. in San Diego is searching for research engineers at all levels. Candidate will work as part of a team on research and development of algorithms and theory of machine learning. Candidate will research fundamental theoretical aspects of deep learning as well as develop novel techniques to advance the theory and practice of deep learning. Candidate can also apply the developed theory and algorithms to advance the performance of multimedia applications, such as computer vision, augmented reality, natural language processing, or speech processing.\n\nJob Responsibilities\nUnderstand state of the art machine/deep learning concepts, theory, and applications.\nResearch algorithms and theory of learning.\nDevelop machine/deep learning algorithms for mobile processors.\nDevelop simulators and analyze the performance.\nProduce key intellectual property for machine/deep learning.\n\nRequired Skills\nStrong analytical and problem-solving skills\nExpertise in machine/deep learning, optimization, probability theory, statistical inference, information theory, signal processing, and/or image processing\nExcellent communication and teamwork skills\nC/C++, Python, and/or MATLAB coding skills\nPublications in highly ranked journals and conferences\nPhD is required\n\nPreferred Skills\nExperience on popular deep learning frameworks\n*********************************************************************************************************************** Samsung Semiconductor Inc (SSI), an equal opportunity employer, is a world leader in Memory, System LSI, and LCD technologies. Headquartered in San Jose, California, SSI is a wholly-owned U.S. subsidiary of Samsung Electronics Co., Ltd.- the second largest semiconductor manufacturer in the world and the industry's volume and technology leader in DRAM, NAND Flash, SSDs, mobile DRAM and graphics memory. It is one of the largest providers of system logic, imaging and LED lighting solutions, as well as providing advanced process design and manufacturing for fabless companies. Samsung Semiconductor, Inc. also has a research and innovation center with numerous labs providing product design and research in: logic, memory, image sensors, displays and mobile technologies. In addition, the company supports Samsung Display Company, the largest producer of LCD and OLED displays. ***********************************************************************************************************************\n\nLearn more about Samsung Semiconductor here.\n\nA day in the life Samsung Video\n\nSamsung Semiconductor Career Page"""
b'Machine Learning Scientist',b'Amazon',"b'San Diego, CA, US'","b'Description\n\nHave you ever wanted to work on machine learning challenges that will make a lasting impact on society? How about solving key problems that impact the experience of millions of Amazon customers?\n\nAmazon is looking for brilliant Machine Learning Scientists who have the passion to tackle tough problems and help shape a new product from the very early stages in the online grocery shopping space. Together, with a multi-disciplinary team of scientists, engineers, economists, product managers, and subject domain experts, you will help define our customer experience with machine learning at its core. You will define the research and experiment strategy with an iterative approach to create machine learning models and progressively improve the results over time. We are looking for candidates who thrive in fast paced environments and want to invent the future.\n\n\nBasic Qualifications\nPhD or Masters degree in Applied Math, Data Science, Computer Science, Engineering, Machine Learning (or in a highly related field)\n5+ years of hands-on industry experience in predictive modeling, algorithm development, and big data analytics\n5+ year of experience in building machine learning models deployed to production environments\nExperience in applying fundamental machine learning algorithms to solve complex problems\nExperience with modifying standard algorithms (e.g. changing objectives, working-out the math, implementing and scaling)\n7+ years in one or more major programming languages (Python, Java, C++, C, Perl/Ruby, etc.)\nPreferred Qualifications\nPhD in Computer Science, Applied Math, Data Science, Engineering, Machine Learning (or in a highly related field)\n7+ years of hands-on industry experience in predictive modeling, algorithm development and big data analytics\nExtensive experience applying theoretical models in an applied environment\nMastery in fundamentals of problem solving, algorithm design and complexity analysis\nStrong interpersonal and communication skills -- the ability to explain technical concepts and analysis implications clearly to a wide audience, including senior executives, and translate business objectives into action\nAmazon.com is an Equal Opportunity-Affirmative Action Employer \xe2\x80\x93 Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation\n\n\nCompany - Amazon.com Services LLC\nJob ID: A1037013'"
b'Deep Machine Learning Engineer',b'CyberCoders Middleware Test Compay',"b'San Diego, CA, US'","b""Happy New Year!\nBased in the San Diego, CA area, we are one of the most innovative Image solutions companies in the World. We are well-funded with premiere clients who are utilizing us to solve the most challenging image issues we currently face. Our team is composed of experts in the world of machine learning and image processing with a leadership team that brings experiences from leading global scientific technology firms and pride themselves in their hands-on, mentor level management style. If you are a strong Deep Learning / Machine Learning Scientist with experience in Python OR Java OR C and, obviously, Machine Learning expertise, we would welcome the opportunity to discuss the details.....What You Need for this PositionRequirements:\n- 3+ years of Deep / Machine Learning experience\n- Master's Degree or PhD HIGHLY preferred. Points if you have published papers on the same topics.\n- Supervised and Unsupervised machine learning a must\n- Timeseries and/or Deep Learning a big plus\n- Algorithm development experience\n- Communicates very well\n- Research type\n- Excellent communication and written skills\n\nNice to have skills:\n- Strong interest in creating solutions to problems\n- Experience in and interest in learning new technologies\n- Experience managing multiple projects and working independentlyTop Reasons to Work with UsFast growing.\nWell-funded.\nStart-up equity.What's In It for YouWe are willing to offer excellent compensation packages including annualized pay potential of $110k to around $135k, plus EQUITY, and excellent benefits. We are located in a centrally located area with access to 2 major freeways, and plenty of parking.So, if you are a recent PHD grad, or PHD grad with experience in Machine Learning, please apply today!\n\n*** You can also email me directly at eric.shaner@cybercoders.com\n*** Find/connect with me on LinkedIn - www.linkedin.com/in/analytics\nDesired Skills and Experience\nLinear, Non-linear, Deep Learning, Supervised Techniques, Timeseries Analysis, UnSupervised Techniques"""
b'Data Scientist - Statistics and Machine Learning',b'Q-Centrix',"b'San Diego, CA, US'","b'Who are we? Q-Centrix is a leading healthcare information solutions provider with offices in Portsmouth, NH, Chicago, and San Diego, plus more than 900 clinical experts working remotely in 49 states. Our team of smart, ambitious, and fun-loving healthcare professionals are 100% focused on improving the quality of patient care at hospitals throughout the country.\n\nAbout the Job Q-Centrix is looking for a Junior Data Scientist to join us at our San Diego office. We are a data driven and automation focused organization that loves to gain new insights from the massive amount of structured and unstructured data that is collected on a daily basis.\n\nAs a Data Scientist, You Will\nWork on various projects ranging from statistical analysis, data pipelines, machine learning, and advanced signal processing to software engineering\nWrite complete softwares to implement domain agnostic generalized mathematical models that could be deployed on any data\nWork closely with leaders across the organization to look for workflow automation opportunities and execute them\nBuild advanced software solutions that will help prepare the data for analytics projects\nLeverage your experience working with supervised machine learning methods such as ensemble tree classifiers, support vector machines, neural networks, and Bayesian methods to create state-of-the-art predictive models\nCommunicate your successful efforts through documentation and white papers\nKnowledge, Skills, Abilities And Qualification Requirements\nM.S. in Applied Mathematics, Computer Science, or Electrical Engineering and 3+ years of prior experience working as a Data Scientist, machine learning engineer, or data engineer is required\n3+ year of hands-on experience in software engineering, deep learning, and signal processing is highly desired\nQuality Requirements\nPositively contribute to our work environment values of professionalism, mutual respect, teamwork, and collaboration.\nKey Competencies\nProfessionalism and customer service orientation\nAbility to manage multiple projects\nPlanning, organization and excellent time management\nAttention to detail and unrelenting passion for delivery\nFlexibility, adaptability, and teamwork\nYou\xe2\x80\x99re Our Dream Candidate If You\nLove solving business problems with mathematics and programming\nHave a proven track record for writing world class software solutions with Python, Ruby, Java, or Go\nAre passionate about automation and consider yourself an advanced python software developer\nBuilt and operationalized signal processing solutions\nAre intimately familiar with the latest techniques in predictive data modeling including deep learning\nLove data science competitions and are an active participant in kaggle competitions\nLove writing detailed documentation of your completed research, and lastly,\nYou love dogs and cats!\nWho are we?\n\nAt Q-Centrix, we hire people who love learning, value innovation and believe in our mission and values to improve outcomes in healthcare. We applaud qualified applicants who are accountable and committed to producing quality work. As an Equal Opportunity Employer, we support and value diversity, dignity and respect in our work environment, and are committed to creating an inclusive environment in which everyone can thrive.\n\nWe employ people based on the needs of the business and the job, and their individual professional qualifications. Here\xe2\x80\x99s what does not impact our employment decisions: race, religious creed, religion, color, sex, sexual orientation, pregnancy, parental status, genetic information, gender, gender identity, gender expression, age, national origin, ancestry, citizenship, protected veteran or disability status, health, marital, civil union or domestic partnership status, or any status or characteristic protected by the laws or regulations in locations where we operate. If you are an individual with a qualified disability and you need an accommodation during the interview process, please reach out to your recruiter.\n\nWe celebrate and embrace these differences, and take pride in our commitment to being an equal opportunity team.'"
b'Software Engineer',b'PointPredictive Inc.',"b'San Diego, California'","b'We are looking for a junior to mid-level software engineer, whose core skills being Python and experience with Amazon Web Services in Our San Diego Offices.\n\nThis person will act as a generalist supporting senior staff, and will contribute in the following areas:\n\nHelp optimize Python analytics applications and AWS infrastructure for performance.\nBuild-out a robust software testing and release pipeline.\nDevelop automated code tests.\nResearch and develop production monitoring tools.\nContribute partially in a DevOps role.\nDevelop production-level data pipelines for company-critical data science and machine learning solutions\nDevelop tooling, optimization, and testing around core data science work\nBuild and maintain production-level python libraries for the data science team\nLeverage open-source tools and cloud computing technologies comfortably\nExecute best practices in version control and continuous integration/delivery\nOwn and drive projects from conception to completion \n\nIdeally, prior experience includes:\n\n1-5 years as software engineer, with Python as a primary language. Familiar with the Pandas library would be helpful.\nSome experience working in an analytics or data science environment, or exposure to machine-learning.\n1-5 years experience with several AWS services, preferably some of Lambda, EC2, S3, Cloudwatch, API Gateway, and S3.\n1-2 years experience with relational (MySQL, PostgresQL) and NoSql databases (AWS Dynamo DB, MongoDB).\nFamiliarity with version control principles, ideally git.\n\nBonus Points for:\n\nKnowledge of AWS Networking: Virtual Private Cloud (VPC), Subnets, Network Address Translation (NAT) services.\nWindows developer or system administrator skills (Windows Server 2012 or greater, ideally Windows Server 2016)\nExperience with Node.js and Nginx.\nAbility to administer an SFTP server, add users, create keys/credentials'"
b'Data Engineer',b'Accenture',"b'San Diego, CA, US'","b""This role is located in either Sacramento or Los Angeles, CA, and relocation would be required if hired.\n\nWe are:\n\nApplied Intelligence, the people who love using data to tell a story. We\xe2\x80\x99re also the world\xe2\x80\x99s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything\xe2\x80\x94spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds?\nVisit us here to find out more about Applied Intelligence.\n\nYou Are:\n\nA Spark Big Data engineering pro\xe2\x80\x94someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. You\xe2\x80\x99re passionate about digital technology, and you take pride in making a tangible difference. You have communication and people skills in spades, along with strong leadership chops. Complex issues don\xe2\x80\x99t faze you thanks to your razor-sharp critical thinking skills. Working in an information systems environment makes you more than happy.\n\nThe Work:\n\nConsult as part of a team that is in charge of building end-to-end digital transformation capabilities and lead fast moving development teams using Agile methodologies.\nDesign and build Big Data and real-time analytics solutions using industry standard technologies and work with data architects to make sure Big Data solutions align with technology direction.\nLead by example, role-modeling best practices for unit testing, CI/CD, performance testing, capacity planning, documentation, monitoring, alerting and incident response.\nKeep everyone from individual contributors to top executives in the loop about progress, communicating across organizations and levels. If critical issues block progress, refer them up the chain of command to be resolved in a timely manner.\nOptimize NLU model by implementing NLP systems, performing intent classification and entity extraction and user testing.\nDevelop and maintain digital conversational flows, dialog research, Architect, Prototype and Test Dialogue Management system and Natural Language Generator Connect to data source (e.g. multiple xml documents) and query database.\nPinpoint and clarify key issues that need action, lead the response and articulate results clearly in actionable form.\nShow a strong aptitude for carrying out solutions and translating objectives into a scalable solution that meets end customers\xe2\x80\x99 needs within deadlines.\nCollaborate with research teams working on a variety of deep learning and NLP problems.\n\nHere's what you need:\n\nBachelor's degree in Computer Science, Engineering, Technical Science or 12 years of experience in programming and building large scale data/analytics solutions operating in production environments.\nMinimum 2+ years of expertise in designing, implementing large scale data pipelines for data curation, feature engineering and machine learning, using Spark in combination with pySpark, Java, Scala or Python; either on premise or on Cloud (AWS, Google or Azure).\nMinimum 1 year of designing and building performant data tiers (or refactoring existing ones), that supports scaled AI and Analytics, using different Cloud native data stores on AWS, Azure and Google (Redshift, S3, Big Query, SQLDW etc.) as well as using NoSQL and Graph Stores.\nMinimum 1 year of designing and building streaming data ingestion, analysis and processing pipelines using Kafka, Kafka Streams, Spark Streaming and similar cloud native technologies.\nBonus points if:\n\nMinimum 1 year of designing and building secured and governed Big Data ETL pipelines, using Talend or Informatica technologies; for data curation and analysis of large le production deployed solutions.\nExperience implementing smart data preparation tools such as Palate, Trifacta, Tamr for enhancing analytics solutions.\nMinimum 1 year of building Business Data Catalogs or Data Marketplaces for powering business analytics using technologies such as Alation, Collibra, Informatica or custom solutions.\n\nImportant Information:\n\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration. Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\n\nEqual Employment Opportunity:\n\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law. Job Candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\n\nAccenture is committed to providing veteran employment opportunities to our service men and women."""
b'Data Scientist',b'Realty Income Corporation',"b'San Diego, CA, US'","b""Description\n\nRealty Income, The Monthly Dividend Company\xc2\xae, one of four San Diego based S&P 500 companies dedicated to providing shareholders with dependable monthly income. Our company is structured as a REIT, and its monthly dividends are supported by the cash flow, over 6,000 real estate properties owned under long-term lease agreements with regional and national commercial tenants. To date, our company has declared over 600 consecutive common stock monthly dividends throughout its 50-year operating history and has continually increased the dividend since Realty Income's public listing in 1994 (NYSE: O). Our company attracts individuals who value integrity, perseverance, and teamwork. If you appreciate working on a truly collaborative team in a professional environment in a company that encourages a work-life balance, make sure to apply today!\n\nAs Realty Income\xe2\x80\x99s Data Scientist, you will be a ground-breaking leader who works as part of a team that builds and owns analytics-based assets, bringing the value of real estate predictive analytics to our business leaders. You will shape the future of a data-savvy organization, in part by driving processes for data extraction and analysis, and by creating new lines of thinking within our core real estate and investing business. In this role, you will design, develop and execute predictive analytics work streams that serve as the catalyst to increase ROI for the business.\n\nYour Contribution to the Team Includes\n\nPredictive Analytics\nBuild predictive analytics for use cases such as: Portfolio Management; Development; Acquisitions\nWork with business teams to identify, develop and deliver new use cases over time\nPrioritize predictive analytics initiatives based on multiple factors, e.g., ROI/productivity, business continuity, ease of delivery\nDeliver insights with user friendly end-products such as web-based tools, reports (e.g., Power BI) or visualizations that are accessible and understandable for business users\nEnsure we remain state of the art by keeping up on the latest technologies and approaches, attending conferences or other events as needed\nInfrastructure for Predictive Analytics\nCreate the vision for static and dynamic data architecture for predictive analytics encompassing internal data in our ERP system or other data sources as well as externally sourced data (e.g., census information news feeds)\nOversee the process for data management leveraging IT and business teams using clearly articulated responsibility matrices and timelines, including meeting internal audit requirements for data/process integrity\nCoordinate with the IT team to buy or license required tools, data and feeds\nWork with the IT team as they set up the necessary infrastructure and processes to support predictive analytics, e.g., ETL from the ERP system to data warehouse/lake\nDetermine how and when to take and store \xe2\x80\x9csnapshots\xe2\x80\x9d of data so that we can go back in time to test new models and approaches\nOrganizational Relationships\nWork closely with business teams, IT, internal audit and enterprise risk to define end products and processes\nCreate cross-functional working groups or teams as needed to initiate, approve or complete work\nUpdate the Investment Committee monthly or quarterly on key matters such as portfolio risk\nSupport business teams in the achievement of their objectives using predictive analytics tools\nPerforms other duties as assigned.\n\nRequirements\n\nWhat You\xe2\x80\x99ll Need to be Successful\nPHD Preferred in a relevant discipline, e.g., machine learning, statistics, applied mathematics, econometrics, or operations research\n3-5+ years of experience providing advanced analytics within a business setting\nPrior work experience within real estate or financial services is preferred, but not required\nProgramming experience in Python, Spark and SQL. Java/Scala is a plus\nExperience with RDBMS systems like PostgreSQL and NoSQL systems like MongoDB\nHands-on experience in Microsoft Azure and Amazon EC2 cloud platform\nDemonstrated ability to design and implement ETL workflows across both Windows and Linux environments\nAbility to clearly communicate ideas, orally or via written communications\nTo all recruitment agencies: Realty Income does not accept unsolicited agency resumes. Please do not forward resumes to our job\xe2\x80\x99s alias, Realty Income employees, or any company location. Realty Income is not responsible for any fees related to unsolicited resumes."""
b'Business Intelligence Analyst - Customer Experience and Analytics',b'BD',"b'San Diego, CA, US'","b'Job Description Summary\n\nBD\xe2\x80\x99s Global Customer Services (GCS) organization is transforming the customer experience on our journey to advance the world of health. The mission of the Customer Experience & Analytics team is to partner with GCS businesses to deliver actionable insights, resulting from analysis of Voice of the Customer (VOC) data and operational data, that drive meaningful improvement in customer and associate experience.\n\nWe are seeking a Business Intelligence Analyst, Customer Experience Analytics that will develop actionable research hypotheses, prepare and analyze datasets, develop predictive models, and present key findings to stakeholders in a clear way. This individual should be highly analytical and capable of truly understanding data to identify new opportunities and actionable insights that drive BD\xe2\x80\x99s customer experience. In addition to technical capabilities, this individual will be extremely collaborative and continuously seeking new opportunities in a consultative manner.\n\nJob Description\n\nJob Summary\n\nBD\xe2\x80\x99s Global Customer Services (GCS) organization is transforming the customer experience on our journey to advance the world of health. The mission of the Customer Experience & Analytics team is to partner with GCS businesses to deliver actionable insights, resulting from analysis of Voice of the Customer (VOC) data and operational data, that drive meaningful improvement in customer and associate experience.\n\nWe are seeking a Business Intelligence Analyst, Customer Experience Analytics that will develop actionable research hypotheses, prepare and analyze datasets, develop predictive models, and present key findings to stakeholders in a clear way. This individual should be highly analytical and capable of truly understanding data to identify new opportunities and actionable insights that drive BD\xe2\x80\x99s customer experience. In addition to technical capabilities, this individual will be extremely collaborative and continuously seeking new opportunities in a consultative manner.\n\nThe Core Responsibilities Include\nPartner with internal customers to understand stakeholder needs; translate business needs into analytical requirements that can be answered with available data using statistical and machine learning methods\nExtract and prepare data sets from various sources including Hadoop, SQL Server, flat files, etc\nDevelop visualizations to help explain patterns and trends in large data sets\nCommunicate analyses and results to executive leadership backed by data and coupled with actionable insights to drive business decisions\nRecognize and adopt industry best practices in reporting and analysis\nSupport the survey methodology of the NPS program, supported by Qualtrics, and capture insights\nDraw conclusions and prioritize actions/recommendations with limited data\n\nQualifications\nBachelor\xe2\x80\x99s or Master\xe2\x80\x99s degree in a quantitative field such as Data Science, Analytics, Computer Science Engineering, Systems Engineering, or Statistics\n3+ years of experience in a role requiring application of analytic skills to integrate data into operational/business planning\nStrong experience with BI tools (e.g., Power BI, Tableau), data extraction, data manipulation, and analysis; demonstrated strength using SQL queries in a business environment\nStrong quantitative and qualitative analytical skills with ability to distill large data sets into meaningful insights and takeaways\nStrong PowerPoint skills and ability to translate data insights into impactful presentations\nSuperior verbal and written communication skills with the ability to effectively advocate technical solutions to non-technical audiences\nAbility to cultivate and maintain productive working relationships with internal business partners and work successfully in a highly cross-functional matrix organization\nExtreme curiosity to understand business operations and data with a desire to work across groups to do so\nQualtrics and Salesforce experience a plus but not required\n\nPrimary Work Location\nUSA CA - San Diego Bldg A&B\n\nAdditional Locations\n\nWork Shift\n\nJob Category: Professional Services'"
b'Data Scientist',b'Broadcom Inc.',"b'San Diego, CA, US'","b'Job Description\n\nDo you enjoy analyzing data? Creating products that solve real-world problems and taking them into production? Working with colleagues to find novel ways to approach difficult problems in fintech?\n\nWe are looking for people with graduate degrees (MS or PhD) in an analytical field, e.g., Physics, Statistics, Electrical Engineering, Computer Science, Oceanography, Applied Mathematics, Data Science. You should understand how to apply mathematics to real-world problems, including linear algebra, vector calculus, etc.\n\nWe Are Looking For People Who\nHave strong scientific coding aptitude \xe2\x80\x93 efficient code that is numerically stable and of production quality.\nAre strong analytical thinkers, including reasoning through probabilities and statistics, as well as delving into detailed deterministic thinking and using individual examples\nCan learn new business domains, understanding the context for the data science\nCan learn and apply machine learning and AI techniques to new domains, with a focus on client needs\nHave interest in working from start to finish: gather data, clean and prepare, model, code, package, guide into production, and help clients use the results.\nEnjoy working with data.\nCan communicate complex and sophisticated ideas to people without scientific backgrounds\nEnjoy working in a team environment\n\nYou Will Be Responsible For\nWorking on problems in the fintech area, including online payments, banking, and other areas\nWorking on a team under the leadership of other Data Scientists\nCommunicating with clients, internal and external, to understand the business problems that we can solve using machine learning and AI\nAnalyzing and understanding data from different domains, including data cleansing and detailed analysis of relationships between fields\nDeveloping supervised, unsupervised, and reinforcement models in the laboratory\nCoding models for production, with particular attention to efficient use of computational resources and robustness of the code\nWorking with Software Engineers and SaaS Operations to package and deploy the models\nMonitoring the models to ensure that they are working properly, and generalizing to new data\nWorking with clients to ensure that they are using the results of the models effectively.\nSkills needed include: excellent written and verbal communications, and presentation skills.\n\nLanguages needed include a subset of: Python, C++, Unix scripting, SAS, PySpark, Scala, Perl, C\n\nStrong command of Unix is preferred.\n\nExperience (Data Scientist): Fresh Graduate degree holders are welcome to apply. Industry experience greatly appreciated.\n\nIf you are located outside USA, please be sure to fill out a home address as this will be used for future correspondence.'"
b'Data Scientist',b'HP',"b'San Diego, CA, US'","b""Data Scientist\n\nAs Data Scientist at HP Inc. in San Diego, you will join an industry-leading organization and work on developing frameworks for systematic data science modeling to identify optimal marketing, pricing and sales decisions for our Printing & PC business. Working within a dynamic, highly skilled and diverse Pricing Strategy and Analytics team (economists, engineers, scientists or even musicians ? majority of them with a PhD) you will build models and develop tools and analytical processes to develop pricing and marketing strategies for HP printers, cartridges and PCs around the world.\n\nResponsibilities\nDevelop and apply statistical methods to analyze the effect of pricing and sales decisions on business performance\nDevelop and implement frameworks and processes for systematic and automated data analysis\nDevelop tools to ingest, merge, and clean data sets\nImmerse yourself in very large data sets and complex problems\nVisualize and interpret the results of analyses, and create strategy recommendations\nPresent the results and the corresponding recommendations to the relevant stakeholders, including senior leadership\n\nQualifications\nInterest in data science, pricing, economics, and/or consumer behavior\nScientific thinking and ability to design and critically analyze quantitative research\nAbility to think creatively about research problems and invent original solutions to modeling challenges\nAbility to build and interpret complex linear regression models, with machine learning experience a plus\nKnowledge of and experience in deploying numerical optimization routines\nProficiency with Python and R is required\nStrong analytical skills, with a high level of attention to detail\nProficiency in Microsoft Excel and Microsoft PowerPoint\nExcellent written and verbal communication skills\n\nNice-To-Haves\nKnowledge of price optimization approaches, price discrimination models and a general knowledge of main concepts from the industrial organization literature\nExperience working with large data sets\nExperience in data engineering\nExposure to digital marketing\nExperience working in or collaborating with industry\nExperience creating data visualizations\nAbility to build dashboards and other tools using front-end development skills\nExperience in software development\n\nEducation & Experience\nBachelor?s, Master's or PhD degree in Engineering, Computer Science, Economics, Quantitative Marketing, Mathematics, Physics or equivalent\n1-3 years? experience including graduate or postgraduate research"""
b'Analytics Engineer',b'ICF',"b'San Diego, CA, US'","b'ICF is a premier provider of Full-spectrum cyberspace operations and analysis services to the Federal government. Our experts use analytics, machine learning and automation to identify and respond to network anolmalies, ensuring resiliency and mission assurance for our clients. We develop the next generation of Cyber Security for our clients, providing monitoring and active network defense of their networks.\n\nWe are seeking an Analytics Engineer to join our team supporting the Navy in San Diego\n\nExperience And Qualification Required\nCybersecurity Workforce (CSWF) IAT Level II\nStrong knowledge of scripting, programming or application programming interface\nSkills to develop extensibility to support diverse analytics for multiple use cases\nKnowledge of military and commercial data transports\nExperience in designing solution sets that operate in a low computational provide and in isolated environments\nExperience developing capabilities that quickly process and provide to end user critical data requests\nExperience in designing, developing, testing, implementing and maintaining large-scale data analytics techniques and technologies to include indexing techniques,information retrieval, data frameworks, machine learning, predictive analytics, data mining and statistical analysis\nExperience in developing analytics supporting cyber security use cases that supports decision aids at the strategic, operational and tactical levels of maritime warfare\nMinimum security clearance of TOP SECRET; ability to\nobtain TS/SCI clearance\n\nAnd Either\nMinimum of BS degree in related field and at least five (5) years of experience in skills identified above\nOR- Formal degree requirement may be evaluated and waived if applicant provides at least seven (7) years of experience in skills identified above\n\nWorking at ICF\n\nWorking at ICF means applying a passion for meaningful work with intellectual rigor to help solve the leading issues of our day. Smart, compassionate, innovative, committed, ICF employees tackle unprecedented challenges to benefit people, businesses, and governments around the globe. We believe in collaboration, mutual respect, open communication, and opportunity for growth. If you\xe2\x80\x99re seeking to make a difference in the world, visit www.icf.com/careers to find your next career. ICF\xe2\x80\x94together for tomorrow.\n\nICF is an equal opportunity employer that values diversity at all levels. (EOE \xe2\x80\x93 Minorities/Females/ Protected Veterans Status/Disability Status/Sexual Orientation/Gender Identity)\n\nReasonable Accommodations are available for disabled veterans and applicants with disabilities in all phases of the application and employment process. To request an accommodation please email and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: and .\n\nSan Diego, CA (CA74)'"
b'Data Scientist',b'National University',"b'San Diego, CA, US'","b'Position Summary\n\nUnder the direction of the VP, Chief Data Officer, the Data Scientist provides analytical leadership to support the data and analytical needs of the entire University. This position is responsible for developing and maintaining National University\xe2\x80\x99s analytical infrastructure to provide timely and reliable data for informed decision-making. In addition, the incumbent will apply advanced statistical, data mining, machine learning and various predictive modeling techniques to provide information, knowledge, coordination, and tools that support the growth and continued success of National University. The VP, Chief Data Officer provides general oversight concerning objectives and projects for this position and completes an annual evaluation of position.\n\nEssential Functions\nResponsible for the development, maintenance and advancement of National University\xe2\x80\x99s analytical\ninfrastructure.\nDevelop and maintain data extraction, transfer and loading from various sources.\nImplement appropriate security measures throughout the data pipeline.\nResponsible for maintaining metadata management and data quality activities so that data are accurate, reliable and documented.\nApply advanced predictive modeling, data mining, machine learning and statistical techniques to enable\ninformed decision-making, student support, and strategic initiatives.\nProvide analytical guidance to the entire University.\nFacilitate the transmission and understanding of data to enable fact-based decisions to various stakeholders, such as leadership, faculty and staff.\nProvide reliable and timely data that supports strategic planning, student success initiates, and educational and operational effectiveness.\nUtilize various software tools and reporting services to deliver actionable data to end-users in a digestible form\n\nSupervisory Responsibilities: NA\n\nRequirements\n\nEducation & Experience\nBachelor\xe2\x80\x99s degree in a related discipline (Statistics, Mathematics, Data Science, Social Sciences).\nAdvanced degree in a related field or evidence of pursuit of advanced studies or degree strongly preferred.\nOne to three (1-3) years of recent professional experience in data analysis and/or data engineering.\nTechnical / Functional Skills\nProficient in the following software applications: Microsoft Office Applications; Microsoft SQL Server; Microsoft\nAzure; Redmine; Peoplesoft/SOAR; Relational Database Management; Tableau/Power BI; and Statistical\nanalysis software (R, Python, or the equivalent) required.\nExperience and thorough knowledge in data collection and analysis techniques.\nCompetencies\nRequires analytic ability and frequent independent judgment based on knowledge of University policy and precedent.\nFluency in information technologies, including high level of proficiency and understanding with data mapping, data mining, machine learning, statistics, cloud computing and analytical programming languages such as SQL, R and/or Python.\nProven ability to independently synthesize, implement, analyze and report findings of research studies.\nExceptional interpersonal, organizational, and problem-solving skills as well as effective written and verbal communications.\nProven ability to troubleshoot problems and overcome obstacles with creative solutions.\nCapable of performing in a professional and friendly manner despite conditions of deadlines and pressure.\nKeen ability to transform vague requirements into clear, objective, and actionable tasks.\nFully accustomed to working on multiple projects, both independently and as a team member.\nSelf-starter with a positive attitude, intellectual curiosity and a passion for analytics\n\nPhysical Demands / Environment\n\nTravel: none required'"
b'Data Specialist',b'Veyo',b'Greater San Diego Area',"b'Veyo is using its platform and app-based transportation services to reinvent the medical logistics world. Our company is using technology to pioneer new operational models to help make transportation more powerful and more reliable for the healthcare industry.\n\nWhen you work at Veyo, you\xe2\x80\x99re helping to solve one of the nation\xe2\x80\x99s growing healthcare challenges -- ensuring patients get to and from their medical appointments, safely and on-time. We are using smart design and innovative technology to make patient transportation safer and more connected. In the process, we\xe2\x80\x99re transforming the entire industry.\n\nWhat you can expect:\nUse technology to help people lead healthier lives\nWork with an incredibly talented, intelligent team\nAbility to try out new technologies to gauge fit for business needs\nEncouragement to grow professionally and personally \xe2\x80\x93 attend conferences, give knowledge sharing presentations, pick your career path\n\nWhat we\xe2\x80\x99ll expect from you:\nBe committed to the health and safety of our passengers\nHelp shape the strategy and direction of the company and an industry\nSolve algorithmic problems in the logistics, healthcare and operations space through research, experiments and development and support deployment of these solutions into a real world environment\nEntrepreneurial. Everywhere you go, you can\xe2\x80\x99t help but mobilize people, build things, solve problems, roll up your sleeves, go above and beyond, raise the bar. You are an insatiable doer and driver\nAbility to effectively collaborate with and communicate complex concepts to both technical and non-technical audiences at all levels, from C-Level to individual contributors.\nUnderstand the latest industrial and academic developments in AI/ML, and apply it to create prototypes for demonstration\nWork with development teams to mature these algorithms into production quality programs\nDo applied research on a wide array of Operations research and machine learning projects.\n\nRequired Skills:\nAdvanced degree in Statistics, Applied Mathematics, Operations Research, Computer Science, or a related quantitative field.\n5+ years of experience crafting advanced models and familiar with statistical methods applied to large data sets\nProven experience with optimization libraries, scripting languages (Python, R, etc.), SQL and statistical tools, major object-oriented programming languages, and simulation software\nFamiliar with the Microsoft stack C#, .Net 4.5 is a plus\nFamiliarity with GoLang is a plus\n\n\nWe like the following personality traits: Friendly, social, outgoing, positive, passionate, cool under pressure, detail-oriented, deadline oriented, quick learner, multi-tasker, great sense of humor.\n\nWe\xe2\x80\x99re looking for people that love the opportunity to be involved in strategy and management at the top level, but also aren\xe2\x80\x99t scared to get their hands dirty and do what needs to be done to make things happen! We move quickly, and our team doesn\xe2\x80\x99t know the meaning of \xe2\x80\x9cnot my job.\xe2\x80\x9d We want people that want to get things done and can check their ego at the door.\n\nWe thank all applicants for their interest and effort in applying for this position. This position is only for candidates legally allowed to work in the US. EOE.\n\nVeyo is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.'"
"b'AWS DevOps, DataOps, and Cloud Engineering Consultant'",b'Hitachi Vantara',"b'San Diego, CA, US'","b'The Company\n\nHitachi Vantara, a wholly owned subsidiary of Hitachi, Ltd., helps data-driven leaders use the value in their data to innovate intelligently and reach outcomes that matter for business and society \xe2\x80\x93 what we call a double bottom line. Only Hitachi Vantara combines 100+ years of experience in operational technology (OT) and 60+ years in IT to unlock the power of data from your business, your people and your machines. We help enterprises store, enrich, activate and monetize data for better customer experiences, new revenue streams and lower business costs.\n\n47Lining, a part of Hitachi Vantara is an AWS Premier Consulting Partner with Big Data and Machine Learning Competency designations. We develop big data solutions and deliver big data managed services built from underlying AWS building blocks like Amazon Redshift, Kinesis, S3, DynamoDB, Machine Learning and Elastic MapReduce. We help customers build, operate and manage breathtaking \xe2\x80\x9cData Machines\xe2\x80\x9d for their data-driven businesses. We architect solutions that address traditional data warehousing, Internet-of-Things analytics back-ends, predictive analytics and machine learning to open up new business opportunities. Our experience spans use cases in multiple industries including industrial, manufacturing, oil & gas, energy, life sciences, gaming, retail analytics, financial services and media & entertainment.\n\nThe Role\n\nWe are seeking experienced and versatile AWS Software Engineering Consultants to develop data and analytics services and solutions in AWS. The ideal contributor will work with a skilled team to develop, deploy, and operate enterprise-grade data platform services and infrastructure on the AWS platform, spanning ingest of IoT and other enterprise data sources, Big Data, machine learning and predictive analytics.\n\n47Lining is growing at an exponential rate and can only grow as quickly as we are able to find the right talent.\xe2\x80\x82We pay extremely competitive salaries, bonuses, free training and conference attending budget, flexible hours and we have a genuinely extremely talented team.\n\nResponsibilities\nHands-on experience developing advanced analytics in SQL, R, Spark or similar tools\nWork with AWS architectures, development, and deployment\nBuild with enterprise-scale data warehouse technologies (Teradata, Oracle, SQL Data Warehouse, Vertica, Redshift)\nExperience managing applications in AWS and familiarity with core services including EC2, S3, RDS, etc.\nExposure to networking & load balancing solutions\nREST API design and development\nWork across all layers of an application, from back-end databases through UI\nCollaborate with development teams to deliver high-quality results\nUse Agile / Scrum development methodology\nSystem decomposition, architecture, design, and specification\n\n\nQualifications\nExperience with deployment automation tools like Puppet, Chef, and Ansible\nGood working knowledge of Big Data technologies such as Hadoop, Hive, Spark\nProficient with SQL databases and knowledge of standard methodologies\nStrong experience with middle-tier web services development (REST APIs)\nStrong background in commercial-grade software development with Java, Python, SQL\nFront End Application Development (Application Views & Controller)\nDomain Entity and Behavior Modeling, Design, and Implementation\n3rd-party application, service and data integration\nData Management, Mapping, Translation & Persistence\nLarge-scale Data Management & Workflow\nAnalytic development and automation\nExcellent documentation habits\n\nWe are an equal opportunity employer. All applicants will be considered for employment without attention to age, race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.'"
"b'Temp Scientist, GMP/Data Review'",b'Neurocrine Biosciences',"b'San Diego, CA, US'","b'Who We Are\n\nAt Neurocrine Biosciences, we pride ourselves on having a strong, distinctive and positive culture based on our shared purpose and values. We know what it takes to be great, and we are as passionate about our people as we are about our purpose - to relieve patient suffering and enhance lives.\n\nWhat We Do\n\nNeurocrine Biosciences (Nasdaq: NBIX) is a neuroscience-focused, biopharmaceutical company with more than 25 years of experience discovering and developing life-changing treatments for people with serious, challenging and under-addressed neurological, endocrine and psychiatric disorders. Headquartered in San Diego, Neurocrine Biosciences specializes in targeting and interrupting disease-causing mechanisms involving the interconnected pathways of the nervous and endocrine systems.\n\nThe company\xe2\x80\x99s diverse portfolio includes two FDA-approved treatments INGREZZA\xc2\xae (valbenazine) for tardive dyskinesia and ORILISSA\xc2\xae (elagolix) for endometriosis*, as well as clinical development programs in multiple therapeutic areas, including Parkinson\xe2\x80\x99s disease, chorea in Huntington disease, congenital adrenal hyperplasia, uterine fibroids* and polycystic ovary syndrome.* As part of a strategic collaboration with Voyager Therapeutics, Neurocrine Biosciences is also focused on the development of investigational gene therapy programs for the treatment of severe neurological diseases, including Parkinson\xe2\x80\x99s disease and Friedreich\xe2\x80\x99s ataxia. (*in collaboration with AbbVie)\n\nAbout the Role:\n\nThis temporary opportunity within the Analytical Development group will support the Manager, Stability Coordination in all aspects of stability operations of clinical and commercial materials (drug substance / drug product).\n_\n\nYour Contributions (include, But Are Not Limited To)\nOversees stability program schedules, implementation, and management for studies conducted by Contracted Service Providers (CSP).\nCreates, reviews, and/or approves batch specific stability study protocols, summary tables, reports, and raw data as appropriate.\nDetermines stability sample requirements through review of test methods, specifications, and project plans to ensure adequate materials are placed in the stability chambers to support product characterization and expiry dating.\nMaintains schedule of stability pulls, testing deadlines, and reporting deadlines. Monitors stability program execution.\nEstablishes Quality Metrics; tracks, trends, and follows-up on quality events, deviations, or any applicable nonconformance.\nEscalate any Out of Specification / Trend (OOS/OOT) results, notifications, or observations according to the applicable Neurocrine SOP.\nPrepares stability data graphs, evaluates stability trends and prepares retest period estimations for clinical trial / development materials and extensions of commercial product retest/expiry dating.\nEnsures stability studies for commercial products are in accordance with current guidances, i.e. ICH, FDA, USP, and WHO, and are aligned with submission stability commitments.\nSupports the maintenance or extension of commercial product retest/expiry dating in collaboration with Commercial Manufacturing.\nRequirements:\nBS Degree in chemistry or closely related field with a minimum of 4 years of experience\nIndustry experience in Pharmaceutical or Medical Device development, manufacturing, or quality control / quality assurance\nKnowledge of a GMP manufacturing environment\nHighly motivated, self-starter with excellent oral and written communication skills\nMust have previous analytical laboratory experience\nHigh level of numeracy; experience in statistical analysis, kinetic analysis, and / or experimental design\nStrong organizational skills and the ability to multi-task\nEnthusiasm for developing an expanding technical and theoretical knowledge base\nFamiliarity with Lean Stability concepts and non-isothermal kinetic analysis is desirable.\nNeurocrine Biosciences is an EEO/AA/Disability/Vets employer.'"
b'Azure Data Architect',b'Perficient',"b'San Diego, CA, US'","b""Overview\n\nAt Perficient you\xe2\x80\x99ll deliver mission-critical technology and business solutions to Fortune 500 companies and some of the most recognized brands on the planet. And you\xe2\x80\x99ll do it with cutting-edge technologies, thanks to our close partnerships with the world\xe2\x80\x99s biggest vendors. Our network of offices across North America, as well as locations in India and China, will give you the opportunity to spread your wings, too.\n\nWe\xe2\x80\x99re proud to be publicly recognized as a \xe2\x80\x9cTop Workplace\xe2\x80\x9d year after year. This is due, in no small part, to our entrepreneurial attitude and collaborative spirit that sets us apart and keeps our colleagues impassioned, driven, and fulfilled.\n\nPerficient currently has a career opportunity for a Senior Azure Solutions Architect.\n\nJob Overview\n\nOne of our large clients has made strategic decision to move all their Hospital management data to a new Azure environment for processing and analytics. This is a multiyear roadmap with many components that will piece into a larger Enterprise level Azure implementation. Perficient subject matter expert will work with the client team to move this data into new environment in a fashion that will meet requirements for applications and analytics.\n\nA Senior Solutions Architect is expected to be knowledgeable in two or more technologies within (a given Solutions/Practice area). The Solutions Architect may or may not have a programming background, but will have expert infrastructure architecture, client presales / presentation, team management and thought leadership skills.\n\nYou will provide best-fit architectural solutions for one or more projects; you will assist in defining scope and sizing of work; and anchor Proof of Concept developments. You will provide solution architecture for the business problem, platform integration with third party services, designing and developing complex features for clients' business needs. You will collaborate with some of the best talent in the industry to create and implement innovative high quality solutions, participate in Sales and various pursuits focused on our clients' business needs.\n\nYou will also contribute in a variety of roles in thought leadership, mentorship, systems analysis, architecture, design, configuration, testing, debugging, and documentation. You will challenge your leading edge solutions, consultative and business skills through the diversity of work in multiple industry domains. This role is considered part of the Business Unit Senior Leadership team and may mentor junior architects and other delivery team members.\n\nResponsibilities\nOwn and aggressively drive forward specific areas of Azure technology architecture and provide architectural solutions/designs to project execution teams for implementation.\nProvide architectural assessments, strategies, and roadmaps for one or more technologies including ADLS and Synapse (formerly knows as ADW)\nLead workshops with many teams to define data ingestion, validation, mining, engineering, modeling, visualization, AI, and analytics\nDesign and Build Azure Data services including ADF, ADL, AMM, ADLS, ADW, Power BI, AML, ABS, and other services within the Azure data framework\nLead the technical planning & requirements gathering phases including estimate, develop, test, manage projects, architect and deliver complex projects\nParticipate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT associates\nContribute to the thought capital through the creation of executive presentations, architecture documents and articulate them to executives through presentations Determine Project and solution estimation and team structure definition\nSupport multiple Agile Scrum teams with planning, scoping and creation of technical solutions for the new product capabilities, through to continuous delivery to production.\nProvide end to end vision and hands on experience with Azure Cloud Platform\nProvide vision and leadership to define the core technologies necessary to meet client needs including: development tools and methodologies, package solutions, systems architecture, security techniques, and emerging technologies\nLiaise with offshore team and clients for resolving technical dependencies, issues, and risks.\nMentor and provide architectural guidance to multiple teams building innovative applications.\nDrive common vision, practices and capabilities across teams.\nEngage with business stakeholders to understand required capabilities, integrating business knowledge with technical solutions\nEngage with Technical Architects and technical staff to determine the most appropriate technical strategy and designs to meet business needs\nDemonstrate broad solutions technical leadership, impacting significant technical direction, exerting influence outside of the immediate team and driving change\n\nQualifications\nAt least 10+ years of experience in designing, architecting and implementing large scale data processing/data storage/data distribution systems particularly in Azure\nMost recent 2+ years of experience in delivering large scale Azure projects\nAt least 5+ years real time and streaming experience in Azure based data solutions\nAt least 3+ years in presales and demo using Azure data services including ADW and ADLS\nAt least 5+ years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms\nAt least 5+ years of demonstrated experience at least in the most recent 2+ years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio\nShould have experience designing service management, orchestration, monitoring and management requirements of cloud platform.\nAt least 3+ years of experience in migrating large volumes of data using standard Azure automation tools from on premise and cloud infrastructure to Azure\nAbility to produce high quality work products under pressure and within deadlines with specific references\nVERY strong communication, solutioning, and client facing skills especially non-technical business users\nAt least 5+ years of working with large multi-vendor environment with multiple teams and people as a part of the project\nAt least 2+ year of working with Power BI\nAt least 5+ years of working with a complex Big Data environment using Microsoft tools\n5+ years of experience with Team Foundation Server/JIRA/GitHub and other code management toolsets\n\nPreferred Skills And Education\n\nMaster\xe2\x80\x99s degree in Computer Science or related field\n\nCertification in Azure platform\n\nPerficient full-time employees receive complete and competitive benefits. We offer a collaborative work environment, competitive compensation, generous work/life opportunities and an outstanding benefits package that includes paid time off plus holidays. In addition, all colleagues are eligible for a number of rewards and recognition programs including billable bonus opportunities. Encouraging a healthy work/life balance and providing our colleagues great benefits are just part of what makes Perficient a great place to work.\n\nMore About Perficient\n\nPerficient is the leading digital transformation consulting firm serving Global 2000 and enterprise customers throughout North America. With unparalleled information technology, management consulting and creative capabilities, Perficient and its Perficient Digital agency deliver vision, execution and value with outstanding digital experience, business optimization and industry solutions.\n\nOur work enables clients to improve productivity and competitiveness; grow and strengthen relationships with customers, suppliers and partners; and reduce costs. Perficient's professionals serve clients from a network of offices across North America and offshore locations in India and China. Traded on the Nasdaq Global Select Market, Perficient is a member of the Russell 2000 index and the S&P SmallCap 600 index.\n\nPerficient is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national, origin, disability status, protected veteran status, or any other characteristic protected by law.\n\nDisclaimer: The above statements are not intended to be a complete statement of job content, rather to act as a guide to the essential functions performed by the employee assigned to this classification. Management retains the discretion to add or change the duties of the position at any time.\n\nOptions\n\nApply for this job online Apply\n\nShare\n\nRefer this job to a friend Refer\n\nSorry the Share function is not working properly at this moment. Please refresh the page and try again later.\n\nShare on your newsfeed\n\nSelect work authorization questions to ask when applicants apply\n\nAre you legally authorized to work in the United States?\nWill you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?"""
b'Machine Learning Engineer',b'Big Cloud',b'Greater San Diego Area',"b""Work with industry experts in combining the best of deep learning and semiconductor design, to bring on-edge machine learning to listening devices.\n\nThis will improve efficiency and improving privacy, whilst lowering latency and saving bandwidth. Moving away from inference and training that is dependent on cloud or legacy data-centers, this company uses unique technology to accelerate toward processing on device.\n\nAs the first, implementation is on devices with listening capabilities, the company is looking for a strong engineer with the ability to implement speech and audio algorithms in high quality, seamless code.\n\nIf you\xe2\x80\x99re a passionate innovative engineer, excited about the future of deep learning then this is for you.\n\nThe company is well-funded, about to complete their series A, and are confident they have a homerun venture, exemplified by the interest by major technology companies who see the value of implementation into their hardware devices.\n\nResponsibilities:\nDesign and implement signal processing algorithms on devices that adopt microphone array to achieve the state-of-art speech recognition performance \n Design and implement robust acoustic modeling algorithms for adverse acoustic conditions, such as far-field, reverberant, and noisy environments\n\nQualifications:\nPh.D. or Master's degree in Computer Science, Electrical Engineering, Signal processing\nExperience with acoustic signal processing algorithms \nExperience with common signal processing and speech recognition toolkits \nExperience with deep learning frameworks\nExperience with building embedded systems is a plus \nPublication record in top speech conferences/journals is a plus\n\nKeywords: speech recognition, speech processing, audio signaling, acoustic signal processing, speaker verification, speech signal processing, long short term memory, lstm, ICASSP, Interspeech, language translation, noise suppression, multi-channel signal processing, acoustic echo cancellation, speech coding, audio coding, TTS, text-to-speech\n \n  Big Cloud is acting as a vendor to this position which is a direct hire."""
b'Machine Learning Performance Engineers',b'Qualcomm',"b'San Diego, CA, US'","b""Job Id\n\nJob Title\n\nMachine Learning Performance Engineers\n\nCompany\n\n\nDivision\n\nQualcomm Technologies, Inc.\n\n\nCorporate Research & Development\n\nJob Area\n\nEngineering - Systems\n\nLocation\n\nCalifornia - San Diego\n\nNorth Carolina - Raleigh\n\nOverview\n\nQualcomm is a company of inventors that unlocked 5G - ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5G\xe2\x80\x99s potential into world-changing technologies and products. This is the Invention Age - and this is where you come in. Qualcomm is utilizing its traditional strengths in digital wireless technologies to play a central role in the evolution of automotive infotainment and autonomous driving. We are investing in several supporting technologies including 4G, 5G, ADAS, and Deep Learning.\n\nThe Qualcomm CR&D team is developing hardware and software solutions for the Qualcomm ADAS system. We are seeking ambitious, bright and innovative engineers with experience in software system design, autonomy, device functional safety concepts and implementations.\n\nJob activities span the whole product life cycle from early R&D to commercial deployment. The environment is fast-paced and requires cross-functional interaction on a daily basis so good communication, planning and execution skills are a must.\n\nWe are looking to staff engineers at multiple levels in systems & software, integration and test. Details of one of the roles we are looking to staff are listed below.\n\nDesired Skills And Aptitudes\nExperience executing, analyzing, and optimizing neural networks in TensorFlow, Caffe2, PyTorch or similar frameworks\nBackground and understanding of neural network operators and mathematical operations: linear algebra, math libraries, desirable\nExperience with industry standard and emerging ML benchmark suites such as MLPerf desirable\nExperience / understanding of machine learning execution engines such as Glow, ONNX Runtime, or similar a plus\nExperience with machine learning accelerators and related software a plus\nStrong skills in analyzing performance of software/hardware solutions on multi-core architectures; understanding of multi-core architecture fundamentals (core, cache, memory, bus, PCIe, etc\xe2\x80\xa6)\nTarget specific code generation and optimization using LLVM or GCC compiler\nPerformance analysis, tuning, and debug using Linux-based profiling tools: perf events, hot-spots, call stacks, Ftrace\nUse of simulators, emulators, JTAG and serial debuggers, a plus\nStrong development skills in C++ and Python\nExcellent communication skills (written and verbal) and team player\n\nEducation Requirements\n\nRequired: Bachelor's, Computer Engineering and/or Electrical Engineering\nPreferred: Master's, Computer Engineering and/or Electrical Engineering\n\nKeywords"""
"b'Scientist, Data Science'",b'Johnson & Johnson',"b'San Diego, CA, US'","b'Janssen Research & Development LLC, a Johnson & Johnson company, is recruiting for a Scientist, Data Science located in La Jolla, CA or Spring House, PA with up to 15% domestic travel.\n\nThe R&D Data Science team within Janssen is looking for an outstanding scientist who is interested in designing, developing, and fielding impactful data science solutions. Our team supports projects from discovery through late development. The scientist will help identify viable data science opportunities and then conceive, develop and implement end to end data analytical solutions. The scientist will be someone who stays on the cutting edge of the data science field in order to implement novel algorithms that influence decisions at various levels in the organization. The role requires both a broad knowledge of existing machine learning algorithms and creativity to invent and customize when necessary. The scientist will be part of a multifaceted, accomplished team that supports multiple R&D therapeutic areas in the discovery and development of innovative medicines.\n\nKey Responsibilities\nWork with colleagues in research and development to design, build and deploy state-of-the art scientific algorithms to support Janssen R&D initiatives.\nAssemble large, complex data sets that meet functional / non-functional business requirements.\nDevelop and apply creative solutions that go beyond current tools to deliver data-driven insights to high-priority scientific problems.\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery.\nAdvocate transparency & action through data storytelling! Establish and execute strategies to increase usage and adoption of Data Science from project conceptualization to completion.\n\nQualifications\nPh.D degree (OR Master\xe2\x80\x99s degree with a minimum of 3 years of relevant experience) in Computer Science, Statistics, Machine Learning & Artificial Intelligence, Physics, Mathematics, Computational Chemistry, Bioinformatics, Computational Biology or a related discipline is required.\n\nRequired\n\nExperience and Skills:\nFamiliarity with large datasets, understanding of data analysis workflows, and/or knowledge of querying languages such as SQL is required.\nProficient with common data science toolkits, such as R, Pandas, TensorFlow, NumPy.\nStrong working knowledge of statistics, machine learning algorithms such as Random Forest, SVM, neural networks, etc. and/or Natural Language Processing techniques is required.\nExperience with visualization software/tools such as Python, R, D3.js, Spotfire, Tableau, etc.\nExperience with big data tools: Spark, Hadoop, Redshift, EMR.\nAbility to effectively communicate technical work to a wide audience.\n\nPrefered\nHandling of healthcare relevant datasets, such as EHR, genomics, clinical trials, insurance claims or registry data.\nExperience designing, developing and deployed web applications, microservices.\nFamiliarity with drug discovery and clinical development processes.\nExperience building processes supporting data transformation, data structures, metadata.\nWe will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\n\nJohnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.\n\nPrimary Location\nUnited States-California-San Diego-\nOther Locations\nNorth America-United States-Pennsylvania-Spring House\nOrganization\nJanssen Research & Development, LLC (6084)\nJob Function\nR&D\nRequisition ID\n2534200402'"
b'Staff Deep Learning/AI Engineer',b'Illumina',"b'San Diego, CA, US'","b'Position Summary\n\nThe Staff Deep Learning/AI Engineer in Illumina\xe2\x80\x99s Finance Performance Management group will focus on applying machine learning/deep learning techniques to finance and business applications. They will be part of analytics team developing machine learning/deep learning methods applied to financial and commercial datasets, with the goal of improving finance and accounting processes.\n\nResponsibilities\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of finance and accounting processes\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDeliver solutions leveraging latest machine learning (ML) techniques, including exploratory data analysis, feature engineering, model selection, model evaluation and cross-validation, and deployment and productionalization at all scales.\nUse predictive modeling to increase and optimize forecasting, revenue generation, and other business outcomes.\nDevelop company A/B testing framework and test model quality.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nMentor and scientifically lead junior members of the team\nBuild strong collaborative relationships with diverse groups within and outside of Illumina\nListed responsibilities are an essential, but not exhaustive list, of the usual duties associated with the position. Changes to individual responsibilities may occur due to business needs.\n\nRequirements\nExperience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\n5-7 years of experience manipulating data sets and building statistical models\nMaster\xe2\x80\x99s or PhD in Statistics, Mathematics, Computer Science or another quantitative field\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nExcellent written and verbal communication skills for coordinating across teams\nAll listed requirements are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional task and responsibilities.\nIllumina believes that everyone has the ability to make an impact, and we are proud to be an equal opportunity employer committed to providing employment opportunity regardless of sex, race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship status, and genetic information. If you require accommodation to complete the application or interview process, please contact accommodations@illumina.com. To learn more, visit: https://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf'"
b'SSD Machine Learning Engineer I (Temporary)',b'Kaiser Permanente',"b'San Diego, CA, US'","b""Description\n\nMachine Learning Engineer will provide technical direction, execution and support of machine learning strategies for the SCPMG Medical informatics group. The position entails designing and implementing data pipelining, integration, and optimization of machine learning models to address healthcare's triple aim: to improve the health of populations, to lower the cost of care, and to enhance the care experience.\n\nEssential Responsibilities\nUse statistical and machine learning techniques to develop and improve clinical decision support tools\nDesign and develop data pipelines for machine learning applications\nOptimize machine learning models to scale in real-time streaming applications\nIntegrate and deploy machine learning components in a production environment\nWork closely with machine learning scientists, physicians, and other stakeholders\nDeploy developed products to project environments.\nReview and provide practical feedback on group products and procedures.\nProvide technical feedback on team members' work.\nSeek out open-source software packages or existing software code that can be reused or applied to assigned tasks.\nProduce/archive process related artifacts such as design documents, test plans, wikis, and code review forms.\nExperience\n\nBasic Qualifications:\nMinimum two (2) years of programming or technical related experience.\nEducation\nB.S. in Computer Science, Informatics, Physics, Mathematics, Engineering or related fields.\nLicense, Certification, Registration\nN/A\nAdditional Requirements\nFamiliarity in the following languages, expert in at least one: Python, Java, SQL\nExperience with pipelining, workflow, and orchestration tools such as Apache Airflow, MLFlow, Kubeflow, Kubernates\nExperience with deep learning frameworks (e.g. Tensorflow)\nFamiliarity with classification and regression algorithms\nPreferred Qualifications\nDemonstrated experience in Natural Language Processing\nDemonstrated experience with machine learning integration and deployment in production environments\nDemonstrated experience with Tensorflow Serving or TensorRT\nFamiliarity with C++\nFamiliarity with writing custom CUDA\nExperience with source control tools for code and models/data\nFamiliarity with healthcare terminology\nM.S. in Computer Science, Informatics, Physics, Mathematics, Engineering or related fields.\nThis is a temporary position"""
b'Summer 2020 Machine Learning/HPC Co-Op/Intern - (78821)',b'AMD',"b'San Diego, CA, US'","b'What You Do At AMD Changes Everything\n\nAt AMD, we push the boundaries of what is possible. We believe in changing the world for the better by driving innovation in high-performance computing, graphics, and visualization technologies \xe2\x80\x93 building blocks for gaming, immersive platforms, and the data center.\n\nDeveloping great technology takes more than talent: it takes amazing people who understand collaboration, respect, and who will go the \xe2\x80\x9cextra mile\xe2\x80\x9d to achieve unthinkable results. It takes people who have the passion and desire to disrupt the status quo, push boundaries, deliver innovation, and change the world. If you have this type of passion, we invite you to take a look at the opportunities available to come join our team.\n\nMachine Learning/HPC Internship\n\nThe Role\n\nRTG (Radeon Technologies Group) Architecture team in San Diego is passionate about developing next-generation GPU solutions. As a Machine Learning/HPC architect, you will collaborate with a strong architecture and design team on developing next generation products for data centers and super-computers. You will engage in architecture exploration, modeling and analysis of ML/HPC workloads. Through your experiments and analysis, you will provide valuable insight into new and emerging hardware and software technologies.\n\nThe Person\n\nYou have excellent analytical and problem-solving skills, along with attention to detail. You are an effective team player who focuses on collaboration, team building, mentoring, and furthering team success. You have strong communication, time management, and presentation skills\n\nKey Responsibilities\nWork with architects to propose innovative solutions that can be implemented in SW/HW, validated by developing various models/simulators\nAnalyze HPC/ML workloads, identify performance bottlenecks and propose solutions\nCollect/summarize data or simulation results for consumption by architects and design teams\n\n\nPreferred Experience\nKnowledge of CPU architectures, basic knowledge of GPGPU architectures\nExcellent C/C++/Scripting (Python, etc.) skills\nKnowledge of Graphics/Compute APIs (CUDA/OpenCL/Vulkan etc.) is preferred\nHW/RTL/SystemC experience is a plus\nKnowledge of ML networks, Tensorflow/Pytorch is desirable\n\n\nAcademic Credentials\nBachelor of Science degree with emphasis in Electrical Engineering, Computer architecture, or Computer Science with relevant experience preferred, or\nMaster or PhD degree with emphasis in Electrical Engineering, Computer architecture, or Computer Science\n\n\nLOCATION:\n\nSan Diego, CA\n\nAMD does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services. AMD and its subsidiaries are equal opportunity employers and will consider all applicants without regard to race, marital status, sex, age, color, religion, national origin, veteran status, disability or any other characteristic protected by law. EOE/MFDV\n\nRequisition Number: 78821\nCountry: United States State: California City: San Diego\nJob Function: Student/ Intern/ Temp\n\nAMD does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services. AMD and its subsidiaries are equal opportunity employers. We consider candidates regardless of age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status. Please click here for more information.'"
b'Deep Learning Research Engineer',b'TuSimple',"b'San Diego, CA, US'","b'TuSimple was founded in 2015 with the goal of bringing the top minds in the world together to achieve the dream of a driverless truck solution. With a foundation in computer vision, algorithms, mapping, and AI, TuSimple is working to create the first commercially viable autonomous truck driving platform with L4 (SAE) levels of safety.\n\nJob Description\n\nOur deep learning team helps autonomous trucks sense and perceive the world. You will play an important role in creating novel algorithms for advanced perception and applying your algorithm on terabytes of data. You will also work closely with other talents in this field in building the next-generation of autonomous sensing algorithms.\n\nResponsibilities\nResearch and prototype developing using deep learning with a special focus on the perception problems of autonomous driving\n\n\nQualifications\nMS/PhD in Computer Science/Electrical Engineering\n3+ years of research or practical experience in applying deep learning on large scale and real world data\nKnowledge in deep learning topics including but not limited to detection, segmentation, 3D perception, and spatial-temporal analysis\nStrong coding skills in Python or C/C++\nFamiliar with at least one of the following deep learning frameworks: MXNET (preferred), TensorFlow, Pytorch, Caffe.\n\n\nPreferred\nTrack record of publishing in top-tier computer vision or machine learning conferences or/and journals.\nPrior academic or industrial experience in autonomous driving.\n\n\nPerks\nCompetitive salary and benefits\nWork with world class AI Engineers\nShape the landscape of autonomous driving\nDaily breakfast, lunch, and dinner\nFull kitchen with unlimited snacks and fruits\nMedical, Vision, and Dental insurance plan\nCompany 401(K) program\nCompany paid life insurance\n\nTuSimple is an Equal Opportunity Employer. This company does not discriminate in employment and personnel practices on the basis of race, sex, age, handicap, religion, national origin or any other basis prohibited by applicable law. Hiring, transferring and promotion practices are performed without regard to the above listed items.'"
b'Sr. Machine Learning Engineer',b'ServiceNow',"b'San Diego, CA, US'","b'Job Title: Senior Machine Learning Engineer\n\nCompany\n\nWork matters. It\xe2\x80\x99s where we spend a third of our lives. And the workplace of the future is going to be a great place. We\xe2\x80\x99re dedicated to bringing that to life for people everywhere. That\xe2\x80\x99s why we put people at the heart of everything we do.\n\nPeople matter. Our people have a passion for learning, building, and innovating. Whether you\xe2\x80\x99re an engineer, a sales professional, a finance professional, or anything in-between, our roles aim to provide each person with meaningful impact and plenty of space to grow.\n\nTeam\n\nCome join the Vulnerability Response Product Engineering team and work with a talented group of developers building best in class automated security orchestration in ServiceNow cloud platform. This team is responsible for the innovation, features, and architecture of products used by many Fortune 500 companies.\n\nRole\n\nAlmost 48% of organizations report that they have had a data breach in the past two years. As the severity and volume of attacks increase, the race to outpace attackers continues. Cybersecurity teams are not equipped enough to keep up and need to leverage the right tools to detect and patch in a timely manner.\n\n60% of breach victims said they were breached due to an unpatched known vulnerability where the patch was not applied\n62% were unaware that their organizations were vulnerable prior to the data breach\n52% of respondents say their organizations are at a disadvantage in responding to vulnerabilities because they use manual processes\n\nWith ServicerNow Vulnerability Response product, we replace manual tasks with automated security orchestration. By unifying the data and processes across IT and security teams, we enable them to prioritize and remediate vulnerabilities and security incidents faster. Using ServiceNow Vulnerability Response, vulnerabilities are patched 60% faster, triage time shrinks by 50% and the existing security and IT staff can handle 50% more workload.\n\nAs a Senior Machine Learning Engineer, you will play a major part in defining the strategy to use massive amounts of data, to prioritize, remediate and predict the vulnerabilities within an Enterprise to reduce and manage exposure to cyber security risk within an organization.\n\nWhat You Get To Do In This Role\nYou will build models against machine learning algorithms and collaborate with industry leading machine learning technologists to address new problem spaces within the ServiceNow ecosystem.\nYou will join a team that takes pride in building extensible and resilient engineering solutions.\nYou will work closely with Product Managers and customers to understand detailed requirements.\nYou will own your solution from design, implementation, automation, delivery and validation with our users.\nYou will define machine learning application strategies and architecture to support these strategies.\nYou will collaborate with an energetic team of like-minded developers, product managers and quality engineers using agile software development methodology.\nYou will work closely with the ServiceNow SaaS platform team on understanding the platform capabilities and extending those capabilities to meet the unique challenges and needs of Vulnerability Response product.\nYou will troubleshoot problems encountered by customers and provide resolutions.\n\nIn order to be successful in this role, we need someone who has:\n6+ years of experience in architecture, design and development of enterprise-grade applications in a high transaction environment.\n2+ years and/or machine learning experience\nKnowledge of Machine Learning algorithms\nStrong understanding of Object-Oriented Analysis, Design Patterns, Data Structures, and time and space-efficient and high performing algorithms\nPassion for software development and problem solving\nHigh energy, self-starter with aptitude for learning new technologies\nKnowledge of Java & JavaScript technologies, with excellent understanding of JavaScript frameworks as Angular, React, Node.js.\nExpert in building RESTful services, and data exchange formats as XML and JSON.\nSolid experience with open source technologies Linux, Apache, Selenium.\nIn-depth knowledge of relational databases (e.g. PostgreSQL, MySQL) and NoSQL databases (e.g. MongoDB)\nExceptional debugging including browser-based debugging, testing, and problem-solving skills.\nExceptional written and verbal communication skills with proven ability to effectively communicate complex technical issues to both technical and non-technical teams.\nPassion for software development, problem-solving, and learning new technologies.\nStrong educational background in Computer Science, Machine Learning, or Mathematics fields, prefer MS/PhD\n\nNote that an exact match on skills is less critical than strong design instincts, high quality coding discipline and enthusiasm for taking on an ambitious project that will reshape the way people interact with enterprise software.\n\nEEOE Statement Section\n\nServiceNow\xe2\x80\x99s EEOE statement is automatically added to each U.S. based job description.'"
b'Deep Learning Research Scientist / Engineer (Deep Learning & Algorithms)',b'Samsung Electronics America',"b'San Diego, CA, US'","b""Description\n\nPosition at Samsung Semiconductor, Inc.\n\nJOB TITLE\n\nResearch Engineer-Deep Learning Theory and Algorithms\n\nRequisition ID\n\nDSA31988\n\nOverview\n\nSamsung Semiconductor, Inc. in San Diego is searching for research engineers at all levels. Candidate will work as part of a team on research and development of algorithms and theory of machine learning. Candidate will research fundamental theoretical aspects of deep learning as well as develop novel techniques to advance the theory and practice of deep learning. Candidate can also apply the developed theory and algorithms to advance the performance of multimedia applications, such as computer vision, augmented reality, natural language processing, or speech processing.\n\nJob Responsibilities\nUnderstand state of the art machine/deep learning concepts, theory, and applications.\nResearch algorithms and theory of learning.\nDevelop machine/deep learning algorithms for mobile processors.\nDevelop simulators and analyze the performance.\nProduce key intellectual property for machine/deep learning.\n\nRequired Skills\nStrong analytical and problem-solving skills\nExpertise in machine/deep learning, optimization, probability theory, statistical inference, information theory, signal processing, and/or image processing\nExcellent communication and teamwork skills\nC/C++, Python, and/or MATLAB coding skills\nPublications in highly ranked journals and conferences\nPhD is required\n\nPreferred Skills\nExperience on popular deep learning frameworks\n*********************************************************************************************************************** Samsung Semiconductor Inc (SSI), an equal opportunity employer, is a world leader in Memory, System LSI, and LCD technologies. Headquartered in San Jose, California, SSI is a wholly-owned U.S. subsidiary of Samsung Electronics Co., Ltd.- the second largest semiconductor manufacturer in the world and the industry's volume and technology leader in DRAM, NAND Flash, SSDs, mobile DRAM and graphics memory. It is one of the largest providers of system logic, imaging and LED lighting solutions, as well as providing advanced process design and manufacturing for fabless companies. Samsung Semiconductor, Inc. also has a research and innovation center with numerous labs providing product design and research in: logic, memory, image sensors, displays and mobile technologies. In addition, the company supports Samsung Display Company, the largest producer of LCD and OLED displays. ***********************************************************************************************************************\n\nLearn more about Samsung Semiconductor here.\n\nA day in the life Samsung Video\n\nSamsung Semiconductor Career Page"""
b'Machine Learning Scientist',b'Amazon',"b'San Diego, CA, US'","b'Description\n\nHave you ever wanted to work on machine learning challenges that will make a lasting impact on society? How about solving key problems that impact the experience of millions of Amazon customers?\n\nAmazon is looking for brilliant Machine Learning Scientists who have the passion to tackle tough problems and help shape a new product from the very early stages in the online grocery shopping space. Together, with a multi-disciplinary team of scientists, engineers, economists, product managers, and subject domain experts, you will help define our customer experience with machine learning at its core. You will define the research and experiment strategy with an iterative approach to create machine learning models and progressively improve the results over time. We are looking for candidates who thrive in fast paced environments and want to invent the future.\n\n\nBasic Qualifications\nPhD or Masters degree in Applied Math, Data Science, Computer Science, Engineering, Machine Learning (or in a highly related field)\n5+ years of hands-on industry experience in predictive modeling, algorithm development, and big data analytics\n5+ year of experience in building machine learning models deployed to production environments\nExperience in applying fundamental machine learning algorithms to solve complex problems\nExperience with modifying standard algorithms (e.g. changing objectives, working-out the math, implementing and scaling)\n7+ years in one or more major programming languages (Python, Java, C++, C, Perl/Ruby, etc.)\nPreferred Qualifications\nPhD in Computer Science, Applied Math, Data Science, Engineering, Machine Learning (or in a highly related field)\n7+ years of hands-on industry experience in predictive modeling, algorithm development and big data analytics\nExtensive experience applying theoretical models in an applied environment\nMastery in fundamentals of problem solving, algorithm design and complexity analysis\nStrong interpersonal and communication skills -- the ability to explain technical concepts and analysis implications clearly to a wide audience, including senior executives, and translate business objectives into action\nAmazon.com is an Equal Opportunity-Affirmative Action Employer \xe2\x80\x93 Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation\n\n\nCompany - Amazon.com Services LLC\nJob ID: A1037013'"
b'Deep Machine Learning Engineer',b'CyberCoders Middleware Test Compay',"b'San Diego, CA, US'","b""Happy New Year!\nBased in the San Diego, CA area, we are one of the most innovative Image solutions companies in the World. We are well-funded with premiere clients who are utilizing us to solve the most challenging image issues we currently face. Our team is composed of experts in the world of machine learning and image processing with a leadership team that brings experiences from leading global scientific technology firms and pride themselves in their hands-on, mentor level management style. If you are a strong Deep Learning / Machine Learning Scientist with experience in Python OR Java OR C and, obviously, Machine Learning expertise, we would welcome the opportunity to discuss the details.....What You Need for this PositionRequirements:\n- 3+ years of Deep / Machine Learning experience\n- Master's Degree or PhD HIGHLY preferred. Points if you have published papers on the same topics.\n- Supervised and Unsupervised machine learning a must\n- Timeseries and/or Deep Learning a big plus\n- Algorithm development experience\n- Communicates very well\n- Research type\n- Excellent communication and written skills\n\nNice to have skills:\n- Strong interest in creating solutions to problems\n- Experience in and interest in learning new technologies\n- Experience managing multiple projects and working independentlyTop Reasons to Work with UsFast growing.\nWell-funded.\nStart-up equity.What's In It for YouWe are willing to offer excellent compensation packages including annualized pay potential of $110k to around $135k, plus EQUITY, and excellent benefits. We are located in a centrally located area with access to 2 major freeways, and plenty of parking.So, if you are a recent PHD grad, or PHD grad with experience in Machine Learning, please apply today!\n\n*** You can also email me directly at eric.shaner@cybercoders.com\n*** Find/connect with me on LinkedIn - www.linkedin.com/in/analytics\nDesired Skills and Experience\nLinear, Non-linear, Deep Learning, Supervised Techniques, Timeseries Analysis, UnSupervised Techniques"""
b'Data Scientist - Statistics and Machine Learning',b'Q-Centrix',"b'San Diego, CA, US'","b'Who are we? Q-Centrix is a leading healthcare information solutions provider with offices in Portsmouth, NH, Chicago, and San Diego, plus more than 900 clinical experts working remotely in 49 states. Our team of smart, ambitious, and fun-loving healthcare professionals are 100% focused on improving the quality of patient care at hospitals throughout the country.\n\nAbout the Job Q-Centrix is looking for a Junior Data Scientist to join us at our San Diego office. We are a data driven and automation focused organization that loves to gain new insights from the massive amount of structured and unstructured data that is collected on a daily basis.\n\nAs a Data Scientist, You Will\nWork on various projects ranging from statistical analysis, data pipelines, machine learning, and advanced signal processing to software engineering\nWrite complete softwares to implement domain agnostic generalized mathematical models that could be deployed on any data\nWork closely with leaders across the organization to look for workflow automation opportunities and execute them\nBuild advanced software solutions that will help prepare the data for analytics projects\nLeverage your experience working with supervised machine learning methods such as ensemble tree classifiers, support vector machines, neural networks, and Bayesian methods to create state-of-the-art predictive models\nCommunicate your successful efforts through documentation and white papers\nKnowledge, Skills, Abilities And Qualification Requirements\nM.S. in Applied Mathematics, Computer Science, or Electrical Engineering and 3+ years of prior experience working as a Data Scientist, machine learning engineer, or data engineer is required\n3+ year of hands-on experience in software engineering, deep learning, and signal processing is highly desired\nQuality Requirements\nPositively contribute to our work environment values of professionalism, mutual respect, teamwork, and collaboration.\nKey Competencies\nProfessionalism and customer service orientation\nAbility to manage multiple projects\nPlanning, organization and excellent time management\nAttention to detail and unrelenting passion for delivery\nFlexibility, adaptability, and teamwork\nYou\xe2\x80\x99re Our Dream Candidate If You\nLove solving business problems with mathematics and programming\nHave a proven track record for writing world class software solutions with Python, Ruby, Java, or Go\nAre passionate about automation and consider yourself an advanced python software developer\nBuilt and operationalized signal processing solutions\nAre intimately familiar with the latest techniques in predictive data modeling including deep learning\nLove data science competitions and are an active participant in kaggle competitions\nLove writing detailed documentation of your completed research, and lastly,\nYou love dogs and cats!\nWho are we?\n\nAt Q-Centrix, we hire people who love learning, value innovation and believe in our mission and values to improve outcomes in healthcare. We applaud qualified applicants who are accountable and committed to producing quality work. As an Equal Opportunity Employer, we support and value diversity, dignity and respect in our work environment, and are committed to creating an inclusive environment in which everyone can thrive.\n\nWe employ people based on the needs of the business and the job, and their individual professional qualifications. Here\xe2\x80\x99s what does not impact our employment decisions: race, religious creed, religion, color, sex, sexual orientation, pregnancy, parental status, genetic information, gender, gender identity, gender expression, age, national origin, ancestry, citizenship, protected veteran or disability status, health, marital, civil union or domestic partnership status, or any status or characteristic protected by the laws or regulations in locations where we operate. If you are an individual with a qualified disability and you need an accommodation during the interview process, please reach out to your recruiter.\n\nWe celebrate and embrace these differences, and take pride in our commitment to being an equal opportunity team.'"
b'Software Engineer',b'PointPredictive Inc.',"b'San Diego, California'","b'We are looking for a junior to mid-level software engineer, whose core skills being Python and experience with Amazon Web Services in Our San Diego Offices.\n\nThis person will act as a generalist supporting senior staff, and will contribute in the following areas:\n\nHelp optimize Python analytics applications and AWS infrastructure for performance.\nBuild-out a robust software testing and release pipeline.\nDevelop automated code tests.\nResearch and develop production monitoring tools.\nContribute partially in a DevOps role.\nDevelop production-level data pipelines for company-critical data science and machine learning solutions\nDevelop tooling, optimization, and testing around core data science work\nBuild and maintain production-level python libraries for the data science team\nLeverage open-source tools and cloud computing technologies comfortably\nExecute best practices in version control and continuous integration/delivery\nOwn and drive projects from conception to completion \n\nIdeally, prior experience includes:\n\n1-5 years as software engineer, with Python as a primary language. Familiar with the Pandas library would be helpful.\nSome experience working in an analytics or data science environment, or exposure to machine-learning.\n1-5 years experience with several AWS services, preferably some of Lambda, EC2, S3, Cloudwatch, API Gateway, and S3.\n1-2 years experience with relational (MySQL, PostgresQL) and NoSql databases (AWS Dynamo DB, MongoDB).\nFamiliarity with version control principles, ideally git.\n\nBonus Points for:\n\nKnowledge of AWS Networking: Virtual Private Cloud (VPC), Subnets, Network Address Translation (NAT) services.\nWindows developer or system administrator skills (Windows Server 2012 or greater, ideally Windows Server 2016)\nExperience with Node.js and Nginx.\nAbility to administer an SFTP server, add users, create keys/credentials'"
b'Data Engineer',b'Accenture',"b'San Diego, CA, US'","b""This role is located in either Sacramento or Los Angeles, CA, and relocation would be required if hired.\n\nWe are:\n\nApplied Intelligence, the people who love using data to tell a story. We\xe2\x80\x99re also the world\xe2\x80\x99s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything\xe2\x80\x94spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds?\nVisit us here to find out more about Applied Intelligence.\n\nYou Are:\n\nA Spark Big Data engineering pro\xe2\x80\x94someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. You\xe2\x80\x99re passionate about digital technology, and you take pride in making a tangible difference. You have communication and people skills in spades, along with strong leadership chops. Complex issues don\xe2\x80\x99t faze you thanks to your razor-sharp critical thinking skills. Working in an information systems environment makes you more than happy.\n\nThe Work:\n\nConsult as part of a team that is in charge of building end-to-end digital transformation capabilities and lead fast moving development teams using Agile methodologies.\nDesign and build Big Data and real-time analytics solutions using industry standard technologies and work with data architects to make sure Big Data solutions align with technology direction.\nLead by example, role-modeling best practices for unit testing, CI/CD, performance testing, capacity planning, documentation, monitoring, alerting and incident response.\nKeep everyone from individual contributors to top executives in the loop about progress, communicating across organizations and levels. If critical issues block progress, refer them up the chain of command to be resolved in a timely manner.\nOptimize NLU model by implementing NLP systems, performing intent classification and entity extraction and user testing.\nDevelop and maintain digital conversational flows, dialog research, Architect, Prototype and Test Dialogue Management system and Natural Language Generator Connect to data source (e.g. multiple xml documents) and query database.\nPinpoint and clarify key issues that need action, lead the response and articulate results clearly in actionable form.\nShow a strong aptitude for carrying out solutions and translating objectives into a scalable solution that meets end customers\xe2\x80\x99 needs within deadlines.\nCollaborate with research teams working on a variety of deep learning and NLP problems.\n\nHere's what you need:\n\nBachelor's degree in Computer Science, Engineering, Technical Science or 12 years of experience in programming and building large scale data/analytics solutions operating in production environments.\nMinimum 2+ years of expertise in designing, implementing large scale data pipelines for data curation, feature engineering and machine learning, using Spark in combination with pySpark, Java, Scala or Python; either on premise or on Cloud (AWS, Google or Azure).\nMinimum 1 year of designing and building performant data tiers (or refactoring existing ones), that supports scaled AI and Analytics, using different Cloud native data stores on AWS, Azure and Google (Redshift, S3, Big Query, SQLDW etc.) as well as using NoSQL and Graph Stores.\nMinimum 1 year of designing and building streaming data ingestion, analysis and processing pipelines using Kafka, Kafka Streams, Spark Streaming and similar cloud native technologies.\nBonus points if:\n\nMinimum 1 year of designing and building secured and governed Big Data ETL pipelines, using Talend or Informatica technologies; for data curation and analysis of large le production deployed solutions.\nExperience implementing smart data preparation tools such as Palate, Trifacta, Tamr for enhancing analytics solutions.\nMinimum 1 year of building Business Data Catalogs or Data Marketplaces for powering business analytics using technologies such as Alation, Collibra, Informatica or custom solutions.\n\nImportant Information:\n\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration. Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\n\nEqual Employment Opportunity:\n\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law. Job Candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\n\nAccenture is committed to providing veteran employment opportunities to our service men and women."""
b'Data Scientist',b'Realty Income Corporation',"b'San Diego, CA, US'","b""Description\n\nRealty Income, The Monthly Dividend Company\xc2\xae, one of four San Diego based S&P 500 companies dedicated to providing shareholders with dependable monthly income. Our company is structured as a REIT, and its monthly dividends are supported by the cash flow, over 6,000 real estate properties owned under long-term lease agreements with regional and national commercial tenants. To date, our company has declared over 600 consecutive common stock monthly dividends throughout its 50-year operating history and has continually increased the dividend since Realty Income's public listing in 1994 (NYSE: O). Our company attracts individuals who value integrity, perseverance, and teamwork. If you appreciate working on a truly collaborative team in a professional environment in a company that encourages a work-life balance, make sure to apply today!\n\nAs Realty Income\xe2\x80\x99s Data Scientist, you will be a ground-breaking leader who works as part of a team that builds and owns analytics-based assets, bringing the value of real estate predictive analytics to our business leaders. You will shape the future of a data-savvy organization, in part by driving processes for data extraction and analysis, and by creating new lines of thinking within our core real estate and investing business. In this role, you will design, develop and execute predictive analytics work streams that serve as the catalyst to increase ROI for the business.\n\nYour Contribution to the Team Includes\n\nPredictive Analytics\nBuild predictive analytics for use cases such as: Portfolio Management; Development; Acquisitions\nWork with business teams to identify, develop and deliver new use cases over time\nPrioritize predictive analytics initiatives based on multiple factors, e.g., ROI/productivity, business continuity, ease of delivery\nDeliver insights with user friendly end-products such as web-based tools, reports (e.g., Power BI) or visualizations that are accessible and understandable for business users\nEnsure we remain state of the art by keeping up on the latest technologies and approaches, attending conferences or other events as needed\nInfrastructure for Predictive Analytics\nCreate the vision for static and dynamic data architecture for predictive analytics encompassing internal data in our ERP system or other data sources as well as externally sourced data (e.g., census information news feeds)\nOversee the process for data management leveraging IT and business teams using clearly articulated responsibility matrices and timelines, including meeting internal audit requirements for data/process integrity\nCoordinate with the IT team to buy or license required tools, data and feeds\nWork with the IT team as they set up the necessary infrastructure and processes to support predictive analytics, e.g., ETL from the ERP system to data warehouse/lake\nDetermine how and when to take and store \xe2\x80\x9csnapshots\xe2\x80\x9d of data so that we can go back in time to test new models and approaches\nOrganizational Relationships\nWork closely with business teams, IT, internal audit and enterprise risk to define end products and processes\nCreate cross-functional working groups or teams as needed to initiate, approve or complete work\nUpdate the Investment Committee monthly or quarterly on key matters such as portfolio risk\nSupport business teams in the achievement of their objectives using predictive analytics tools\nPerforms other duties as assigned.\n\nRequirements\n\nWhat You\xe2\x80\x99ll Need to be Successful\nPHD Preferred in a relevant discipline, e.g., machine learning, statistics, applied mathematics, econometrics, or operations research\n3-5+ years of experience providing advanced analytics within a business setting\nPrior work experience within real estate or financial services is preferred, but not required\nProgramming experience in Python, Spark and SQL. Java/Scala is a plus\nExperience with RDBMS systems like PostgreSQL and NoSQL systems like MongoDB\nHands-on experience in Microsoft Azure and Amazon EC2 cloud platform\nDemonstrated ability to design and implement ETL workflows across both Windows and Linux environments\nAbility to clearly communicate ideas, orally or via written communications\nTo all recruitment agencies: Realty Income does not accept unsolicited agency resumes. Please do not forward resumes to our job\xe2\x80\x99s alias, Realty Income employees, or any company location. Realty Income is not responsible for any fees related to unsolicited resumes."""
b'Business Intelligence Analyst - Customer Experience and Analytics',b'BD',"b'San Diego, CA, US'","b'Job Description Summary\n\nBD\xe2\x80\x99s Global Customer Services (GCS) organization is transforming the customer experience on our journey to advance the world of health. The mission of the Customer Experience & Analytics team is to partner with GCS businesses to deliver actionable insights, resulting from analysis of Voice of the Customer (VOC) data and operational data, that drive meaningful improvement in customer and associate experience.\n\nWe are seeking a Business Intelligence Analyst, Customer Experience Analytics that will develop actionable research hypotheses, prepare and analyze datasets, develop predictive models, and present key findings to stakeholders in a clear way. This individual should be highly analytical and capable of truly understanding data to identify new opportunities and actionable insights that drive BD\xe2\x80\x99s customer experience. In addition to technical capabilities, this individual will be extremely collaborative and continuously seeking new opportunities in a consultative manner.\n\nJob Description\n\nJob Summary\n\nBD\xe2\x80\x99s Global Customer Services (GCS) organization is transforming the customer experience on our journey to advance the world of health. The mission of the Customer Experience & Analytics team is to partner with GCS businesses to deliver actionable insights, resulting from analysis of Voice of the Customer (VOC) data and operational data, that drive meaningful improvement in customer and associate experience.\n\nWe are seeking a Business Intelligence Analyst, Customer Experience Analytics that will develop actionable research hypotheses, prepare and analyze datasets, develop predictive models, and present key findings to stakeholders in a clear way. This individual should be highly analytical and capable of truly understanding data to identify new opportunities and actionable insights that drive BD\xe2\x80\x99s customer experience. In addition to technical capabilities, this individual will be extremely collaborative and continuously seeking new opportunities in a consultative manner.\n\nThe Core Responsibilities Include\nPartner with internal customers to understand stakeholder needs; translate business needs into analytical requirements that can be answered with available data using statistical and machine learning methods\nExtract and prepare data sets from various sources including Hadoop, SQL Server, flat files, etc\nDevelop visualizations to help explain patterns and trends in large data sets\nCommunicate analyses and results to executive leadership backed by data and coupled with actionable insights to drive business decisions\nRecognize and adopt industry best practices in reporting and analysis\nSupport the survey methodology of the NPS program, supported by Qualtrics, and capture insights\nDraw conclusions and prioritize actions/recommendations with limited data\n\nQualifications\nBachelor\xe2\x80\x99s or Master\xe2\x80\x99s degree in a quantitative field such as Data Science, Analytics, Computer Science Engineering, Systems Engineering, or Statistics\n3+ years of experience in a role requiring application of analytic skills to integrate data into operational/business planning\nStrong experience with BI tools (e.g., Power BI, Tableau), data extraction, data manipulation, and analysis; demonstrated strength using SQL queries in a business environment\nStrong quantitative and qualitative analytical skills with ability to distill large data sets into meaningful insights and takeaways\nStrong PowerPoint skills and ability to translate data insights into impactful presentations\nSuperior verbal and written communication skills with the ability to effectively advocate technical solutions to non-technical audiences\nAbility to cultivate and maintain productive working relationships with internal business partners and work successfully in a highly cross-functional matrix organization\nExtreme curiosity to understand business operations and data with a desire to work across groups to do so\nQualtrics and Salesforce experience a plus but not required\n\nPrimary Work Location\nUSA CA - San Diego Bldg A&B\n\nAdditional Locations\n\nWork Shift\n\nJob Category: Professional Services'"
b'Data Scientist',b'Broadcom Inc.',"b'San Diego, CA, US'","b'Job Description\n\nDo you enjoy analyzing data? Creating products that solve real-world problems and taking them into production? Working with colleagues to find novel ways to approach difficult problems in fintech?\n\nWe are looking for people with graduate degrees (MS or PhD) in an analytical field, e.g., Physics, Statistics, Electrical Engineering, Computer Science, Oceanography, Applied Mathematics, Data Science. You should understand how to apply mathematics to real-world problems, including linear algebra, vector calculus, etc.\n\nWe Are Looking For People Who\nHave strong scientific coding aptitude \xe2\x80\x93 efficient code that is numerically stable and of production quality.\nAre strong analytical thinkers, including reasoning through probabilities and statistics, as well as delving into detailed deterministic thinking and using individual examples\nCan learn new business domains, understanding the context for the data science\nCan learn and apply machine learning and AI techniques to new domains, with a focus on client needs\nHave interest in working from start to finish: gather data, clean and prepare, model, code, package, guide into production, and help clients use the results.\nEnjoy working with data.\nCan communicate complex and sophisticated ideas to people without scientific backgrounds\nEnjoy working in a team environment\n\nYou Will Be Responsible For\nWorking on problems in the fintech area, including online payments, banking, and other areas\nWorking on a team under the leadership of other Data Scientists\nCommunicating with clients, internal and external, to understand the business problems that we can solve using machine learning and AI\nAnalyzing and understanding data from different domains, including data cleansing and detailed analysis of relationships between fields\nDeveloping supervised, unsupervised, and reinforcement models in the laboratory\nCoding models for production, with particular attention to efficient use of computational resources and robustness of the code\nWorking with Software Engineers and SaaS Operations to package and deploy the models\nMonitoring the models to ensure that they are working properly, and generalizing to new data\nWorking with clients to ensure that they are using the results of the models effectively.\nSkills needed include: excellent written and verbal communications, and presentation skills.\n\nLanguages needed include a subset of: Python, C++, Unix scripting, SAS, PySpark, Scala, Perl, C\n\nStrong command of Unix is preferred.\n\nExperience (Data Scientist): Fresh Graduate degree holders are welcome to apply. Industry experience greatly appreciated.\n\nIf you are located outside USA, please be sure to fill out a home address as this will be used for future correspondence.'"
b'Data Scientist',b'HP',"b'San Diego, CA, US'","b""Data Scientist\n\nAs Data Scientist at HP Inc. in San Diego, you will join an industry-leading organization and work on developing frameworks for systematic data science modeling to identify optimal marketing, pricing and sales decisions for our Printing & PC business. Working within a dynamic, highly skilled and diverse Pricing Strategy and Analytics team (economists, engineers, scientists or even musicians ? majority of them with a PhD) you will build models and develop tools and analytical processes to develop pricing and marketing strategies for HP printers, cartridges and PCs around the world.\n\nResponsibilities\nDevelop and apply statistical methods to analyze the effect of pricing and sales decisions on business performance\nDevelop and implement frameworks and processes for systematic and automated data analysis\nDevelop tools to ingest, merge, and clean data sets\nImmerse yourself in very large data sets and complex problems\nVisualize and interpret the results of analyses, and create strategy recommendations\nPresent the results and the corresponding recommendations to the relevant stakeholders, including senior leadership\n\nQualifications\nInterest in data science, pricing, economics, and/or consumer behavior\nScientific thinking and ability to design and critically analyze quantitative research\nAbility to think creatively about research problems and invent original solutions to modeling challenges\nAbility to build and interpret complex linear regression models, with machine learning experience a plus\nKnowledge of and experience in deploying numerical optimization routines\nProficiency with Python and R is required\nStrong analytical skills, with a high level of attention to detail\nProficiency in Microsoft Excel and Microsoft PowerPoint\nExcellent written and verbal communication skills\n\nNice-To-Haves\nKnowledge of price optimization approaches, price discrimination models and a general knowledge of main concepts from the industrial organization literature\nExperience working with large data sets\nExperience in data engineering\nExposure to digital marketing\nExperience working in or collaborating with industry\nExperience creating data visualizations\nAbility to build dashboards and other tools using front-end development skills\nExperience in software development\n\nEducation & Experience\nBachelor?s, Master's or PhD degree in Engineering, Computer Science, Economics, Quantitative Marketing, Mathematics, Physics or equivalent\n1-3 years? experience including graduate or postgraduate research"""
b'Analytics Engineer',b'ICF',"b'San Diego, CA, US'","b'ICF is a premier provider of Full-spectrum cyberspace operations and analysis services to the Federal government. Our experts use analytics, machine learning and automation to identify and respond to network anolmalies, ensuring resiliency and mission assurance for our clients. We develop the next generation of Cyber Security for our clients, providing monitoring and active network defense of their networks.\n\nWe are seeking an Analytics Engineer to join our team supporting the Navy in San Diego\n\nExperience And Qualification Required\nCybersecurity Workforce (CSWF) IAT Level II\nStrong knowledge of scripting, programming or application programming interface\nSkills to develop extensibility to support diverse analytics for multiple use cases\nKnowledge of military and commercial data transports\nExperience in designing solution sets that operate in a low computational provide and in isolated environments\nExperience developing capabilities that quickly process and provide to end user critical data requests\nExperience in designing, developing, testing, implementing and maintaining large-scale data analytics techniques and technologies to include indexing techniques,information retrieval, data frameworks, machine learning, predictive analytics, data mining and statistical analysis\nExperience in developing analytics supporting cyber security use cases that supports decision aids at the strategic, operational and tactical levels of maritime warfare\nMinimum security clearance of TOP SECRET; ability to\nobtain TS/SCI clearance\n\nAnd Either\nMinimum of BS degree in related field and at least five (5) years of experience in skills identified above\nOR- Formal degree requirement may be evaluated and waived if applicant provides at least seven (7) years of experience in skills identified above\n\nWorking at ICF\n\nWorking at ICF means applying a passion for meaningful work with intellectual rigor to help solve the leading issues of our day. Smart, compassionate, innovative, committed, ICF employees tackle unprecedented challenges to benefit people, businesses, and governments around the globe. We believe in collaboration, mutual respect, open communication, and opportunity for growth. If you\xe2\x80\x99re seeking to make a difference in the world, visit www.icf.com/careers to find your next career. ICF\xe2\x80\x94together for tomorrow.\n\nICF is an equal opportunity employer that values diversity at all levels. (EOE \xe2\x80\x93 Minorities/Females/ Protected Veterans Status/Disability Status/Sexual Orientation/Gender Identity)\n\nReasonable Accommodations are available for disabled veterans and applicants with disabilities in all phases of the application and employment process. To request an accommodation please email and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: and .\n\nSan Diego, CA (CA74)'"
b'Data Scientist',b'National University',"b'San Diego, CA, US'","b'Position Summary\n\nUnder the direction of the VP, Chief Data Officer, the Data Scientist provides analytical leadership to support the data and analytical needs of the entire University. This position is responsible for developing and maintaining National University\xe2\x80\x99s analytical infrastructure to provide timely and reliable data for informed decision-making. In addition, the incumbent will apply advanced statistical, data mining, machine learning and various predictive modeling techniques to provide information, knowledge, coordination, and tools that support the growth and continued success of National University. The VP, Chief Data Officer provides general oversight concerning objectives and projects for this position and completes an annual evaluation of position.\n\nEssential Functions\nResponsible for the development, maintenance and advancement of National University\xe2\x80\x99s analytical\ninfrastructure.\nDevelop and maintain data extraction, transfer and loading from various sources.\nImplement appropriate security measures throughout the data pipeline.\nResponsible for maintaining metadata management and data quality activities so that data are accurate, reliable and documented.\nApply advanced predictive modeling, data mining, machine learning and statistical techniques to enable\ninformed decision-making, student support, and strategic initiatives.\nProvide analytical guidance to the entire University.\nFacilitate the transmission and understanding of data to enable fact-based decisions to various stakeholders, such as leadership, faculty and staff.\nProvide reliable and timely data that supports strategic planning, student success initiates, and educational and operational effectiveness.\nUtilize various software tools and reporting services to deliver actionable data to end-users in a digestible form\n\nSupervisory Responsibilities: NA\n\nRequirements\n\nEducation & Experience\nBachelor\xe2\x80\x99s degree in a related discipline (Statistics, Mathematics, Data Science, Social Sciences).\nAdvanced degree in a related field or evidence of pursuit of advanced studies or degree strongly preferred.\nOne to three (1-3) years of recent professional experience in data analysis and/or data engineering.\nTechnical / Functional Skills\nProficient in the following software applications: Microsoft Office Applications; Microsoft SQL Server; Microsoft\nAzure; Redmine; Peoplesoft/SOAR; Relational Database Management; Tableau/Power BI; and Statistical\nanalysis software (R, Python, or the equivalent) required.\nExperience and thorough knowledge in data collection and analysis techniques.\nCompetencies\nRequires analytic ability and frequent independent judgment based on knowledge of University policy and precedent.\nFluency in information technologies, including high level of proficiency and understanding with data mapping, data mining, machine learning, statistics, cloud computing and analytical programming languages such as SQL, R and/or Python.\nProven ability to independently synthesize, implement, analyze and report findings of research studies.\nExceptional interpersonal, organizational, and problem-solving skills as well as effective written and verbal communications.\nProven ability to troubleshoot problems and overcome obstacles with creative solutions.\nCapable of performing in a professional and friendly manner despite conditions of deadlines and pressure.\nKeen ability to transform vague requirements into clear, objective, and actionable tasks.\nFully accustomed to working on multiple projects, both independently and as a team member.\nSelf-starter with a positive attitude, intellectual curiosity and a passion for analytics\n\nPhysical Demands / Environment\n\nTravel: none required'"
b'Data Specialist',b'Veyo',b'Greater San Diego Area',"b'Veyo is using its platform and app-based transportation services to reinvent the medical logistics world. Our company is using technology to pioneer new operational models to help make transportation more powerful and more reliable for the healthcare industry.\n\nWhen you work at Veyo, you\xe2\x80\x99re helping to solve one of the nation\xe2\x80\x99s growing healthcare challenges -- ensuring patients get to and from their medical appointments, safely and on-time. We are using smart design and innovative technology to make patient transportation safer and more connected. In the process, we\xe2\x80\x99re transforming the entire industry.\n\nWhat you can expect:\nUse technology to help people lead healthier lives\nWork with an incredibly talented, intelligent team\nAbility to try out new technologies to gauge fit for business needs\nEncouragement to grow professionally and personally \xe2\x80\x93 attend conferences, give knowledge sharing presentations, pick your career path\n\nWhat we\xe2\x80\x99ll expect from you:\nBe committed to the health and safety of our passengers\nHelp shape the strategy and direction of the company and an industry\nSolve algorithmic problems in the logistics, healthcare and operations space through research, experiments and development and support deployment of these solutions into a real world environment\nEntrepreneurial. Everywhere you go, you can\xe2\x80\x99t help but mobilize people, build things, solve problems, roll up your sleeves, go above and beyond, raise the bar. You are an insatiable doer and driver\nAbility to effectively collaborate with and communicate complex concepts to both technical and non-technical audiences at all levels, from C-Level to individual contributors.\nUnderstand the latest industrial and academic developments in AI/ML, and apply it to create prototypes for demonstration\nWork with development teams to mature these algorithms into production quality programs\nDo applied research on a wide array of Operations research and machine learning projects.\n\nRequired Skills:\nAdvanced degree in Statistics, Applied Mathematics, Operations Research, Computer Science, or a related quantitative field.\n5+ years of experience crafting advanced models and familiar with statistical methods applied to large data sets\nProven experience with optimization libraries, scripting languages (Python, R, etc.), SQL and statistical tools, major object-oriented programming languages, and simulation software\nFamiliar with the Microsoft stack C#, .Net 4.5 is a plus\nFamiliarity with GoLang is a plus\n\n\nWe like the following personality traits: Friendly, social, outgoing, positive, passionate, cool under pressure, detail-oriented, deadline oriented, quick learner, multi-tasker, great sense of humor.\n\nWe\xe2\x80\x99re looking for people that love the opportunity to be involved in strategy and management at the top level, but also aren\xe2\x80\x99t scared to get their hands dirty and do what needs to be done to make things happen! We move quickly, and our team doesn\xe2\x80\x99t know the meaning of \xe2\x80\x9cnot my job.\xe2\x80\x9d We want people that want to get things done and can check their ego at the door.\n\nWe thank all applicants for their interest and effort in applying for this position. This position is only for candidates legally allowed to work in the US. EOE.\n\nVeyo is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.'"
"b'Temp Scientist, GMP/Data Review'",b'Neurocrine Biosciences',"b'San Diego, CA, US'","b'Who We Are\n\nAt Neurocrine Biosciences, we pride ourselves on having a strong, distinctive and positive culture based on our shared purpose and values. We know what it takes to be great, and we are as passionate about our people as we are about our purpose - to relieve patient suffering and enhance lives.\n\nWhat We Do\n\nNeurocrine Biosciences (Nasdaq: NBIX) is a neuroscience-focused, biopharmaceutical company with more than 25 years of experience discovering and developing life-changing treatments for people with serious, challenging and under-addressed neurological, endocrine and psychiatric disorders. Headquartered in San Diego, Neurocrine Biosciences specializes in targeting and interrupting disease-causing mechanisms involving the interconnected pathways of the nervous and endocrine systems.\n\nThe company\xe2\x80\x99s diverse portfolio includes two FDA-approved treatments INGREZZA\xc2\xae (valbenazine) for tardive dyskinesia and ORILISSA\xc2\xae (elagolix) for endometriosis*, as well as clinical development programs in multiple therapeutic areas, including Parkinson\xe2\x80\x99s disease, chorea in Huntington disease, congenital adrenal hyperplasia, uterine fibroids* and polycystic ovary syndrome.* As part of a strategic collaboration with Voyager Therapeutics, Neurocrine Biosciences is also focused on the development of investigational gene therapy programs for the treatment of severe neurological diseases, including Parkinson\xe2\x80\x99s disease and Friedreich\xe2\x80\x99s ataxia. (*in collaboration with AbbVie)\n\nAbout the Role:\n\nThis temporary opportunity within the Analytical Development group will support the Manager, Stability Coordination in all aspects of stability operations of clinical and commercial materials (drug substance / drug product).\n_\n\nYour Contributions (include, But Are Not Limited To)\nOversees stability program schedules, implementation, and management for studies conducted by Contracted Service Providers (CSP).\nCreates, reviews, and/or approves batch specific stability study protocols, summary tables, reports, and raw data as appropriate.\nDetermines stability sample requirements through review of test methods, specifications, and project plans to ensure adequate materials are placed in the stability chambers to support product characterization and expiry dating.\nMaintains schedule of stability pulls, testing deadlines, and reporting deadlines. Monitors stability program execution.\nEstablishes Quality Metrics; tracks, trends, and follows-up on quality events, deviations, or any applicable nonconformance.\nEscalate any Out of Specification / Trend (OOS/OOT) results, notifications, or observations according to the applicable Neurocrine SOP.\nPrepares stability data graphs, evaluates stability trends and prepares retest period estimations for clinical trial / development materials and extensions of commercial product retest/expiry dating.\nEnsures stability studies for commercial products are in accordance with current guidances, i.e. ICH, FDA, USP, and WHO, and are aligned with submission stability commitments.\nSupports the maintenance or extension of commercial product retest/expiry dating in collaboration with Commercial Manufacturing.\nRequirements:\nBS Degree in chemistry or closely related field with a minimum of 4 years of experience\nIndustry experience in Pharmaceutical or Medical Device development, manufacturing, or quality control / quality assurance\nKnowledge of a GMP manufacturing environment\nHighly motivated, self-starter with excellent oral and written communication skills\nMust have previous analytical laboratory experience\nHigh level of numeracy; experience in statistical analysis, kinetic analysis, and / or experimental design\nStrong organizational skills and the ability to multi-task\nEnthusiasm for developing an expanding technical and theoretical knowledge base\nFamiliarity with Lean Stability concepts and non-isothermal kinetic analysis is desirable.\nNeurocrine Biosciences is an EEO/AA/Disability/Vets employer.'"
b'Machine Learning Engineering Manager',b'Mitchell International',"b'San Diego, California'","b'We are looking for a Machine Learning Engineering Manager having insatiable intellectual curiosity and passion about developing intelligent products and applying Computer Vision; Artificial Intelligence (Deep learning) and Machine learning techniques to solve real business problems in the P&C sector.\n As a ML Engineering Manager, Your primary focus will be to apply your experience in managing teams and Machine Learning knowledge in developing algorithmic solutions that combine techniques like clustering, Image based pattern mining, predictive modeling, deep learning, statistical Analysis, information retrieval, computer vision and natural language processing and apply them to vast amounts of data. You will help us analyze and discover information hidden in the vast amounts of data (Textual as well as Image), and help us make smarter decisions and deliver AI enabled products to our customers. \n You will be responsible to solve many challenging problems, including\nLeading engineering projects and a team of data scientists from inception to shipped software.\nBuilding models at scale using vast amounts of structured and unstructured heterogeneous types of data.\nEnsuring high accuracy based on industry\xe2\x80\x99s stringent requirements around precision or recall and with minimum Type I and Type II errors.\nGenerating predictions for millions of rows of data with high response time.\nDealing with high data diversity (vast amounts of data will need to be classified and will have multi labelled outcomes).\nDealing with very high dimensionality (expect to work on large matrix computations, variable transformation & feature engineering and selection using PCA and other novel ML techniques).\nDealing with noisy data (build models robust enough for unclassified and/or mislabeled data).\nYou will primarily work on,\nWorking collaboratively in coming up with strategy around labelling vast amounts of images as well as textual data.\nApplying ML techniques like collaborative filtering, bootstrap aggregation (bagging), Random Forest and Ensemble algorithms and generate statistically significant models.\nSelecting features, building and optimizing classifiers using machine learning techniques.\nData mining using state-of-the-art methods.\nExtending company\xe2\x80\x99s data with third party sources of information when needed.\nEnhancing data collection procedures to include information that is relevant for building analytic systems.\nProcessing, cleansing, and verifying the integrity of data used for analysis.\nDoing ad-hoc analysis and presenting results in a clear manner.\nCreating automated anomaly detection systems and constant tracking of its performance.\nBeing creative and going far beyond theoretical solutions to deal with challenges outlined.\nMeeting business requirements with domain knowledge into complex data analytical workflows and efficiently utilize expertise when needed to mitigate risk.\n\nQualifications\nYou must have\nConsistent track record of hiring, managing, and developing great Data Scientists and Engineers.\nDeep & broad understanding of machine learning theory, practice, and tools.\nPassionate problem solver, building the best solutions for the most important problems.\nAbility to communicate thoughtfully, leveraging problem-solving skills and a learning mindset to build long-term relationships.\nAt least 5+ years hands-on software development experience and applied machine learning experience.\nAt least 3+ years of engineering management experience.\nAt a Minimum - Master\xe2\x80\x99s Degree in Computer Science, Data Science, Mathematics or related field \nSound coding knowledge of scientific, distributed programming and scripting languages like Python, PyTorch, PySpark and/or Java.\nSolid foundation in statistics, machine learning, data structures, algorithms, and software design.\nExcellent understanding of machine learning, AI techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, Ensembles, Decisions Trees, and CNNs.\nExperience with common data science toolkits, such as Scikit-learn, MLLib, Google Inception, Google TensorFlow, Weka, NumPy, SciPy, MatLab, Excellence in at least three of these is highly desirable.\nProficiency in using query languages such as SQL, PL/SQL.\nExperience Big Data framework like Hadoop.\nGood applied statistics skills, such as distributions, statistical analysis and testing (T Test), and regression techniques.\nGreat communication skills and Data-oriented personality.\n\nPreferred Qualifications\nExperience with cloud framework like AWS SageMaker, GCP MLE as well as data visualization tools, such as D3.js, Tableau, Kibana, GGplot is a plus.\nFamiliarity of modern statistical learning methods & machine learning Frameworks like H2O, Spark, and PyTorch\nExperience working with cloud infrastructure like AWS, Azure and/or GCP.\nExperience with NoSQL databases, such as MongoDB, HBase is a plus\n  Mitchell International, an equal opportunity employer, values the diversity of our workforce and the knowledge of our people. Mitchell will not discriminate against an applicant or employee on the basis of race, color, religion, national origin, ancestry, sex/gender, age, physical or mental disability, military or veteran status, genetic information, sexual orientation, gender identity, gender expression, marital status, or any other characteristic protected by applicable federal, state or local law.'"
b'Azure Data Architect',b'Perficient',"b'San Diego, CA, US'","b""Overview\n\nAt Perficient you\xe2\x80\x99ll deliver mission-critical technology and business solutions to Fortune 500 companies and some of the most recognized brands on the planet. And you\xe2\x80\x99ll do it with cutting-edge technologies, thanks to our close partnerships with the world\xe2\x80\x99s biggest vendors. Our network of offices across North America, as well as locations in India and China, will give you the opportunity to spread your wings, too.\n\nWe\xe2\x80\x99re proud to be publicly recognized as a \xe2\x80\x9cTop Workplace\xe2\x80\x9d year after year. This is due, in no small part, to our entrepreneurial attitude and collaborative spirit that sets us apart and keeps our colleagues impassioned, driven, and fulfilled.\n\nPerficient currently has a career opportunity for a Senior Azure Solutions Architect.\n\nJob Overview\n\nOne of our large clients has made strategic decision to move all their Hospital management data to a new Azure environment for processing and analytics. This is a multiyear roadmap with many components that will piece into a larger Enterprise level Azure implementation. Perficient subject matter expert will work with the client team to move this data into new environment in a fashion that will meet requirements for applications and analytics.\n\nA Senior Solutions Architect is expected to be knowledgeable in two or more technologies within (a given Solutions/Practice area). The Solutions Architect may or may not have a programming background, but will have expert infrastructure architecture, client presales / presentation, team management and thought leadership skills.\n\nYou will provide best-fit architectural solutions for one or more projects; you will assist in defining scope and sizing of work; and anchor Proof of Concept developments. You will provide solution architecture for the business problem, platform integration with third party services, designing and developing complex features for clients' business needs. You will collaborate with some of the best talent in the industry to create and implement innovative high quality solutions, participate in Sales and various pursuits focused on our clients' business needs.\n\nYou will also contribute in a variety of roles in thought leadership, mentorship, systems analysis, architecture, design, configuration, testing, debugging, and documentation. You will challenge your leading edge solutions, consultative and business skills through the diversity of work in multiple industry domains. This role is considered part of the Business Unit Senior Leadership team and may mentor junior architects and other delivery team members.\n\nResponsibilities\nOwn and aggressively drive forward specific areas of Azure technology architecture and provide architectural solutions/designs to project execution teams for implementation.\nProvide architectural assessments, strategies, and roadmaps for one or more technologies including ADLS and Synapse (formerly knows as ADW)\nLead workshops with many teams to define data ingestion, validation, mining, engineering, modeling, visualization, AI, and analytics\nDesign and Build Azure Data services including ADF, ADL, AMM, ADLS, ADW, Power BI, AML, ABS, and other services within the Azure data framework\nLead the technical planning & requirements gathering phases including estimate, develop, test, manage projects, architect and deliver complex projects\nParticipate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT associates\nContribute to the thought capital through the creation of executive presentations, architecture documents and articulate them to executives through presentations Determine Project and solution estimation and team structure definition\nSupport multiple Agile Scrum teams with planning, scoping and creation of technical solutions for the new product capabilities, through to continuous delivery to production.\nProvide end to end vision and hands on experience with Azure Cloud Platform\nProvide vision and leadership to define the core technologies necessary to meet client needs including: development tools and methodologies, package solutions, systems architecture, security techniques, and emerging technologies\nLiaise with offshore team and clients for resolving technical dependencies, issues, and risks.\nMentor and provide architectural guidance to multiple teams building innovative applications.\nDrive common vision, practices and capabilities across teams.\nEngage with business stakeholders to understand required capabilities, integrating business knowledge with technical solutions\nEngage with Technical Architects and technical staff to determine the most appropriate technical strategy and designs to meet business needs\nDemonstrate broad solutions technical leadership, impacting significant technical direction, exerting influence outside of the immediate team and driving change\n\nQualifications\nAt least 10+ years of experience in designing, architecting and implementing large scale data processing/data storage/data distribution systems particularly in Azure\nMost recent 2+ years of experience in delivering large scale Azure projects\nAt least 5+ years real time and streaming experience in Azure based data solutions\nAt least 3+ years in presales and demo using Azure data services including ADW and ADLS\nAt least 5+ years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms\nAt least 5+ years of demonstrated experience at least in the most recent 2+ years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio\nShould have experience designing service management, orchestration, monitoring and management requirements of cloud platform.\nAt least 3+ years of experience in migrating large volumes of data using standard Azure automation tools from on premise and cloud infrastructure to Azure\nAbility to produce high quality work products under pressure and within deadlines with specific references\nVERY strong communication, solutioning, and client facing skills especially non-technical business users\nAt least 5+ years of working with large multi-vendor environment with multiple teams and people as a part of the project\nAt least 2+ year of working with Power BI\nAt least 5+ years of working with a complex Big Data environment using Microsoft tools\n5+ years of experience with Team Foundation Server/JIRA/GitHub and other code management toolsets\n\nPreferred Skills And Education\n\nMaster\xe2\x80\x99s degree in Computer Science or related field\n\nCertification in Azure platform\n\nPerficient full-time employees receive complete and competitive benefits. We offer a collaborative work environment, competitive compensation, generous work/life opportunities and an outstanding benefits package that includes paid time off plus holidays. In addition, all colleagues are eligible for a number of rewards and recognition programs including billable bonus opportunities. Encouraging a healthy work/life balance and providing our colleagues great benefits are just part of what makes Perficient a great place to work.\n\nMore About Perficient\n\nPerficient is the leading digital transformation consulting firm serving Global 2000 and enterprise customers throughout North America. With unparalleled information technology, management consulting and creative capabilities, Perficient and its Perficient Digital agency deliver vision, execution and value with outstanding digital experience, business optimization and industry solutions.\n\nOur work enables clients to improve productivity and competitiveness; grow and strengthen relationships with customers, suppliers and partners; and reduce costs. Perficient's professionals serve clients from a network of offices across North America and offshore locations in India and China. Traded on the Nasdaq Global Select Market, Perficient is a member of the Russell 2000 index and the S&P SmallCap 600 index.\n\nPerficient is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national, origin, disability status, protected veteran status, or any other characteristic protected by law.\n\nDisclaimer: The above statements are not intended to be a complete statement of job content, rather to act as a guide to the essential functions performed by the employee assigned to this classification. Management retains the discretion to add or change the duties of the position at any time.\n\nOptions\n\nApply for this job online Apply\n\nShare\n\nRefer this job to a friend Refer\n\nSorry the Share function is not working properly at this moment. Please refresh the page and try again later.\n\nShare on your newsfeed\n\nSelect work authorization questions to ask when applicants apply\n\nAre you legally authorized to work in the United States?\nWill you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?"""
b'Staff Data Scientist',b'Wiley Job Network',"b'San Diego, CA, US'",b'Intuit is hiring a Staff Data scientist to focus on our Consumer Tax Group. We are looking for exceptional talent that can improve the bottom lines of our TurboTax offerings.'
b'Machine Learning Performance Engineers',b'Qualcomm',"b'San Diego, CA, US'","b""Job Id\n\nJob Title\n\nMachine Learning Performance Engineers\n\nCompany\n\n\nDivision\n\nQualcomm Technologies, Inc.\n\n\nCorporate Research & Development\n\nJob Area\n\nEngineering - Systems\n\nLocation\n\nCalifornia - San Diego\n\nNorth Carolina - Raleigh\n\nOverview\n\nQualcomm is a company of inventors that unlocked 5G - ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5G\xe2\x80\x99s potential into world-changing technologies and products. This is the Invention Age - and this is where you come in. Qualcomm is utilizing its traditional strengths in digital wireless technologies to play a central role in the evolution of automotive infotainment and autonomous driving. We are investing in several supporting technologies including 4G, 5G, ADAS, and Deep Learning.\n\nThe Qualcomm CR&D team is developing hardware and software solutions for the Qualcomm ADAS system. We are seeking ambitious, bright and innovative engineers with experience in software system design, autonomy, device functional safety concepts and implementations.\n\nJob activities span the whole product life cycle from early R&D to commercial deployment. The environment is fast-paced and requires cross-functional interaction on a daily basis so good communication, planning and execution skills are a must.\n\nWe are looking to staff engineers at multiple levels in systems & software, integration and test. Details of one of the roles we are looking to staff are listed below.\n\nDesired Skills And Aptitudes\nExperience executing, analyzing, and optimizing neural networks in TensorFlow, Caffe2, PyTorch or similar frameworks\nBackground and understanding of neural network operators and mathematical operations: linear algebra, math libraries, desirable\nExperience with industry standard and emerging ML benchmark suites such as MLPerf desirable\nExperience / understanding of machine learning execution engines such as Glow, ONNX Runtime, or similar a plus\nExperience with machine learning accelerators and related software a plus\nStrong skills in analyzing performance of software/hardware solutions on multi-core architectures; understanding of multi-core architecture fundamentals (core, cache, memory, bus, PCIe, etc\xe2\x80\xa6)\nTarget specific code generation and optimization using LLVM or GCC compiler\nPerformance analysis, tuning, and debug using Linux-based profiling tools: perf events, hot-spots, call stacks, Ftrace\nUse of simulators, emulators, JTAG and serial debuggers, a plus\nStrong development skills in C++ and Python\nExcellent communication skills (written and verbal) and team player\n\nEducation Requirements\n\nRequired: Bachelor's, Computer Engineering and/or Electrical Engineering\nPreferred: Master's, Computer Engineering and/or Electrical Engineering\n\nKeywords"""
"b'Scientist, Data Science'",b'Johnson & Johnson',"b'San Diego, CA, US'","b'Janssen Research & Development LLC, a Johnson & Johnson company, is recruiting for a Scientist, Data Science located in La Jolla, CA or Spring House, PA with up to 15% domestic travel.\n\nThe R&D Data Science team within Janssen is looking for an outstanding scientist who is interested in designing, developing, and fielding impactful data science solutions. Our team supports projects from discovery through late development. The scientist will help identify viable data science opportunities and then conceive, develop and implement end to end data analytical solutions. The scientist will be someone who stays on the cutting edge of the data science field in order to implement novel algorithms that influence decisions at various levels in the organization. The role requires both a broad knowledge of existing machine learning algorithms and creativity to invent and customize when necessary. The scientist will be part of a multifaceted, accomplished team that supports multiple R&D therapeutic areas in the discovery and development of innovative medicines.\n\nKey Responsibilities\nWork with colleagues in research and development to design, build and deploy state-of-the art scientific algorithms to support Janssen R&D initiatives.\nAssemble large, complex data sets that meet functional / non-functional business requirements.\nDevelop and apply creative solutions that go beyond current tools to deliver data-driven insights to high-priority scientific problems.\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery.\nAdvocate transparency & action through data storytelling! Establish and execute strategies to increase usage and adoption of Data Science from project conceptualization to completion.\n\nQualifications\nPh.D degree (OR Master\xe2\x80\x99s degree with a minimum of 3 years of relevant experience) in Computer Science, Statistics, Machine Learning & Artificial Intelligence, Physics, Mathematics, Computational Chemistry, Bioinformatics, Computational Biology or a related discipline is required.\n\nRequired\n\nExperience and Skills:\nFamiliarity with large datasets, understanding of data analysis workflows, and/or knowledge of querying languages such as SQL is required.\nProficient with common data science toolkits, such as R, Pandas, TensorFlow, NumPy.\nStrong working knowledge of statistics, machine learning algorithms such as Random Forest, SVM, neural networks, etc. and/or Natural Language Processing techniques is required.\nExperience with visualization software/tools such as Python, R, D3.js, Spotfire, Tableau, etc.\nExperience with big data tools: Spark, Hadoop, Redshift, EMR.\nAbility to effectively communicate technical work to a wide audience.\n\nPrefered\nHandling of healthcare relevant datasets, such as EHR, genomics, clinical trials, insurance claims or registry data.\nExperience designing, developing and deployed web applications, microservices.\nFamiliarity with drug discovery and clinical development processes.\nExperience building processes supporting data transformation, data structures, metadata.\nWe will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\n\nJohnson & Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.\n\nPrimary Location\nUnited States-California-San Diego-\nOther Locations\nNorth America-United States-Pennsylvania-Spring House\nOrganization\nJanssen Research & Development, LLC (6084)\nJob Function\nR&D\nRequisition ID\n2534200402'"
b'Staff Deep Learning/AI Engineer',b'Illumina',"b'San Diego, CA, US'","b'Position Summary\n\nThe Staff Deep Learning/AI Engineer in Illumina\xe2\x80\x99s Finance Performance Management group will focus on applying machine learning/deep learning techniques to finance and business applications. They will be part of analytics team developing machine learning/deep learning methods applied to financial and commercial datasets, with the goal of improving finance and accounting processes.\n\nResponsibilities\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\nMine and analyze data from company databases to drive optimization and improvement of finance and accounting processes\nAssess the effectiveness and accuracy of new data sources and data gathering techniques.\nDeliver solutions leveraging latest machine learning (ML) techniques, including exploratory data analysis, feature engineering, model selection, model evaluation and cross-validation, and deployment and productionalization at all scales.\nUse predictive modeling to increase and optimize forecasting, revenue generation, and other business outcomes.\nDevelop company A/B testing framework and test model quality.\nCoordinate with different functional teams to implement models and monitor outcomes.\nDevelop processes and tools to monitor and analyze model performance and data accuracy.\nMentor and scientifically lead junior members of the team\nBuild strong collaborative relationships with diverse groups within and outside of Illumina\nListed responsibilities are an essential, but not exhaustive list, of the usual duties associated with the position. Changes to individual responsibilities may occur due to business needs.\n\nRequirements\nExperience using statistical computer languages (R, Python, SLQ, etc.) to manipulate data and draw insights from large data sets.\n5-7 years of experience manipulating data sets and building statistical models\nMaster\xe2\x80\x99s or PhD in Statistics, Mathematics, Computer Science or another quantitative field\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nExcellent written and verbal communication skills for coordinating across teams\nAll listed requirements are deemed as essential functions to this position; however, business conditions may require reasonable accommodations for additional task and responsibilities.\nIllumina believes that everyone has the ability to make an impact, and we are proud to be an equal opportunity employer committed to providing employment opportunity regardless of sex, race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship status, and genetic information. If you require accommodation to complete the application or interview process, please contact accommodations@illumina.com. To learn more, visit: https://www.dol.gov/ofccp/regs/compliance/posters/pdf/eeopost.pdf'"
b'SSD Machine Learning Engineer I (Temporary)',b'Kaiser Permanente',"b'San Diego, CA, US'","b""Description\n\nMachine Learning Engineer will provide technical direction, execution and support of machine learning strategies for the SCPMG Medical informatics group. The position entails designing and implementing data pipelining, integration, and optimization of machine learning models to address healthcare's triple aim: to improve the health of populations, to lower the cost of care, and to enhance the care experience.\n\nEssential Responsibilities\nUse statistical and machine learning techniques to develop and improve clinical decision support tools\nDesign and develop data pipelines for machine learning applications\nOptimize machine learning models to scale in real-time streaming applications\nIntegrate and deploy machine learning components in a production environment\nWork closely with machine learning scientists, physicians, and other stakeholders\nDeploy developed products to project environments.\nReview and provide practical feedback on group products and procedures.\nProvide technical feedback on team members' work.\nSeek out open-source software packages or existing software code that can be reused or applied to assigned tasks.\nProduce/archive process related artifacts such as design documents, test plans, wikis, and code review forms.\nExperience\n\nBasic Qualifications:\nMinimum two (2) years of programming or technical related experience.\nEducation\nB.S. in Computer Science, Informatics, Physics, Mathematics, Engineering or related fields.\nLicense, Certification, Registration\nN/A\nAdditional Requirements\nFamiliarity in the following languages, expert in at least one: Python, Java, SQL\nExperience with pipelining, workflow, and orchestration tools such as Apache Airflow, MLFlow, Kubeflow, Kubernates\nExperience with deep learning frameworks (e.g. Tensorflow)\nFamiliarity with classification and regression algorithms\nPreferred Qualifications\nDemonstrated experience in Natural Language Processing\nDemonstrated experience with machine learning integration and deployment in production environments\nDemonstrated experience with Tensorflow Serving or TensorRT\nFamiliarity with C++\nFamiliarity with writing custom CUDA\nExperience with source control tools for code and models/data\nFamiliarity with healthcare terminology\nM.S. in Computer Science, Informatics, Physics, Mathematics, Engineering or related fields.\nThis is a temporary position"""
b'Summer 2020 Machine Learning/HPC Co-Op/Intern - (78821)',b'AMD',"b'San Diego, CA, US'","b'What You Do At AMD Changes Everything\n\nAt AMD, we push the boundaries of what is possible. We believe in changing the world for the better by driving innovation in high-performance computing, graphics, and visualization technologies \xe2\x80\x93 building blocks for gaming, immersive platforms, and the data center.\n\nDeveloping great technology takes more than talent: it takes amazing people who understand collaboration, respect, and who will go the \xe2\x80\x9cextra mile\xe2\x80\x9d to achieve unthinkable results. It takes people who have the passion and desire to disrupt the status quo, push boundaries, deliver innovation, and change the world. If you have this type of passion, we invite you to take a look at the opportunities available to come join our team.\n\nMachine Learning/HPC Internship\n\nThe Role\n\nRTG (Radeon Technologies Group) Architecture team in San Diego is passionate about developing next-generation GPU solutions. As a Machine Learning/HPC architect, you will collaborate with a strong architecture and design team on developing next generation products for data centers and super-computers. You will engage in architecture exploration, modeling and analysis of ML/HPC workloads. Through your experiments and analysis, you will provide valuable insight into new and emerging hardware and software technologies.\n\nThe Person\n\nYou have excellent analytical and problem-solving skills, along with attention to detail. You are an effective team player who focuses on collaboration, team building, mentoring, and furthering team success. You have strong communication, time management, and presentation skills\n\nKey Responsibilities\nWork with architects to propose innovative solutions that can be implemented in SW/HW, validated by developing various models/simulators\nAnalyze HPC/ML workloads, identify performance bottlenecks and propose solutions\nCollect/summarize data or simulation results for consumption by architects and design teams\n\n\nPreferred Experience\nKnowledge of CPU architectures, basic knowledge of GPGPU architectures\nExcellent C/C++/Scripting (Python, etc.) skills\nKnowledge of Graphics/Compute APIs (CUDA/OpenCL/Vulkan etc.) is preferred\nHW/RTL/SystemC experience is a plus\nKnowledge of ML networks, Tensorflow/Pytorch is desirable\n\n\nAcademic Credentials\nBachelor of Science degree with emphasis in Electrical Engineering, Computer architecture, or Computer Science with relevant experience preferred, or\nMaster or PhD degree with emphasis in Electrical Engineering, Computer architecture, or Computer Science\n\n\nLOCATION:\n\nSan Diego, CA\n\nAMD does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services. AMD and its subsidiaries are equal opportunity employers and will consider all applicants without regard to race, marital status, sex, age, color, religion, national origin, veteran status, disability or any other characteristic protected by law. EOE/MFDV\n\nRequisition Number: 78821\nCountry: United States State: California City: San Diego\nJob Function: Student/ Intern/ Temp\n\nAMD does not accept unsolicited resumes from headhunters, recruitment agencies or fee based recruitment services. AMD and its subsidiaries are equal opportunity employers. We consider candidates regardless of age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status. Please click here for more information.'"
b'Deep Learning Research Engineer',b'TuSimple',"b'San Diego, CA, US'","b'TuSimple was founded in 2015 with the goal of bringing the top minds in the world together to achieve the dream of a driverless truck solution. With a foundation in computer vision, algorithms, mapping, and AI, TuSimple is working to create the first commercially viable autonomous truck driving platform with L4 (SAE) levels of safety.\n\nJob Description\n\nOur deep learning team helps autonomous trucks sense and perceive the world. You will play an important role in creating novel algorithms for advanced perception and applying your algorithm on terabytes of data. You will also work closely with other talents in this field in building the next-generation of autonomous sensing algorithms.\n\nResponsibilities\nResearch and prototype developing using deep learning with a special focus on the perception problems of autonomous driving\n\n\nQualifications\nMS/PhD in Computer Science/Electrical Engineering\n3+ years of research or practical experience in applying deep learning on large scale and real world data\nKnowledge in deep learning topics including but not limited to detection, segmentation, 3D perception, and spatial-temporal analysis\nStrong coding skills in Python or C/C++\nFamiliar with at least one of the following deep learning frameworks: MXNET (preferred), TensorFlow, Pytorch, Caffe.\n\n\nPreferred\nTrack record of publishing in top-tier computer vision or machine learning conferences or/and journals.\nPrior academic or industrial experience in autonomous driving.\n\n\nPerks\nCompetitive salary and benefits\nWork with world class AI Engineers\nShape the landscape of autonomous driving\nDaily breakfast, lunch, and dinner\nFull kitchen with unlimited snacks and fruits\nMedical, Vision, and Dental insurance plan\nCompany 401(K) program\nCompany paid life insurance\n\nTuSimple is an Equal Opportunity Employer. This company does not discriminate in employment and personnel practices on the basis of race, sex, age, handicap, religion, national origin or any other basis prohibited by applicable law. Hiring, transferring and promotion practices are performed without regard to the above listed items.'"
b'Sr. Machine Learning Engineer',b'ServiceNow',"b'San Diego, CA, US'","b'Job Title: Senior Machine Learning Engineer\n\nCompany\n\nWork matters. It\xe2\x80\x99s where we spend a third of our lives. And the workplace of the future is going to be a great place. We\xe2\x80\x99re dedicated to bringing that to life for people everywhere. That\xe2\x80\x99s why we put people at the heart of everything we do.\n\nPeople matter. Our people have a passion for learning, building, and innovating. Whether you\xe2\x80\x99re an engineer, a sales professional, a finance professional, or anything in-between, our roles aim to provide each person with meaningful impact and plenty of space to grow.\n\nTeam\n\nCome join the Vulnerability Response Product Engineering team and work with a talented group of developers building best in class automated security orchestration in ServiceNow cloud platform. This team is responsible for the innovation, features, and architecture of products used by many Fortune 500 companies.\n\nRole\n\nAlmost 48% of organizations report that they have had a data breach in the past two years. As the severity and volume of attacks increase, the race to outpace attackers continues. Cybersecurity teams are not equipped enough to keep up and need to leverage the right tools to detect and patch in a timely manner.\n\n60% of breach victims said they were breached due to an unpatched known vulnerability where the patch was not applied\n62% were unaware that their organizations were vulnerable prior to the data breach\n52% of respondents say their organizations are at a disadvantage in responding to vulnerabilities because they use manual processes\n\nWith ServicerNow Vulnerability Response product, we replace manual tasks with automated security orchestration. By unifying the data and processes across IT and security teams, we enable them to prioritize and remediate vulnerabilities and security incidents faster. Using ServiceNow Vulnerability Response, vulnerabilities are patched 60% faster, triage time shrinks by 50% and the existing security and IT staff can handle 50% more workload.\n\nAs a Senior Machine Learning Engineer, you will play a major part in defining the strategy to use massive amounts of data, to prioritize, remediate and predict the vulnerabilities within an Enterprise to reduce and manage exposure to cyber security risk within an organization.\n\nWhat You Get To Do In This Role\nYou will build models against machine learning algorithms and collaborate with industry leading machine learning technologists to address new problem spaces within the ServiceNow ecosystem.\nYou will join a team that takes pride in building extensible and resilient engineering solutions.\nYou will work closely with Product Managers and customers to understand detailed requirements.\nYou will own your solution from design, implementation, automation, delivery and validation with our users.\nYou will define machine learning application strategies and architecture to support these strategies.\nYou will collaborate with an energetic team of like-minded developers, product managers and quality engineers using agile software development methodology.\nYou will work closely with the ServiceNow SaaS platform team on understanding the platform capabilities and extending those capabilities to meet the unique challenges and needs of Vulnerability Response product.\nYou will troubleshoot problems encountered by customers and provide resolutions.\n\nIn order to be successful in this role, we need someone who has:\n6+ years of experience in architecture, design and development of enterprise-grade applications in a high transaction environment.\n2+ years and/or machine learning experience\nKnowledge of Machine Learning algorithms\nStrong understanding of Object-Oriented Analysis, Design Patterns, Data Structures, and time and space-efficient and high performing algorithms\nPassion for software development and problem solving\nHigh energy, self-starter with aptitude for learning new technologies\nKnowledge of Java & JavaScript technologies, with excellent understanding of JavaScript frameworks as Angular, React, Node.js.\nExpert in building RESTful services, and data exchange formats as XML and JSON.\nSolid experience with open source technologies Linux, Apache, Selenium.\nIn-depth knowledge of relational databases (e.g. PostgreSQL, MySQL) and NoSQL databases (e.g. MongoDB)\nExceptional debugging including browser-based debugging, testing, and problem-solving skills.\nExceptional written and verbal communication skills with proven ability to effectively communicate complex technical issues to both technical and non-technical teams.\nPassion for software development, problem-solving, and learning new technologies.\nStrong educational background in Computer Science, Machine Learning, or Mathematics fields, prefer MS/PhD\n\nNote that an exact match on skills is less critical than strong design instincts, high quality coding discipline and enthusiasm for taking on an ambitious project that will reshape the way people interact with enterprise software.\n\nEEOE Statement Section\n\nServiceNow\xe2\x80\x99s EEOE statement is automatically added to each U.S. based job description.'"
b'Deep Learning Research Scientist / Engineer (Deep Learning & Algorithms)',b'Samsung Electronics America',"b'San Diego, CA, US'","b""Description\n\nPosition at Samsung Semiconductor, Inc.\n\nJOB TITLE\n\nResearch Engineer-Deep Learning Theory and Algorithms\n\nRequisition ID\n\nDSA31988\n\nOverview\n\nSamsung Semiconductor, Inc. in San Diego is searching for research engineers at all levels. Candidate will work as part of a team on research and development of algorithms and theory of machine learning. Candidate will research fundamental theoretical aspects of deep learning as well as develop novel techniques to advance the theory and practice of deep learning. Candidate can also apply the developed theory and algorithms to advance the performance of multimedia applications, such as computer vision, augmented reality, natural language processing, or speech processing.\n\nJob Responsibilities\nUnderstand state of the art machine/deep learning concepts, theory, and applications.\nResearch algorithms and theory of learning.\nDevelop machine/deep learning algorithms for mobile processors.\nDevelop simulators and analyze the performance.\nProduce key intellectual property for machine/deep learning.\n\nRequired Skills\nStrong analytical and problem-solving skills\nExpertise in machine/deep learning, optimization, probability theory, statistical inference, information theory, signal processing, and/or image processing\nExcellent communication and teamwork skills\nC/C++, Python, and/or MATLAB coding skills\nPublications in highly ranked journals and conferences\nPhD is required\n\nPreferred Skills\nExperience on popular deep learning frameworks\n*********************************************************************************************************************** Samsung Semiconductor Inc (SSI), an equal opportunity employer, is a world leader in Memory, System LSI, and LCD technologies. Headquartered in San Jose, California, SSI is a wholly-owned U.S. subsidiary of Samsung Electronics Co., Ltd.- the second largest semiconductor manufacturer in the world and the industry's volume and technology leader in DRAM, NAND Flash, SSDs, mobile DRAM and graphics memory. It is one of the largest providers of system logic, imaging and LED lighting solutions, as well as providing advanced process design and manufacturing for fabless companies. Samsung Semiconductor, Inc. also has a research and innovation center with numerous labs providing product design and research in: logic, memory, image sensors, displays and mobile technologies. In addition, the company supports Samsung Display Company, the largest producer of LCD and OLED displays. ***********************************************************************************************************************\n\nLearn more about Samsung Semiconductor here.\n\nA day in the life Samsung Video\n\nSamsung Semiconductor Career Page"""
b'Machine Learning Scientist',b'Amazon',"b'San Diego, CA, US'","b'Description\n\nHave you ever wanted to work on machine learning challenges that will make a lasting impact on society? How about solving key problems that impact the experience of millions of Amazon customers?\n\nAmazon is looking for brilliant Machine Learning Scientists who have the passion to tackle tough problems and help shape a new product from the very early stages in the online grocery shopping space. Together, with a multi-disciplinary team of scientists, engineers, economists, product managers, and subject domain experts, you will help define our customer experience with machine learning at its core. You will define the research and experiment strategy with an iterative approach to create machine learning models and progressively improve the results over time. We are looking for candidates who thrive in fast paced environments and want to invent the future.\n\n\nBasic Qualifications\nPhD or Masters degree in Applied Math, Data Science, Computer Science, Engineering, Machine Learning (or in a highly related field)\n5+ years of hands-on industry experience in predictive modeling, algorithm development, and big data analytics\n5+ year of experience in building machine learning models deployed to production environments\nExperience in applying fundamental machine learning algorithms to solve complex problems\nExperience with modifying standard algorithms (e.g. changing objectives, working-out the math, implementing and scaling)\n7+ years in one or more major programming languages (Python, Java, C++, C, Perl/Ruby, etc.)\nPreferred Qualifications\nPhD in Computer Science, Applied Math, Data Science, Engineering, Machine Learning (or in a highly related field)\n7+ years of hands-on industry experience in predictive modeling, algorithm development and big data analytics\nExtensive experience applying theoretical models in an applied environment\nMastery in fundamentals of problem solving, algorithm design and complexity analysis\nStrong interpersonal and communication skills -- the ability to explain technical concepts and analysis implications clearly to a wide audience, including senior executives, and translate business objectives into action\nAmazon.com is an Equal Opportunity-Affirmative Action Employer \xe2\x80\x93 Minority / Women / Disability / Veteran / Gender Identity / Sexual Orientation\n\n\nCompany - Amazon.com Services LLC\nJob ID: A1037013'"
b'Deep Machine Learning Engineer',b'CyberCoders Middleware Test Compay',"b'San Diego, CA, US'","b""Happy New Year!\nBased in the San Diego, CA area, we are one of the most innovative Image solutions companies in the World. We are well-funded with premiere clients who are utilizing us to solve the most challenging image issues we currently face. Our team is composed of experts in the world of machine learning and image processing with a leadership team that brings experiences from leading global scientific technology firms and pride themselves in their hands-on, mentor level management style. If you are a strong Deep Learning / Machine Learning Scientist with experience in Python OR Java OR C and, obviously, Machine Learning expertise, we would welcome the opportunity to discuss the details.....What You Need for this PositionRequirements:\n- 3+ years of Deep / Machine Learning experience\n- Master's Degree or PhD HIGHLY preferred. Points if you have published papers on the same topics.\n- Supervised and Unsupervised machine learning a must\n- Timeseries and/or Deep Learning a big plus\n- Algorithm development experience\n- Communicates very well\n- Research type\n- Excellent communication and written skills\n\nNice to have skills:\n- Strong interest in creating solutions to problems\n- Experience in and interest in learning new technologies\n- Experience managing multiple projects and working independentlyTop Reasons to Work with UsFast growing.\nWell-funded.\nStart-up equity.What's In It for YouWe are willing to offer excellent compensation packages including annualized pay potential of $110k to around $135k, plus EQUITY, and excellent benefits. We are located in a centrally located area with access to 2 major freeways, and plenty of parking.So, if you are a recent PHD grad, or PHD grad with experience in Machine Learning, please apply today!\n\n*** You can also email me directly at eric.shaner@cybercoders.com\n*** Find/connect with me on LinkedIn - www.linkedin.com/in/analytics\nDesired Skills and Experience\nLinear, Non-linear, Deep Learning, Supervised Techniques, Timeseries Analysis, UnSupervised Techniques"""
b'Data Scientist - Statistics and Machine Learning',b'Q-Centrix',"b'San Diego, CA, US'","b'Who are we? Q-Centrix is a leading healthcare information solutions provider with offices in Portsmouth, NH, Chicago, and San Diego, plus more than 900 clinical experts working remotely in 49 states. Our team of smart, ambitious, and fun-loving healthcare professionals are 100% focused on improving the quality of patient care at hospitals throughout the country.\n\nAbout the Job Q-Centrix is looking for a Junior Data Scientist to join us at our San Diego office. We are a data driven and automation focused organization that loves to gain new insights from the massive amount of structured and unstructured data that is collected on a daily basis.\n\nAs a Data Scientist, You Will\nWork on various projects ranging from statistical analysis, data pipelines, machine learning, and advanced signal processing to software engineering\nWrite complete softwares to implement domain agnostic generalized mathematical models that could be deployed on any data\nWork closely with leaders across the organization to look for workflow automation opportunities and execute them\nBuild advanced software solutions that will help prepare the data for analytics projects\nLeverage your experience working with supervised machine learning methods such as ensemble tree classifiers, support vector machines, neural networks, and Bayesian methods to create state-of-the-art predictive models\nCommunicate your successful efforts through documentation and white papers\nKnowledge, Skills, Abilities And Qualification Requirements\nM.S. in Applied Mathematics, Computer Science, or Electrical Engineering and 3+ years of prior experience working as a Data Scientist, machine learning engineer, or data engineer is required\n3+ year of hands-on experience in software engineering, deep learning, and signal processing is highly desired\nQuality Requirements\nPositively contribute to our work environment values of professionalism, mutual respect, teamwork, and collaboration.\nKey Competencies\nProfessionalism and customer service orientation\nAbility to manage multiple projects\nPlanning, organization and excellent time management\nAttention to detail and unrelenting passion for delivery\nFlexibility, adaptability, and teamwork\nYou\xe2\x80\x99re Our Dream Candidate If You\nLove solving business problems with mathematics and programming\nHave a proven track record for writing world class software solutions with Python, Ruby, Java, or Go\nAre passionate about automation and consider yourself an advanced python software developer\nBuilt and operationalized signal processing solutions\nAre intimately familiar with the latest techniques in predictive data modeling including deep learning\nLove data science competitions and are an active participant in kaggle competitions\nLove writing detailed documentation of your completed research, and lastly,\nYou love dogs and cats!\nWho are we?\n\nAt Q-Centrix, we hire people who love learning, value innovation and believe in our mission and values to improve outcomes in healthcare. We applaud qualified applicants who are accountable and committed to producing quality work. As an Equal Opportunity Employer, we support and value diversity, dignity and respect in our work environment, and are committed to creating an inclusive environment in which everyone can thrive.\n\nWe employ people based on the needs of the business and the job, and their individual professional qualifications. Here\xe2\x80\x99s what does not impact our employment decisions: race, religious creed, religion, color, sex, sexual orientation, pregnancy, parental status, genetic information, gender, gender identity, gender expression, age, national origin, ancestry, citizenship, protected veteran or disability status, health, marital, civil union or domestic partnership status, or any status or characteristic protected by the laws or regulations in locations where we operate. If you are an individual with a qualified disability and you need an accommodation during the interview process, please reach out to your recruiter.\n\nWe celebrate and embrace these differences, and take pride in our commitment to being an equal opportunity team.'"
b'Software Engineer',b'PointPredictive Inc.',"b'San Diego, California'","b'We are looking for a junior to mid-level software engineer, whose core skills being Python and experience with Amazon Web Services in Our San Diego Offices.\n\nThis person will act as a generalist supporting senior staff, and will contribute in the following areas:\n\nHelp optimize Python analytics applications and AWS infrastructure for performance.\nBuild-out a robust software testing and release pipeline.\nDevelop automated code tests.\nResearch and develop production monitoring tools.\nContribute partially in a DevOps role.\nDevelop production-level data pipelines for company-critical data science and machine learning solutions\nDevelop tooling, optimization, and testing around core data science work\nBuild and maintain production-level python libraries for the data science team\nLeverage open-source tools and cloud computing technologies comfortably\nExecute best practices in version control and continuous integration/delivery\nOwn and drive projects from conception to completion \n\nIdeally, prior experience includes:\n\n1-5 years as software engineer, with Python as a primary language. Familiar with the Pandas library would be helpful.\nSome experience working in an analytics or data science environment, or exposure to machine-learning.\n1-5 years experience with several AWS services, preferably some of Lambda, EC2, S3, Cloudwatch, API Gateway, and S3.\n1-2 years experience with relational (MySQL, PostgresQL) and NoSql databases (AWS Dynamo DB, MongoDB).\nFamiliarity with version control principles, ideally git.\n\nBonus Points for:\n\nKnowledge of AWS Networking: Virtual Private Cloud (VPC), Subnets, Network Address Translation (NAT) services.\nWindows developer or system administrator skills (Windows Server 2012 or greater, ideally Windows Server 2016)\nExperience with Node.js and Nginx.\nAbility to administer an SFTP server, add users, create keys/credentials'"
b'Data Engineer',b'Accenture',"b'San Diego, CA, US'","b""This role is located in either Sacramento or Los Angeles, CA, and relocation would be required if hired.\n\nWe are:\n\nApplied Intelligence, the people who love using data to tell a story. We\xe2\x80\x99re also the world\xe2\x80\x99s largest team of data scientists, data engineers, and experts in machine learning and AI. A great day for us? Solving big problems using the latest tech, serious brain power, and deep knowledge of just about every industry. We believe a mix of data, analytics, automation, and responsible AI can do almost anything\xe2\x80\x94spark digital metamorphoses, widen the range of what humans can do, and breathe life into smart products and services. Want to join our crew of sharp analytical minds?\nVisit us here to find out more about Applied Intelligence.\n\nYou Are:\n\nA Spark Big Data engineering pro\xe2\x80\x94someone who thrives in a team setting where you can use your creative and analytical prowess to obliterate problems. You\xe2\x80\x99re passionate about digital technology, and you take pride in making a tangible difference. You have communication and people skills in spades, along with strong leadership chops. Complex issues don\xe2\x80\x99t faze you thanks to your razor-sharp critical thinking skills. Working in an information systems environment makes you more than happy.\n\nThe Work:\n\nConsult as part of a team that is in charge of building end-to-end digital transformation capabilities and lead fast moving development teams using Agile methodologies.\nDesign and build Big Data and real-time analytics solutions using industry standard technologies and work with data architects to make sure Big Data solutions align with technology direction.\nLead by example, role-modeling best practices for unit testing, CI/CD, performance testing, capacity planning, documentation, monitoring, alerting and incident response.\nKeep everyone from individual contributors to top executives in the loop about progress, communicating across organizations and levels. If critical issues block progress, refer them up the chain of command to be resolved in a timely manner.\nOptimize NLU model by implementing NLP systems, performing intent classification and entity extraction and user testing.\nDevelop and maintain digital conversational flows, dialog research, Architect, Prototype and Test Dialogue Management system and Natural Language Generator Connect to data source (e.g. multiple xml documents) and query database.\nPinpoint and clarify key issues that need action, lead the response and articulate results clearly in actionable form.\nShow a strong aptitude for carrying out solutions and translating objectives into a scalable solution that meets end customers\xe2\x80\x99 needs within deadlines.\nCollaborate with research teams working on a variety of deep learning and NLP problems.\n\nHere's what you need:\n\nBachelor's degree in Computer Science, Engineering, Technical Science or 12 years of experience in programming and building large scale data/analytics solutions operating in production environments.\nMinimum 2+ years of expertise in designing, implementing large scale data pipelines for data curation, feature engineering and machine learning, using Spark in combination with pySpark, Java, Scala or Python; either on premise or on Cloud (AWS, Google or Azure).\nMinimum 1 year of designing and building performant data tiers (or refactoring existing ones), that supports scaled AI and Analytics, using different Cloud native data stores on AWS, Azure and Google (Redshift, S3, Big Query, SQLDW etc.) as well as using NoSQL and Graph Stores.\nMinimum 1 year of designing and building streaming data ingestion, analysis and processing pipelines using Kafka, Kafka Streams, Spark Streaming and similar cloud native technologies.\nBonus points if:\n\nMinimum 1 year of designing and building secured and governed Big Data ETL pipelines, using Talend or Informatica technologies; for data curation and analysis of large le production deployed solutions.\nExperience implementing smart data preparation tools such as Palate, Trifacta, Tamr for enhancing analytics solutions.\nMinimum 1 year of building Business Data Catalogs or Data Marketplaces for powering business analytics using technologies such as Alation, Collibra, Informatica or custom solutions.\n\nImportant Information:\n\nApplicants for employment in the US must have work authorization that does not now or in the future require sponsorship of a visa for employment authorization in the United States and with Accenture (i.e., H1-B visa, F-1 visa (OPT), TN visa or any other non-immigrant status).Candidates who are currently employed by a client of Accenture or an affiliated Accenture business may not be eligible for consideration. Accenture is an EEO and Affirmative Action Employer of Females/Minorities/Veterans/Individuals with Disabilities.\n\nEqual Employment Opportunity:\n\nAll employment decisions shall be made without regard to age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by federal, state, or local law. Job Candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.\n\nAccenture is committed to providing veteran employment opportunities to our service men and women."""
b'Data Scientist',b'Realty Income Corporation',"b'San Diego, CA, US'","b""Description\n\nRealty Income, The Monthly Dividend Company\xc2\xae, one of four San Diego based S&P 500 companies dedicated to providing shareholders with dependable monthly income. Our company is structured as a REIT, and its monthly dividends are supported by the cash flow, over 6,000 real estate properties owned under long-term lease agreements with regional and national commercial tenants. To date, our company has declared over 600 consecutive common stock monthly dividends throughout its 50-year operating history and has continually increased the dividend since Realty Income's public listing in 1994 (NYSE: O). Our company attracts individuals who value integrity, perseverance, and teamwork. If you appreciate working on a truly collaborative team in a professional environment in a company that encourages a work-life balance, make sure to apply today!\n\nAs Realty Income\xe2\x80\x99s Data Scientist, you will be a ground-breaking leader who works as part of a team that builds and owns analytics-based assets, bringing the value of real estate predictive analytics to our business leaders. You will shape the future of a data-savvy organization, in part by driving processes for data extraction and analysis, and by creating new lines of thinking within our core real estate and investing business. In this role, you will design, develop and execute predictive analytics work streams that serve as the catalyst to increase ROI for the business.\n\nYour Contribution to the Team Includes\n\nPredictive Analytics\nBuild predictive analytics for use cases such as: Portfolio Management; Development; Acquisitions\nWork with business teams to identify, develop and deliver new use cases over time\nPrioritize predictive analytics initiatives based on multiple factors, e.g., ROI/productivity, business continuity, ease of delivery\nDeliver insights with user friendly end-products such as web-based tools, reports (e.g., Power BI) or visualizations that are accessible and understandable for business users\nEnsure we remain state of the art by keeping up on the latest technologies and approaches, attending conferences or other events as needed\nInfrastructure for Predictive Analytics\nCreate the vision for static and dynamic data architecture for predictive analytics encompassing internal data in our ERP system or other data sources as well as externally sourced data (e.g., census information news feeds)\nOversee the process for data management leveraging IT and business teams using clearly articulated responsibility matrices and timelines, including meeting internal audit requirements for data/process integrity\nCoordinate with the IT team to buy or license required tools, data and feeds\nWork with the IT team as they set up the necessary infrastructure and processes to support predictive analytics, e.g., ETL from the ERP system to data warehouse/lake\nDetermine how and when to take and store \xe2\x80\x9csnapshots\xe2\x80\x9d of data so that we can go back in time to test new models and approaches\nOrganizational Relationships\nWork closely with business teams, IT, internal audit and enterprise risk to define end products and processes\nCreate cross-functional working groups or teams as needed to initiate, approve or complete work\nUpdate the Investment Committee monthly or quarterly on key matters such as portfolio risk\nSupport business teams in the achievement of their objectives using predictive analytics tools\nPerforms other duties as assigned.\n\nRequirements\n\nWhat You\xe2\x80\x99ll Need to be Successful\nPHD Preferred in a relevant discipline, e.g., machine learning, statistics, applied mathematics, econometrics, or operations research\n3-5+ years of experience providing advanced analytics within a business setting\nPrior work experience within real estate or financial services is preferred, but not required\nProgramming experience in Python, Spark and SQL. Java/Scala is a plus\nExperience with RDBMS systems like PostgreSQL and NoSQL systems like MongoDB\nHands-on experience in Microsoft Azure and Amazon EC2 cloud platform\nDemonstrated ability to design and implement ETL workflows across both Windows and Linux environments\nAbility to clearly communicate ideas, orally or via written communications\nTo all recruitment agencies: Realty Income does not accept unsolicited agency resumes. Please do not forward resumes to our job\xe2\x80\x99s alias, Realty Income employees, or any company location. Realty Income is not responsible for any fees related to unsolicited resumes."""
b'Business Intelligence Analyst - Customer Experience and Analytics',b'BD',"b'San Diego, CA, US'","b'Job Description Summary\n\nBD\xe2\x80\x99s Global Customer Services (GCS) organization is transforming the customer experience on our journey to advance the world of health. The mission of the Customer Experience & Analytics team is to partner with GCS businesses to deliver actionable insights, resulting from analysis of Voice of the Customer (VOC) data and operational data, that drive meaningful improvement in customer and associate experience.\n\nWe are seeking a Business Intelligence Analyst, Customer Experience Analytics that will develop actionable research hypotheses, prepare and analyze datasets, develop predictive models, and present key findings to stakeholders in a clear way. This individual should be highly analytical and capable of truly understanding data to identify new opportunities and actionable insights that drive BD\xe2\x80\x99s customer experience. In addition to technical capabilities, this individual will be extremely collaborative and continuously seeking new opportunities in a consultative manner.\n\nJob Description\n\nJob Summary\n\nBD\xe2\x80\x99s Global Customer Services (GCS) organization is transforming the customer experience on our journey to advance the world of health. The mission of the Customer Experience & Analytics team is to partner with GCS businesses to deliver actionable insights, resulting from analysis of Voice of the Customer (VOC) data and operational data, that drive meaningful improvement in customer and associate experience.\n\nWe are seeking a Business Intelligence Analyst, Customer Experience Analytics that will develop actionable research hypotheses, prepare and analyze datasets, develop predictive models, and present key findings to stakeholders in a clear way. This individual should be highly analytical and capable of truly understanding data to identify new opportunities and actionable insights that drive BD\xe2\x80\x99s customer experience. In addition to technical capabilities, this individual will be extremely collaborative and continuously seeking new opportunities in a consultative manner.\n\nThe Core Responsibilities Include\nPartner with internal customers to understand stakeholder needs; translate business needs into analytical requirements that can be answered with available data using statistical and machine learning methods\nExtract and prepare data sets from various sources including Hadoop, SQL Server, flat files, etc\nDevelop visualizations to help explain patterns and trends in large data sets\nCommunicate analyses and results to executive leadership backed by data and coupled with actionable insights to drive business decisions\nRecognize and adopt industry best practices in reporting and analysis\nSupport the survey methodology of the NPS program, supported by Qualtrics, and capture insights\nDraw conclusions and prioritize actions/recommendations with limited data\n\nQualifications\nBachelor\xe2\x80\x99s or Master\xe2\x80\x99s degree in a quantitative field such as Data Science, Analytics, Computer Science Engineering, Systems Engineering, or Statistics\n3+ years of experience in a role requiring application of analytic skills to integrate data into operational/business planning\nStrong experience with BI tools (e.g., Power BI, Tableau), data extraction, data manipulation, and analysis; demonstrated strength using SQL queries in a business environment\nStrong quantitative and qualitative analytical skills with ability to distill large data sets into meaningful insights and takeaways\nStrong PowerPoint skills and ability to translate data insights into impactful presentations\nSuperior verbal and written communication skills with the ability to effectively advocate technical solutions to non-technical audiences\nAbility to cultivate and maintain productive working relationships with internal business partners and work successfully in a highly cross-functional matrix organization\nExtreme curiosity to understand business operations and data with a desire to work across groups to do so\nQualtrics and Salesforce experience a plus but not required\n\nPrimary Work Location\nUSA CA - San Diego Bldg A&B\n\nAdditional Locations\n\nWork Shift\n\nJob Category: Professional Services'"
b'Data Scientist',b'Broadcom Inc.',"b'San Diego, CA, US'","b'Job Description\n\nDo you enjoy analyzing data? Creating products that solve real-world problems and taking them into production? Working with colleagues to find novel ways to approach difficult problems in fintech?\n\nWe are looking for people with graduate degrees (MS or PhD) in an analytical field, e.g., Physics, Statistics, Electrical Engineering, Computer Science, Oceanography, Applied Mathematics, Data Science. You should understand how to apply mathematics to real-world problems, including linear algebra, vector calculus, etc.\n\nWe Are Looking For People Who\nHave strong scientific coding aptitude \xe2\x80\x93 efficient code that is numerically stable and of production quality.\nAre strong analytical thinkers, including reasoning through probabilities and statistics, as well as delving into detailed deterministic thinking and using individual examples\nCan learn new business domains, understanding the context for the data science\nCan learn and apply machine learning and AI techniques to new domains, with a focus on client needs\nHave interest in working from start to finish: gather data, clean and prepare, model, code, package, guide into production, and help clients use the results.\nEnjoy working with data.\nCan communicate complex and sophisticated ideas to people without scientific backgrounds\nEnjoy working in a team environment\n\nYou Will Be Responsible For\nWorking on problems in the fintech area, including online payments, banking, and other areas\nWorking on a team under the leadership of other Data Scientists\nCommunicating with clients, internal and external, to understand the business problems that we can solve using machine learning and AI\nAnalyzing and understanding data from different domains, including data cleansing and detailed analysis of relationships between fields\nDeveloping supervised, unsupervised, and reinforcement models in the laboratory\nCoding models for production, with particular attention to efficient use of computational resources and robustness of the code\nWorking with Software Engineers and SaaS Operations to package and deploy the models\nMonitoring the models to ensure that they are working properly, and generalizing to new data\nWorking with clients to ensure that they are using the results of the models effectively.\nSkills needed include: excellent written and verbal communications, and presentation skills.\n\nLanguages needed include a subset of: Python, C++, Unix scripting, SAS, PySpark, Scala, Perl, C\n\nStrong command of Unix is preferred.\n\nExperience (Data Scientist): Fresh Graduate degree holders are welcome to apply. Industry experience greatly appreciated.\n\nIf you are located outside USA, please be sure to fill out a home address as this will be used for future correspondence.'"
b'Data Scientist',b'HP',"b'San Diego, CA, US'","b""Data Scientist\n\nAs Data Scientist at HP Inc. in San Diego, you will join an industry-leading organization and work on developing frameworks for systematic data science modeling to identify optimal marketing, pricing and sales decisions for our Printing & PC business. Working within a dynamic, highly skilled and diverse Pricing Strategy and Analytics team (economists, engineers, scientists or even musicians ? majority of them with a PhD) you will build models and develop tools and analytical processes to develop pricing and marketing strategies for HP printers, cartridges and PCs around the world.\n\nResponsibilities\nDevelop and apply statistical methods to analyze the effect of pricing and sales decisions on business performance\nDevelop and implement frameworks and processes for systematic and automated data analysis\nDevelop tools to ingest, merge, and clean data sets\nImmerse yourself in very large data sets and complex problems\nVisualize and interpret the results of analyses, and create strategy recommendations\nPresent the results and the corresponding recommendations to the relevant stakeholders, including senior leadership\n\nQualifications\nInterest in data science, pricing, economics, and/or consumer behavior\nScientific thinking and ability to design and critically analyze quantitative research\nAbility to think creatively about research problems and invent original solutions to modeling challenges\nAbility to build and interpret complex linear regression models, with machine learning experience a plus\nKnowledge of and experience in deploying numerical optimization routines\nProficiency with Python and R is required\nStrong analytical skills, with a high level of attention to detail\nProficiency in Microsoft Excel and Microsoft PowerPoint\nExcellent written and verbal communication skills\n\nNice-To-Haves\nKnowledge of price optimization approaches, price discrimination models and a general knowledge of main concepts from the industrial organization literature\nExperience working with large data sets\nExperience in data engineering\nExposure to digital marketing\nExperience working in or collaborating with industry\nExperience creating data visualizations\nAbility to build dashboards and other tools using front-end development skills\nExperience in software development\n\nEducation & Experience\nBachelor?s, Master's or PhD degree in Engineering, Computer Science, Economics, Quantitative Marketing, Mathematics, Physics or equivalent\n1-3 years? experience including graduate or postgraduate research"""
b'Analytics Engineer',b'ICF',"b'San Diego, CA, US'","b'ICF is a premier provider of Full-spectrum cyberspace operations and analysis services to the Federal government. Our experts use analytics, machine learning and automation to identify and respond to network anolmalies, ensuring resiliency and mission assurance for our clients. We develop the next generation of Cyber Security for our clients, providing monitoring and active network defense of their networks.\n\nWe are seeking an Analytics Engineer to join our team supporting the Navy in San Diego\n\nExperience And Qualification Required\nCybersecurity Workforce (CSWF) IAT Level II\nStrong knowledge of scripting, programming or application programming interface\nSkills to develop extensibility to support diverse analytics for multiple use cases\nKnowledge of military and commercial data transports\nExperience in designing solution sets that operate in a low computational provide and in isolated environments\nExperience developing capabilities that quickly process and provide to end user critical data requests\nExperience in designing, developing, testing, implementing and maintaining large-scale data analytics techniques and technologies to include indexing techniques,information retrieval, data frameworks, machine learning, predictive analytics, data mining and statistical analysis\nExperience in developing analytics supporting cyber security use cases that supports decision aids at the strategic, operational and tactical levels of maritime warfare\nMinimum security clearance of TOP SECRET; ability to\nobtain TS/SCI clearance\n\nAnd Either\nMinimum of BS degree in related field and at least five (5) years of experience in skills identified above\nOR- Formal degree requirement may be evaluated and waived if applicant provides at least seven (7) years of experience in skills identified above\n\nWorking at ICF\n\nWorking at ICF means applying a passion for meaningful work with intellectual rigor to help solve the leading issues of our day. Smart, compassionate, innovative, committed, ICF employees tackle unprecedented challenges to benefit people, businesses, and governments around the globe. We believe in collaboration, mutual respect, open communication, and opportunity for growth. If you\xe2\x80\x99re seeking to make a difference in the world, visit www.icf.com/careers to find your next career. ICF\xe2\x80\x94together for tomorrow.\n\nICF is an equal opportunity employer that values diversity at all levels. (EOE \xe2\x80\x93 Minorities/Females/ Protected Veterans Status/Disability Status/Sexual Orientation/Gender Identity)\n\nReasonable Accommodations are available for disabled veterans and applicants with disabilities in all phases of the application and employment process. To request an accommodation please email and we will be happy to assist. All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations. Read more about non-discrimination: and .\n\nSan Diego, CA (CA74)'"
b'Data Scientist',b'National University',"b'San Diego, CA, US'","b'Position Summary\n\nUnder the direction of the VP, Chief Data Officer, the Data Scientist provides analytical leadership to support the data and analytical needs of the entire University. This position is responsible for developing and maintaining National University\xe2\x80\x99s analytical infrastructure to provide timely and reliable data for informed decision-making. In addition, the incumbent will apply advanced statistical, data mining, machine learning and various predictive modeling techniques to provide information, knowledge, coordination, and tools that support the growth and continued success of National University. The VP, Chief Data Officer provides general oversight concerning objectives and projects for this position and completes an annual evaluation of position.\n\nEssential Functions\nResponsible for the development, maintenance and advancement of National University\xe2\x80\x99s analytical\ninfrastructure.\nDevelop and maintain data extraction, transfer and loading from various sources.\nImplement appropriate security measures throughout the data pipeline.\nResponsible for maintaining metadata management and data quality activities so that data are accurate, reliable and documented.\nApply advanced predictive modeling, data mining, machine learning and statistical techniques to enable\ninformed decision-making, student support, and strategic initiatives.\nProvide analytical guidance to the entire University.\nFacilitate the transmission and understanding of data to enable fact-based decisions to various stakeholders, such as leadership, faculty and staff.\nProvide reliable and timely data that supports strategic planning, student success initiates, and educational and operational effectiveness.\nUtilize various software tools and reporting services to deliver actionable data to end-users in a digestible form\n\nSupervisory Responsibilities: NA\n\nRequirements\n\nEducation & Experience\nBachelor\xe2\x80\x99s degree in a related discipline (Statistics, Mathematics, Data Science, Social Sciences).\nAdvanced degree in a related field or evidence of pursuit of advanced studies or degree strongly preferred.\nOne to three (1-3) years of recent professional experience in data analysis and/or data engineering.\nTechnical / Functional Skills\nProficient in the following software applications: Microsoft Office Applications; Microsoft SQL Server; Microsoft\nAzure; Redmine; Peoplesoft/SOAR; Relational Database Management; Tableau/Power BI; and Statistical\nanalysis software (R, Python, or the equivalent) required.\nExperience and thorough knowledge in data collection and analysis techniques.\nCompetencies\nRequires analytic ability and frequent independent judgment based on knowledge of University policy and precedent.\nFluency in information technologies, including high level of proficiency and understanding with data mapping, data mining, machine learning, statistics, cloud computing and analytical programming languages such as SQL, R and/or Python.\nProven ability to independently synthesize, implement, analyze and report findings of research studies.\nExceptional interpersonal, organizational, and problem-solving skills as well as effective written and verbal communications.\nProven ability to troubleshoot problems and overcome obstacles with creative solutions.\nCapable of performing in a professional and friendly manner despite conditions of deadlines and pressure.\nKeen ability to transform vague requirements into clear, objective, and actionable tasks.\nFully accustomed to working on multiple projects, both independently and as a team member.\nSelf-starter with a positive attitude, intellectual curiosity and a passion for analytics\n\nPhysical Demands / Environment\n\nTravel: none required'"
b'Data Specialist',b'Veyo',b'Greater San Diego Area',"b'Veyo is using its platform and app-based transportation services to reinvent the medical logistics world. Our company is using technology to pioneer new operational models to help make transportation more powerful and more reliable for the healthcare industry.\n\nWhen you work at Veyo, you\xe2\x80\x99re helping to solve one of the nation\xe2\x80\x99s growing healthcare challenges -- ensuring patients get to and from their medical appointments, safely and on-time. We are using smart design and innovative technology to make patient transportation safer and more connected. In the process, we\xe2\x80\x99re transforming the entire industry.\n\nWhat you can expect:\nUse technology to help people lead healthier lives\nWork with an incredibly talented, intelligent team\nAbility to try out new technologies to gauge fit for business needs\nEncouragement to grow professionally and personally \xe2\x80\x93 attend conferences, give knowledge sharing presentations, pick your career path\n\nWhat we\xe2\x80\x99ll expect from you:\nBe committed to the health and safety of our passengers\nHelp shape the strategy and direction of the company and an industry\nSolve algorithmic problems in the logistics, healthcare and operations space through research, experiments and development and support deployment of these solutions into a real world environment\nEntrepreneurial. Everywhere you go, you can\xe2\x80\x99t help but mobilize people, build things, solve problems, roll up your sleeves, go above and beyond, raise the bar. You are an insatiable doer and driver\nAbility to effectively collaborate with and communicate complex concepts to both technical and non-technical audiences at all levels, from C-Level to individual contributors.\nUnderstand the latest industrial and academic developments in AI/ML, and apply it to create prototypes for demonstration\nWork with development teams to mature these algorithms into production quality programs\nDo applied research on a wide array of Operations research and machine learning projects.\n\nRequired Skills:\nAdvanced degree in Statistics, Applied Mathematics, Operations Research, Computer Science, or a related quantitative field.\n5+ years of experience crafting advanced models and familiar with statistical methods applied to large data sets\nProven experience with optimization libraries, scripting languages (Python, R, etc.), SQL and statistical tools, major object-oriented programming languages, and simulation software\nFamiliar with the Microsoft stack C#, .Net 4.5 is a plus\nFamiliarity with GoLang is a plus\n\n\nWe like the following personality traits: Friendly, social, outgoing, positive, passionate, cool under pressure, detail-oriented, deadline oriented, quick learner, multi-tasker, great sense of humor.\n\nWe\xe2\x80\x99re looking for people that love the opportunity to be involved in strategy and management at the top level, but also aren\xe2\x80\x99t scared to get their hands dirty and do what needs to be done to make things happen! We move quickly, and our team doesn\xe2\x80\x99t know the meaning of \xe2\x80\x9cnot my job.\xe2\x80\x9d We want people that want to get things done and can check their ego at the door.\n\nWe thank all applicants for their interest and effort in applying for this position. This position is only for candidates legally allowed to work in the US. EOE.\n\nVeyo is proud to be an equal opportunity workplace. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status.'"
"b'Temp Scientist, GMP/Data Review'",b'Neurocrine Biosciences',"b'San Diego, CA, US'","b'Who We Are\n\nAt Neurocrine Biosciences, we pride ourselves on having a strong, distinctive and positive culture based on our shared purpose and values. We know what it takes to be great, and we are as passionate about our people as we are about our purpose - to relieve patient suffering and enhance lives.\n\nWhat We Do\n\nNeurocrine Biosciences (Nasdaq: NBIX) is a neuroscience-focused, biopharmaceutical company with more than 25 years of experience discovering and developing life-changing treatments for people with serious, challenging and under-addressed neurological, endocrine and psychiatric disorders. Headquartered in San Diego, Neurocrine Biosciences specializes in targeting and interrupting disease-causing mechanisms involving the interconnected pathways of the nervous and endocrine systems.\n\nThe company\xe2\x80\x99s diverse portfolio includes two FDA-approved treatments INGREZZA\xc2\xae (valbenazine) for tardive dyskinesia and ORILISSA\xc2\xae (elagolix) for endometriosis*, as well as clinical development programs in multiple therapeutic areas, including Parkinson\xe2\x80\x99s disease, chorea in Huntington disease, congenital adrenal hyperplasia, uterine fibroids* and polycystic ovary syndrome.* As part of a strategic collaboration with Voyager Therapeutics, Neurocrine Biosciences is also focused on the development of investigational gene therapy programs for the treatment of severe neurological diseases, including Parkinson\xe2\x80\x99s disease and Friedreich\xe2\x80\x99s ataxia. (*in collaboration with AbbVie)\n\nAbout the Role:\n\nThis temporary opportunity within the Analytical Development group will support the Manager, Stability Coordination in all aspects of stability operations of clinical and commercial materials (drug substance / drug product).\n_\n\nYour Contributions (include, But Are Not Limited To)\nOversees stability program schedules, implementation, and management for studies conducted by Contracted Service Providers (CSP).\nCreates, reviews, and/or approves batch specific stability study protocols, summary tables, reports, and raw data as appropriate.\nDetermines stability sample requirements through review of test methods, specifications, and project plans to ensure adequate materials are placed in the stability chambers to support product characterization and expiry dating.\nMaintains schedule of stability pulls, testing deadlines, and reporting deadlines. Monitors stability program execution.\nEstablishes Quality Metrics; tracks, trends, and follows-up on quality events, deviations, or any applicable nonconformance.\nEscalate any Out of Specification / Trend (OOS/OOT) results, notifications, or observations according to the applicable Neurocrine SOP.\nPrepares stability data graphs, evaluates stability trends and prepares retest period estimations for clinical trial / development materials and extensions of commercial product retest/expiry dating.\nEnsures stability studies for commercial products are in accordance with current guidances, i.e. ICH, FDA, USP, and WHO, and are aligned with submission stability commitments.\nSupports the maintenance or extension of commercial product retest/expiry dating in collaboration with Commercial Manufacturing.\nRequirements:\nBS Degree in chemistry or closely related field with a minimum of 4 years of experience\nIndustry experience in Pharmaceutical or Medical Device development, manufacturing, or quality control / quality assurance\nKnowledge of a GMP manufacturing environment\nHighly motivated, self-starter with excellent oral and written communication skills\nMust have previous analytical laboratory experience\nHigh level of numeracy; experience in statistical analysis, kinetic analysis, and / or experimental design\nStrong organizational skills and the ability to multi-task\nEnthusiasm for developing an expanding technical and theoretical knowledge base\nFamiliarity with Lean Stability concepts and non-isothermal kinetic analysis is desirable.\nNeurocrine Biosciences is an EEO/AA/Disability/Vets employer.'"
b'Machine Learning Engineering Manager',b'Mitchell International',"b'San Diego, California'","b'We are looking for a Machine Learning Engineering Manager having insatiable intellectual curiosity and passion about developing intelligent products and applying Computer Vision; Artificial Intelligence (Deep learning) and Machine learning techniques to solve real business problems in the P&C sector.\n As a ML Engineering Manager, Your primary focus will be to apply your experience in managing teams and Machine Learning knowledge in developing algorithmic solutions that combine techniques like clustering, Image based pattern mining, predictive modeling, deep learning, statistical Analysis, information retrieval, computer vision and natural language processing and apply them to vast amounts of data. You will help us analyze and discover information hidden in the vast amounts of data (Textual as well as Image), and help us make smarter decisions and deliver AI enabled products to our customers. \n You will be responsible to solve many challenging problems, including\nLeading engineering projects and a team of data scientists from inception to shipped software.\nBuilding models at scale using vast amounts of structured and unstructured heterogeneous types of data.\nEnsuring high accuracy based on industry\xe2\x80\x99s stringent requirements around precision or recall and with minimum Type I and Type II errors.\nGenerating predictions for millions of rows of data with high response time.\nDealing with high data diversity (vast amounts of data will need to be classified and will have multi labelled outcomes).\nDealing with very high dimensionality (expect to work on large matrix computations, variable transformation & feature engineering and selection using PCA and other novel ML techniques).\nDealing with noisy data (build models robust enough for unclassified and/or mislabeled data).\nYou will primarily work on,\nWorking collaboratively in coming up with strategy around labelling vast amounts of images as well as textual data.\nApplying ML techniques like collaborative filtering, bootstrap aggregation (bagging), Random Forest and Ensemble algorithms and generate statistically significant models.\nSelecting features, building and optimizing classifiers using machine learning techniques.\nData mining using state-of-the-art methods.\nExtending company\xe2\x80\x99s data with third party sources of information when needed.\nEnhancing data collection procedures to include information that is relevant for building analytic systems.\nProcessing, cleansing, and verifying the integrity of data used for analysis.\nDoing ad-hoc analysis and presenting results in a clear manner.\nCreating automated anomaly detection systems and constant tracking of its performance.\nBeing creative and going far beyond theoretical solutions to deal with challenges outlined.\nMeeting business requirements with domain knowledge into complex data analytical workflows and efficiently utilize expertise when needed to mitigate risk.\n\nQualifications\nYou must have\nConsistent track record of hiring, managing, and developing great Data Scientists and Engineers.\nDeep & broad understanding of machine learning theory, practice, and tools.\nPassionate problem solver, building the best solutions for the most important problems.\nAbility to communicate thoughtfully, leveraging problem-solving skills and a learning mindset to build long-term relationships.\nAt least 5+ years hands-on software development experience and applied machine learning experience.\nAt least 3+ years of engineering management experience.\nAt a Minimum - Master\xe2\x80\x99s Degree in Computer Science, Data Science, Mathematics or related field \nSound coding knowledge of scientific, distributed programming and scripting languages like Python, PyTorch, PySpark and/or Java.\nSolid foundation in statistics, machine learning, data structures, algorithms, and software design.\nExcellent understanding of machine learning, AI techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, Ensembles, Decisions Trees, and CNNs.\nExperience with common data science toolkits, such as Scikit-learn, MLLib, Google Inception, Google TensorFlow, Weka, NumPy, SciPy, MatLab, Excellence in at least three of these is highly desirable.\nProficiency in using query languages such as SQL, PL/SQL.\nExperience Big Data framework like Hadoop.\nGood applied statistics skills, such as distributions, statistical analysis and testing (T Test), and regression techniques.\nGreat communication skills and Data-oriented personality.\n\nPreferred Qualifications\nExperience with cloud framework like AWS SageMaker, GCP MLE as well as data visualization tools, such as D3.js, Tableau, Kibana, GGplot is a plus.\nFamiliarity of modern statistical learning methods & machine learning Frameworks like H2O, Spark, and PyTorch\nExperience working with cloud infrastructure like AWS, Azure and/or GCP.\nExperience with NoSQL databases, such as MongoDB, HBase is a plus\n  Mitchell International, an equal opportunity employer, values the diversity of our workforce and the knowledge of our people. Mitchell will not discriminate against an applicant or employee on the basis of race, color, religion, national origin, ancestry, sex/gender, age, physical or mental disability, military or veteran status, genetic information, sexual orientation, gender identity, gender expression, marital status, or any other characteristic protected by applicable federal, state or local law.'"
b'Azure Data Architect',b'Perficient',"b'San Diego, CA, US'","b""Overview\n\nAt Perficient you\xe2\x80\x99ll deliver mission-critical technology and business solutions to Fortune 500 companies and some of the most recognized brands on the planet. And you\xe2\x80\x99ll do it with cutting-edge technologies, thanks to our close partnerships with the world\xe2\x80\x99s biggest vendors. Our network of offices across North America, as well as locations in India and China, will give you the opportunity to spread your wings, too.\n\nWe\xe2\x80\x99re proud to be publicly recognized as a \xe2\x80\x9cTop Workplace\xe2\x80\x9d year after year. This is due, in no small part, to our entrepreneurial attitude and collaborative spirit that sets us apart and keeps our colleagues impassioned, driven, and fulfilled.\n\nPerficient currently has a career opportunity for a Senior Azure Solutions Architect.\n\nJob Overview\n\nOne of our large clients has made strategic decision to move all their Hospital management data to a new Azure environment for processing and analytics. This is a multiyear roadmap with many components that will piece into a larger Enterprise level Azure implementation. Perficient subject matter expert will work with the client team to move this data into new environment in a fashion that will meet requirements for applications and analytics.\n\nA Senior Solutions Architect is expected to be knowledgeable in two or more technologies within (a given Solutions/Practice area). The Solutions Architect may or may not have a programming background, but will have expert infrastructure architecture, client presales / presentation, team management and thought leadership skills.\n\nYou will provide best-fit architectural solutions for one or more projects; you will assist in defining scope and sizing of work; and anchor Proof of Concept developments. You will provide solution architecture for the business problem, platform integration with third party services, designing and developing complex features for clients' business needs. You will collaborate with some of the best talent in the industry to create and implement innovative high quality solutions, participate in Sales and various pursuits focused on our clients' business needs.\n\nYou will also contribute in a variety of roles in thought leadership, mentorship, systems analysis, architecture, design, configuration, testing, debugging, and documentation. You will challenge your leading edge solutions, consultative and business skills through the diversity of work in multiple industry domains. This role is considered part of the Business Unit Senior Leadership team and may mentor junior architects and other delivery team members.\n\nResponsibilities\nOwn and aggressively drive forward specific areas of Azure technology architecture and provide architectural solutions/designs to project execution teams for implementation.\nProvide architectural assessments, strategies, and roadmaps for one or more technologies including ADLS and Synapse (formerly knows as ADW)\nLead workshops with many teams to define data ingestion, validation, mining, engineering, modeling, visualization, AI, and analytics\nDesign and Build Azure Data services including ADF, ADL, AMM, ADLS, ADW, Power BI, AML, ABS, and other services within the Azure data framework\nLead the technical planning & requirements gathering phases including estimate, develop, test, manage projects, architect and deliver complex projects\nParticipate and lead in design sessions, demos and prototype sessions, testing and training workshops with business users and other IT associates\nContribute to the thought capital through the creation of executive presentations, architecture documents and articulate them to executives through presentations Determine Project and solution estimation and team structure definition\nSupport multiple Agile Scrum teams with planning, scoping and creation of technical solutions for the new product capabilities, through to continuous delivery to production.\nProvide end to end vision and hands on experience with Azure Cloud Platform\nProvide vision and leadership to define the core technologies necessary to meet client needs including: development tools and methodologies, package solutions, systems architecture, security techniques, and emerging technologies\nLiaise with offshore team and clients for resolving technical dependencies, issues, and risks.\nMentor and provide architectural guidance to multiple teams building innovative applications.\nDrive common vision, practices and capabilities across teams.\nEngage with business stakeholders to understand required capabilities, integrating business knowledge with technical solutions\nEngage with Technical Architects and technical staff to determine the most appropriate technical strategy and designs to meet business needs\nDemonstrate broad solutions technical leadership, impacting significant technical direction, exerting influence outside of the immediate team and driving change\n\nQualifications\nAt least 10+ years of experience in designing, architecting and implementing large scale data processing/data storage/data distribution systems particularly in Azure\nMost recent 2+ years of experience in delivering large scale Azure projects\nAt least 5+ years real time and streaming experience in Azure based data solutions\nAt least 3+ years in presales and demo using Azure data services including ADW and ADLS\nAt least 5+ years of Hands-on administration, configuration management, monitoring, performance tuning of Hadoop/Distributed platforms\nAt least 5+ years of demonstrated experience at least in the most recent 2+ years of designing and delivering solutions using Cortana Intelligence suite of analytics services part of Microsoft Azure including Azure Machine Learning Studio, HDInsight, Polybase, Azure Data Lake Analytics, Azure Data Warehouse, Streaming Analytics, Data Catalog, R/R Studio\nShould have experience designing service management, orchestration, monitoring and management requirements of cloud platform.\nAt least 3+ years of experience in migrating large volumes of data using standard Azure automation tools from on premise and cloud infrastructure to Azure\nAbility to produce high quality work products under pressure and within deadlines with specific references\nVERY strong communication, solutioning, and client facing skills especially non-technical business users\nAt least 5+ years of working with large multi-vendor environment with multiple teams and people as a part of the project\nAt least 2+ year of working with Power BI\nAt least 5+ years of working with a complex Big Data environment using Microsoft tools\n5+ years of experience with Team Foundation Server/JIRA/GitHub and other code management toolsets\n\nPreferred Skills And Education\n\nMaster\xe2\x80\x99s degree in Computer Science or related field\n\nCertification in Azure platform\n\nPerficient full-time employees receive complete and competitive benefits. We offer a collaborative work environment, competitive compensation, generous work/life opportunities and an outstanding benefits package that includes paid time off plus holidays. In addition, all colleagues are eligible for a number of rewards and recognition programs including billable bonus opportunities. Encouraging a healthy work/life balance and providing our colleagues great benefits are just part of what makes Perficient a great place to work.\n\nMore About Perficient\n\nPerficient is the leading digital transformation consulting firm serving Global 2000 and enterprise customers throughout North America. With unparalleled information technology, management consulting and creative capabilities, Perficient and its Perficient Digital agency deliver vision, execution and value with outstanding digital experience, business optimization and industry solutions.\n\nOur work enables clients to improve productivity and competitiveness; grow and strengthen relationships with customers, suppliers and partners; and reduce costs. Perficient's professionals serve clients from a network of offices across North America and offshore locations in India and China. Traded on the Nasdaq Global Select Market, Perficient is a member of the Russell 2000 index and the S&P SmallCap 600 index.\n\nPerficient is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national, origin, disability status, protected veteran status, or any other characteristic protected by law.\n\nDisclaimer: The above statements are not intended to be a complete statement of job content, rather to act as a guide to the essential functions performed by the employee assigned to this classification. Management retains the discretion to add or change the duties of the position at any time.\n\nOptions\n\nApply for this job online Apply\n\nShare\n\nRefer this job to a friend Refer\n\nSorry the Share function is not working properly at this moment. Please refresh the page and try again later.\n\nShare on your newsfeed\n\nSelect work authorization questions to ask when applicants apply\n\nAre you legally authorized to work in the United States?\nWill you now, or in the future, require sponsorship for employment visa status (e.g. H-1B visa status)?"""
b'Staff Data Scientist',b'Wiley Job Network',"b'San Diego, CA, US'",b'Intuit is hiring a Staff Data scientist to focus on our Consumer Tax Group. We are looking for exceptional talent that can improve the bottom lines of our TurboTax offerings.'
b'Machine Learning Software Engineer \xe2\x80\x93 Qualcomm AI Research',b'Qualcomm',"b'San Diego, CA, US'","b""Job Id\n\nJob Title\n\nMachine Learning Software Engineer \xe2\x80\x93 Qualcomm AI Research\n\nCompany\n\n\nDivision\n\nQualcomm Technologies, Inc.\n\n\nCorporate Research & Development\n\nJob Area\n\nEngineering - Systems\n\nLocation\n\nCalifornia - San Diego\n\nOverview\n\nArtificial Intelligence is changing the world for the benefit of human beings and societies. AI is moving from cloud to the edge devices. QUALCOMM, as the world's leading mobile computing platform provider, is committed to enable the wide deployment of intelligent solutions on all possible devices. Be a part of our Deep Learning research project in Corporate R&D, where you will be involved and participate in building best-in-class solutions and tools needed to enable state-of-the-art technologies for next generation mobile/embedded machine learning platforms for smart phones, autonomous vehicles, robotics and IOT devices. In this role, you will work in a dynamic research environment, be part of a multi-disciplinary team of researchers and software developers, collaborate with internal teams, work with popular neural network frameworks, and understand the architecture of Qualcomm\xe2\x80\x99s SOC compute and ML HW accelerators. You will design, develop & test software for machine learning tools and frameworks that enable making models smaller and run efficiently on all edge devices. The successful applicant should have a strong software background, and passion to work on neural network frameworks/libraries.\n\nWe are looking for motivated engineers at various levels who possess experience in some of the areas below:\nExtensive programming in Python, C/C++\nObject-oriented software design and development\nExperience in debugging complex software issues\nKnowledge of neural networks, with hands-on experience using ML frameworks such as TensorFlow or PyTorch\nKnowledge of Convolutional Neural Networks (CNNs), RNN/LSTMs\nFamiliarity with any of the deep learning compiler frameworks TVM, Glow or XLA\nExperience with compiler frameworks such as LLVM or GCC\nKnowledge Qualcomm Hexagon DSP is a plus\nExperience developing embedded software, preferably on-device ML\nExperience with CI/CD tools like Jenkins, Docker, and Cloud technologies\nPrevious experience working on machine learning data pipelines\nPrevious experience working in an Agile environment, and collaborating with multi-disciplinary teams\n\nEducation Requirements\n\nRequired: Bachelor's, Computer Engineering and/or Computer Science and/or Electrical Engineering\nPreferred: Master's, Computer Engineering and/or Computer Science and/or Electrical Engineering\n\nKeywords"""
